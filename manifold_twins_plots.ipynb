{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run manifold_twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "IDR:          BLACKSTON\n",
      "Phase range: [-5.0, 5.0]\n",
      "Bin velocity: 1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [00:17<00:00, 23.86it/s]\n"
     ]
    }
   ],
   "source": [
    "a = ManifoldTwinsAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating the spectra at maximum light...\n",
      "Loaded cached stan model\n",
      "Using saved stan result\n",
      "Reading between the lines...\n",
      "Loaded cached stan model\n",
      "Using saved stan result\n",
      "Building masks...\n",
      "Masking 30/203 targets whose interpolation uncertainty power is more than 0.100 of the intrinsic power.\n",
      "Generating the manifold learning embedding...\n",
      "Calculating spectral indicators...\n",
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Optimization terminated successfully.\n",
      "    Color scale:          -0.007 ± 0.070\n",
      "    Intrinsic dispersion: 0.065 ± 0.013 mag\n",
      "    GP kernel amplitude:  0.111 ± 0.042 mag\n",
      "    GP length scale:      3.348 ± 2.272\n",
      "    Fit NMAD:             0.072 mag\n",
      "    Fit std:              0.098 mag\n",
      "Calculating SALT2 Hubble residuals...\n",
      "SALT2 Hubble fit: \n",
      "    ref_mag: -10.449\n",
      "    alpha:   0.142\n",
      "    beta:    2.665\n",
      "    σ_int:   0.134\n",
      "    RMS:     0.156\n",
      "    NMAD:    0.110\n",
      "    WRMS:    0.156\n",
      "Loading host galaxy data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "a.run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.97it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = a.bootstrap_salt_hubble_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18377547796239047"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(samples['beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default settings for matplotlib figures\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Choose how big to make figures. This will scale the text size.\n",
    "mpl.rcParams['figure.figsize'] = (5., 4.)\n",
    "\n",
    "# Choose the size of full-page spectra figures.\n",
    "spectrum_plot_figsize = (9., 4.)\n",
    "\n",
    "# Choose how to plot spectra. We use F_nu instead of F_lambda so that\n",
    "# the features at all wavelengths can be seen. The overall scale is\n",
    "# arbitrary and normalized to be ~1.\n",
    "spectrum_plot_scale = a.wave**2 / 5000**2\n",
    "spectrum_plot_ylabel = 'Normalized flux (erg/$cm^2$/s/Hz)'\n",
    "\n",
    "# Choose the colormap to use for all of the plots\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# crange = np.linspace(0, 1, 256)\n",
    "# plot_cmap = ListedColormap(plt.cm.plasma(crange)[:210])\n",
    "plot_cmap = plt.cm.coolwarm\n",
    "\n",
    "# Set the DPI. This will change how big things appear in Jupyter lab\n",
    "# mpl.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 20.32it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    res.append(a.calculate_salt_hubble_residuals(bootstrap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load host galaxy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>Table length=100</i>\n",
       "<table id=\"table139756130139536\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>alpha</th><th>beta</th><th>corr_mag_raw_uncertainties [203]</th><th>corr_mag_uncertainties [203]</th><th>corr_mags [203]</th><th>corr_mags_raw [203]</th><th>intrinsic_dispersion</th><th>mask [151]</th><th>nmad</th><th>ref_mag</th><th>rms</th><th>wrms</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>0.14718095298540537</td><td>2.760114501967889</td><td>0.11290306904216835 .. 0.11066243632156879</td><td>0.18955331249904112 .. 0.1882273361997236</td><td>0.1233526510655274 .. 0.3540437627084003</td><td>-10.463952648969062 .. -9.829615208357197</td><td>0.15226081334413824</td><td>163 .. 154</td><td>0.11979648227782125</td><td>-10.444929680566121</td><td>0.17129110000061384</td><td>0.1738450292180987</td></tr>\n",
       "<tr><td>0.15104730015442075</td><td>2.433313547141882</td><td>0.10953936118833435 .. 0.10385784740929575</td><td>0.17329844190326643 .. 0.16976433896741683</td><td>0.0921878828930609 .. 0.37198698419348375</td><td>-10.512385847095954 .. -9.818336892323964</td><td>0.13428878700975536</td><td>13 .. 191</td><td>0.10311986181332397</td><td>-10.45845799631349</td><td>0.1538468999648941</td><td>0.15427637796502805</td></tr>\n",
       "<tr><td>0.15938527003197792</td><td>2.601011825537981</td><td>0.11153312356519612 .. 0.10778108420359644</td><td>0.159796879894293 .. 0.15720104097570264</td><td>0.1186035674462449 .. 0.34489461021572687</td><td>-10.487532296874777 .. -9.824124372911305</td><td>0.11443515706172555</td><td>95 .. 119</td><td>0.11833883421241921</td><td>-10.45195438842582</td><td>0.14078379552787126</td><td>0.1401151812223052</td></tr>\n",
       "<tr><td>0.1414173042061097</td><td>2.7459514992688527</td><td>0.11255736763850797 .. 0.11004529955013459</td><td>0.16507689688678695 .. 0.16337438241394978</td><td>0.11268064029120417 .. 0.3617664555788611</td><td>-10.466051662162458 .. -9.82912642514509</td><td>0.12075272616409391</td><td>155 .. 30</td><td>0.11633039074062579</td><td>-10.44193215351114</td><td>0.1444160075976739</td><td>0.14607693665932403</td></tr>\n",
       "<tr><td>0.1439565663259102</td><td>2.534074811841783</td><td>0.11029769123842796 .. 0.10551397998368617</td><td>0.1724633192257842 .. 0.16944384249020347</td><td>0.10371796337335049 .. 0.3845529073557046</td><td>-10.49745262788512 .. -9.82181429154943</td><td>0.13258210959947483</td><td>197 .. 34</td><td>0.13099257416204596</td><td>-10.461914084954714</td><td>0.1539889488894685</td><td>0.15323850911508513</td></tr>\n",
       "<tr><td>0.15630047198353506</td><td>2.6034177580356985</td><td>0.11144856710730787 .. 0.10765823455280935</td><td>0.17970005054308302 .. 0.17737423860849186</td><td>0.12732315571291863 .. 0.3616347103708293</td><td>-10.487175728132792 .. -9.824207404697667</td><td>0.14096568750910446</td><td>162 .. 2</td><td>0.11359448649914575</td><td>-10.463301489954148</td><td>0.15926441098373317</td><td>0.16130775624891247</td></tr>\n",
       "<tr><td>0.15677988835576953</td><td>2.8020849477007146</td><td>0.11371392276934682 .. 0.11213851360494531</td><td>0.1861989726056479 .. 0.18524105214917225</td><td>0.1441827293471576 .. 0.340879953453765</td><td>-10.45773246238872 .. -9.831063661747677</td><td>0.1474421960220542</td><td>160 .. 157</td><td>0.13991266013607778</td><td>-10.450254034010776</td><td>0.16856637997930393</td><td>0.16939549662922504</td></tr>\n",
       "<tr><td>0.12927857491545172</td><td>2.673091377471413</td><td>0.11135757690035432 .. 0.10779865794165365</td><td>0.18436207051878226 .. 0.18223450213084175</td><td>0.10047516988597494 .. 0.39616431631201365</td><td>-10.476849821294042 .. -9.826611929799478</td><td>0.14693149122245414</td><td>18 .. 60</td><td>0.12934165451230134</td><td>-10.45226725229302</td><td>0.16726669724111715</td><td>0.16758816273710797</td></tr>\n",
       "<tr><td>0.1461897508424052</td><td>2.537529992211738</td><td>0.11040788497145382 .. 0.1057060393025183</td><td>0.17715390488476782 .. 0.1742623645457536</td><td>0.098686737924778 .. 0.3727658203428046</td><td>-10.496940556445454 .. -9.821933534212551</td><td>0.13854098654207564</td><td>122 .. 164</td><td>0.12296519481076479</td><td>-10.454210515133909</td><td>0.15757737743259004</td><td>0.15876719373987497</td></tr>\n",
       "<tr><td>0.13400775715479116</td><td>2.5745273782640297</td><td>0.11040731727877744 .. 0.10585864091204689</td><td>0.16846927384135577 .. 0.16552393293926645</td><td>0.09088297577101656 .. 0.3916114020240755</td><td>-10.491457397040973 .. -9.823210360996988</td><td>0.12724826332778413</td><td>47 .. 148</td><td>0.11913394609793579</td><td>-10.452707855482213</td><td>0.1495771062131462</td><td>0.15046579996209725</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>0.17162326173961676</td><td>2.463735532442542</td><td>0.11061361214603009 .. 0.1056890343532979</td><td>0.15747810528867515 .. 0.15405893169774762</td><td>0.13320384549117925 .. 0.35101445322201386</td><td>-10.50787718817155 .. -9.819386793676797</td><td>0.11208917188256268</td><td>38 .. 119</td><td>0.10112101062467091</td><td>-10.475061126128905</td><td>0.13414106460002803</td><td>0.13789912453389783</td></tr>\n",
       "<tr><td>0.1414626426139956</td><td>2.284888221731198</td><td>0.10785139734021675 .. 0.10050798820815618</td><td>0.18398593528038232 .. 0.17977974348188003</td><td>0.07451374099184704 .. 0.4077185012817548</td><td>-10.53438306921696 .. -9.81321454582345</td><td>0.1490600565971975</td><td>108 .. 12</td><td>0.11931486103834717</td><td>-10.472052803119034</td><td>0.16783332166445</td><td>0.16629678308815898</td></tr>\n",
       "<tr><td>0.12454851523252469</td><td>3.0452438458583497</td><td>0.1159168020260296 .. 0.11660669873987738</td><td>0.17930550758340533 .. 0.179752280232584</td><td>0.12524630179474627 .. 0.3659097926044872</td><td>-10.421695348919895 .. -9.839455384168362</td><td>0.13679824581404867</td><td>89 .. 51</td><td>0.1398771328439441</td><td>-10.426459539066219</td><td>0.16160651423378772</td><td>0.16211052816431082</td></tr>\n",
       "<tr><td>0.13872327236222956</td><td>2.7784422115267877</td><td>0.11286204172521201 .. 0.110667721982979</td><td>0.18218351678135553 .. 0.18083234780685917</td><td>0.13162368151367332 .. 0.38216137787583193</td><td>-10.461236409695065 .. -9.830247720892787</td><td>0.14301396199126487</td><td>197 .. 23</td><td>0.1075067200220655</td><td>-10.458666016251062</td><td>0.16243857993061103</td><td>0.16471581918545353</td></tr>\n",
       "<tr><td>0.15336995277693696</td><td>2.5861027172098727</td><td>0.11116166539468679 .. 0.1071245801675433</td><td>0.15937412025164874 .. 0.15658502491853776</td><td>0.0886762667796237 .. 0.3341885432426821</td><td>-10.489741885882664 .. -9.823609840646283</td><td>0.11420680519420322</td><td>6 .. 150</td><td>0.11663771553637599</td><td>-10.430055599006097</td><td>0.13854374542266273</td><td>0.13915669160034988</td></tr>\n",
       "<tr><td>0.13916804008074973</td><td>2.577323688710966</td><td>0.11059691656048495 .. 0.10617916968872065</td><td>0.17845499218826988 .. 0.17575130827397767</td><td>0.11181270127879728 .. 0.3978780331340417</td><td>-10.491042972738043 .. -9.82330686522221</td><td>0.14005179857548633</td><td>15 .. 43</td><td>0.13694915007960565</td><td>-10.46823135263013</td><td>0.1593320283211187</td><td>0.16099189645447323</td></tr>\n",
       "<tr><td>0.14821791947521773</td><td>2.6745072317367367</td><td>0.11195172141116701 .. 0.10877356515276755</td><td>0.1774256418268186 .. 0.17543762118422132</td><td>0.10374245812650251 .. 0.3472314238304204</td><td>-10.476639986074352 .. -9.826660792728505</td><td>0.13764690498058782</td><td>45 .. 17</td><td>0.13932344620949605</td><td>-10.437003714320607</td><td>0.15969403009885924</td><td>0.16068299471762612</td></tr>\n",
       "<tr><td>0.14133621526246135</td><td>2.5804895945071835</td><td>0.11069963193248557 .. 0.1063588331163431</td><td>0.18594720280308516 .. 0.1833961698132598</td><td>0.09988237013817347 .. 0.37942298453537937</td><td>-10.490573772937935 .. -9.823416124652375</td><td>0.14940533364075026</td><td>160 .. 193</td><td>0.11061968364284669</td><td>-10.45373443559187</td><td>0.16701446597795508</td><td>0.16849061120796538</td></tr>\n",
       "<tr><td>0.13982851776233196</td><td>2.8115841279647893</td><td>0.11329494127282473 .. 0.11150091077461954</td><td>0.17443456953472525 .. 0.17327471954766444</td><td>0.12060298487507204 .. 0.36205399332102495</td><td>-10.456324646184456 .. -9.831391490523858</td><td>0.13263361312560287</td><td>174 .. 18</td><td>0.1035490837281875</td><td>-10.441664396028402</td><td>0.15562900657322792</td><td>0.15574261220552166</td></tr>\n",
       "<tr><td>0.1400229448447151</td><td>2.3321058896259834</td><td>0.10821638268480183 .. 0.10129702713852495</td><td>0.17863992108657878 .. 0.17453516445558664</td><td>0.07950849435336949 .. 0.4080342634541658</td><td>-10.527385223493235 .. -9.814844087515437</td><td>0.14213175551028565</td><td>105 .. 157</td><td>0.11568004422956843</td><td>-10.471442403612741</td><td>0.16071474263017338</td><td>0.161006761553763</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=100>\n",
       "       alpha               beta        ...         wrms       \n",
       "      float64            float64       ...       float64      \n",
       "------------------- ------------------ ... -------------------\n",
       "0.14718095298540537  2.760114501967889 ...  0.1738450292180987\n",
       "0.15104730015442075  2.433313547141882 ... 0.15427637796502805\n",
       "0.15938527003197792  2.601011825537981 ...  0.1401151812223052\n",
       " 0.1414173042061097 2.7459514992688527 ... 0.14607693665932403\n",
       " 0.1439565663259102  2.534074811841783 ... 0.15323850911508513\n",
       "0.15630047198353506 2.6034177580356985 ... 0.16130775624891247\n",
       "0.15677988835576953 2.8020849477007146 ... 0.16939549662922504\n",
       "0.12927857491545172  2.673091377471413 ... 0.16758816273710797\n",
       " 0.1461897508424052  2.537529992211738 ... 0.15876719373987497\n",
       "0.13400775715479116 2.5745273782640297 ... 0.15046579996209725\n",
       "                ...                ... ...                 ...\n",
       "0.17162326173961676  2.463735532442542 ... 0.13789912453389783\n",
       " 0.1414626426139956  2.284888221731198 ... 0.16629678308815898\n",
       "0.12454851523252469 3.0452438458583497 ... 0.16211052816431082\n",
       "0.13872327236222956 2.7784422115267877 ... 0.16471581918545353\n",
       "0.15336995277693696 2.5861027172098727 ... 0.13915669160034988\n",
       "0.13916804008074973  2.577323688710966 ... 0.16099189645447323\n",
       "0.14821791947521773 2.6745072317367367 ... 0.16068299471762612\n",
       "0.14133621526246135 2.5804895945071835 ... 0.16849061120796538\n",
       "0.13982851776233196 2.8115841279647893 ... 0.15574261220552166\n",
       " 0.1400229448447151 2.3321058896259834 ...   0.161006761553763"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.bootstrap_salt_hubble_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.bootstrap_salt_hubble_residuals_host_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating SALT2 Hubble residuals...\n",
      "SALT2 Hubble fit: \n",
      "    ref_mag: -10.442\n",
      "    alpha:   0.144\n",
      "    beta:    2.597\n",
      "    σ_int:   0.114\n",
      "    RMS:     0.139\n",
      "    NMAD:    0.107\n",
      "    WRMS:    0.139\n"
     ]
    }
   ],
   "source": [
    "a.calculate_salt_hubble_residuals(a.host_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.52it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in tqdm.tqdm(range(100)):\n",
    "    res.append(a.calculate_salt_hubble_residuals(a.host_mask & a.uncertainty_mask & extra_mask,\n",
    "                                                 [a.host_data['p(prompt)']], bootstrap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=100</i>\n",
       "<table id=\"table140703908935248\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>alpha</th><th>beta</th><th>corr_mag_raw_uncertainties [203]</th><th>corr_mag_uncertainties [203]</th><th>corr_mags [203]</th><th>corr_mags_raw [203]</th><th>intrinsic_dispersion</th><th>mask [151]</th><th>nmad</th><th>ref_mag</th><th>rms</th><th>wrms</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>0.16578972610429732</td><td>2.9573284375298634</td><td>0.11594078299439445 .. 0.11633994795187384</td><td>0.18335316637578933 .. 0.1836058330993853</td><td>0.15837902871242449 .. 0.30200126459532406</td><td>-10.43472476124902 .. -9.836421311762278</td><td>0.1420426642198555</td><td>100 .. 54</td><td>0.13169481618122758</td><td>-10.432726958062906</td><td>0.16638092707534743</td><td>0.16644927890579073</td></tr>\n",
       "<tr><td>0.14728533125811707</td><td>2.9614604674441556</td><td>0.11540433135820385 .. 0.11549829736648613</td><td>0.16685706119655433 .. 0.16692206525643583</td><td>0.14517875373982747 .. 0.3387946301971123</td><td>-10.434112378021402 .. -9.836563913362868</td><td>0.12051190470205242</td><td>138 .. 162</td><td>0.12284309254402886</td><td>-10.436814541882288</td><td>0.14499323505612685</td><td>0.14732041255275516</td></tr>\n",
       "<tr><td>0.11782670463732466</td><td>2.517630497209835</td><td>0.10934127567960662 .. 0.10387797965270282</td><td>0.17405311735776183 .. 0.17067398088589372</td><td>0.06792106429348621 .. 0.42342223626554265</td><td>-10.49988974055835 .. -9.821246777364939</td><td>0.13542146467495866</td><td>12 .. 113</td><td>0.10937318423439178</td><td>-10.453831042373121</td><td>0.15669011084138745</td><td>0.1546738133295938</td></tr>\n",
       "<tr><td>0.1435213847246345</td><td>2.4200967403509464</td><td>0.10915003811987918 .. 0.1031771539724747</td><td>0.1685630993058377 .. 0.16475834645892262</td><td>0.0729587422339435 .. 0.37581270977462644</td><td>-10.514344630301625 .. -9.817880763534445</td><td>0.1284514991193899</td><td>48 .. 176</td><td>0.10458624500601935</td><td>-10.448467839522214</td><td>0.14894711209921352</td><td>0.14822309236506706</td></tr>\n",
       "<tr><td>0.15635381518386995</td><td>3.0625598673986745</td><td>0.11702068042885426 .. 0.11848832587773554</td><td>0.18673038492065586 .. 0.18765361806768532</td><td>0.1680556588413733 .. 0.3183286591662462</td><td>-10.419129045824242 .. -9.84005298206545</td><td>0.1455142501770334</td><td>72 .. 74</td><td>0.09986279108455814</td><td>-10.43593570918405</td><td>0.16881673829292262</td><td>0.1703242062680094</td></tr>\n",
       "<tr><td>0.13929587566662263</td><td>2.4419722679585845</td><td>0.1092194764277256 .. 0.10338262352728503</td><td>0.16208802526250507 .. 0.15821378179455897</td><td>0.06252553338541667 .. 0.37297104094166045</td><td>-10.511102590316414 .. -9.818635715777114</td><td>0.11976491098127186</td><td>23 .. 43</td><td>0.10481714161676182</td><td>-10.438880140452905</td><td>0.14076189774161457</td><td>0.14181796796277898</td></tr>\n",
       "<tr><td>0.1378379970770674</td><td>2.6598411319655293</td><td>0.11145908307503767 .. 0.1079155782105965</td><td>0.181679846168189 .. 0.1795277452771466</td><td>0.10486673868222773 .. 0.37950254239477665</td><td>-10.478813560249941 .. -9.826154646997436</td><td>0.14347278244938538</td><td>59 .. 152</td><td>0.11698216494328166</td><td>-10.450342595771037</td><td>0.1637196587826098</td><td>0.16434741624465318</td></tr>\n",
       "<tr><td>0.1466139156619171</td><td>2.6269180847238913</td><td>0.1113721236862561 .. 0.10763946919987043</td><td>0.18883630115209982 .. 0.1866591921873918</td><td>0.12439045316415687 .. 0.3809736895953879</td><td>-10.48369288647726 .. -9.825018430820325</td><td>0.15249720882173487</td><td>52 .. 165</td><td>0.12006437339056965</td><td>-10.466256244207855</td><td>0.16969829226760416</td><td>0.17129166503828672</td></tr>\n",
       "<tr><td>0.13093661496961465</td><td>2.7772746213653714</td><td>0.11262523745518274 .. 0.11027264427002714</td><td>0.1796662144299932 .. 0.17820089946482298</td><td>0.10305557504728213 .. 0.37516165154632297</td><td>-10.46140945118954 .. -9.830207425873317</td><td>0.13998394370701234</td><td>157 .. 17</td><td>0.14500857728939479</td><td>-10.437803380899794</td><td>0.16097867228634521</td><td>0.16119001880384332</td></tr>\n",
       "<tr><td>0.1491118784377539</td><td>2.9298569892775466</td><td>0.1150511674038026 .. 0.11480681109848052</td><td>0.17867070698387127 .. 0.17851345688138126</td><td>0.1560133009457214 .. 0.35039427695275727</td><td>-10.438796138876254 .. -9.835473237190572</td><td>0.13669839213808835</td><td>156 .. 118</td><td>0.15268028377913712</td><td>-10.450565937982526</td><td>0.15952438948057454</td><td>0.1605522565671403</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>0.1493021473444394</td><td>2.98569958077523</td><td>0.11578159648293056 .. 0.11620033527167511</td><td>0.1787215992479248 .. 0.1789931559329836</td><td>0.14577128115038995 .. 0.32942714898195113</td><td>-10.43052004525417 .. -9.837400435950933</td><td>0.1361470967505355</td><td>113 .. 131</td><td>0.1411021965601867</td><td>-10.431863767777152</td><td>0.15923758545961034</td><td>0.16084294154585738</td></tr>\n",
       "<tr><td>0.12814346842410154</td><td>2.5863380989831706</td><td>0.11036092658189811 .. 0.10582763336575925</td><td>0.16817900368742417 .. 0.165239617371492</td><td>0.06521837832282706 .. 0.37987171999177427</td><td>-10.489707001369956 .. -9.823617963970246</td><td>0.12690407071989268</td><td>121 .. 124</td><td>0.10064850516560633</td><td>-10.430965687031133</td><td>0.15000027022032747</td><td>0.1484870935410576</td></tr>\n",
       "<tr><td>0.14642406201412245</td><td>2.442548521663482</td><td>0.1094655583315371 .. 0.1037810236197755</td><td>0.1868549395615292 .. 0.18358257227001692</td><td>0.1175256428598832 .. 0.40831668477906113</td><td>-10.511017187230992 .. -9.818655603024393</td><td>0.1514333516029662</td><td>171 .. 80</td><td>0.12805576041193212</td><td>-10.486899389744233</td><td>0.16620745380872223</td><td>0.16835505490455663</td></tr>\n",
       "<tr><td>0.12984015618225475</td><td>2.4011022585219424</td><td>0.10852332710573243 .. 0.10208168709180915</td><td>0.1735294594569821 .. 0.16957544519429876</td><td>0.06548451082495532 .. 0.4093300673743272</td><td>-10.517159687871551 .. -9.817225239840921</td><td>0.13540738817854286</td><td>140 .. 173</td><td>0.11423627285907864</td><td>-10.45704321369565</td><td>0.15401034035575437</td><td>0.15398809308199488</td></tr>\n",
       "<tr><td>0.13297494291235523</td><td>2.8571439553223152</td><td>0.11366271678637485 .. 0.1122688926391619</td><td>0.18653255924249337 .. 0.18568652811854258</td><td>0.11186128086137082 .. 0.3637838631053931</td><td>-10.449572499006035 .. -9.832963818033216</td><td>0.14790261143838754</td><td>141 .. 140</td><td>0.11990076309891962</td><td>-10.432800356269391</td><td>0.1698832987108213</td><td>0.16930604452090672</td></tr>\n",
       "<tr><td>0.13533304561374288</td><td>2.8471186375248947</td><td>0.11360301369906686 .. 0.11213582126030111</td><td>0.16367973703425448 .. 0.1626648517775568</td><td>0.12285664531805551 .. 0.3701438681260534</td><td>-10.451058290880253 .. -9.832617831582494</td><td>0.11783637636185323</td><td>179 .. 38</td><td>0.09105821243893927</td><td>-10.443000399955825</td><td>0.1429894322554144</td><td>0.14418922828232988</td></tr>\n",
       "<tr><td>0.1225485287483555</td><td>2.7988239185092416</td><td>0.11266394151400155 .. 0.11040716024305036</td><td>0.1743383346604404 .. 0.17288849657406347</td><td>0.11042196570218366 .. 0.40159512991866286</td><td>-10.458215759853418 .. -9.830951119488324</td><td>0.13304394467507852</td><td>179 .. 160</td><td>0.10412574902908901</td><td>-10.450090302525757</td><td>0.15323126971482065</td><td>0.1551139480949508</td></tr>\n",
       "<tr><td>0.1415688339390113</td><td>2.5440045065323034</td><td>0.11032243784483854 .. 0.10559599969820943</td><td>0.15672374619608592 .. 0.15343339754424765</td><td>0.0832057133244497 .. 0.3687747484705124</td><td>-10.495981007734741 .. -9.822156977925278</td><td>0.11131618179629992</td><td>104 .. 114</td><td>0.11652286199793598</td><td>-10.442239989701267</td><td>0.1373443183236804</td><td>0.13712329586497823</td></tr>\n",
       "<tr><td>0.14389614449197602</td><td>2.2905724436672545</td><td>0.1079859647683262 .. 0.10074820354215812</td><td>0.17659292035992602 .. 0.17226227518314366</td><td>0.0748801969831554 .. 0.40037244199355015</td><td>-10.533540644973208 .. -9.81341071554221</td><td>0.1397286331941345</td><td>18 .. 132</td><td>0.12413613974848353</td><td>-10.469222784764812</td><td>0.15514475528410857</td><td>0.1565776166693334</td></tr>\n",
       "<tr><td>0.1317927577675515</td><td>2.728616357233706</td><td>0.11207078104301998 .. 0.10918113859866316</td><td>0.16676118285650182 .. 0.1648331070198205</td><td>0.097260786723524 .. 0.37590948297604854</td><td>-10.468620798991306 .. -9.82852816737544</td><td>0.12348859114957587</td><td>126 .. 139</td><td>0.11248031325284905</td><td>-10.438391749917438</td><td>0.14644059462384074</td><td>0.1468761660892212</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=100>\n",
       "       alpha               beta        ...         wrms       \n",
       "      float64            float64       ...       float64      \n",
       "------------------- ------------------ ... -------------------\n",
       "0.16578972610429732 2.9573284375298634 ... 0.16644927890579073\n",
       "0.14728533125811707 2.9614604674441556 ... 0.14732041255275516\n",
       "0.11782670463732466  2.517630497209835 ...  0.1546738133295938\n",
       " 0.1435213847246345 2.4200967403509464 ... 0.14822309236506706\n",
       "0.15635381518386995 3.0625598673986745 ...  0.1703242062680094\n",
       "0.13929587566662263 2.4419722679585845 ... 0.14181796796277898\n",
       " 0.1378379970770674 2.6598411319655293 ... 0.16434741624465318\n",
       " 0.1466139156619171 2.6269180847238913 ... 0.17129166503828672\n",
       "0.13093661496961465 2.7772746213653714 ... 0.16119001880384332\n",
       " 0.1491118784377539 2.9298569892775466 ...  0.1605522565671403\n",
       "                ...                ... ...                 ...\n",
       " 0.1493021473444394   2.98569958077523 ... 0.16084294154585738\n",
       "0.12814346842410154 2.5863380989831706 ...  0.1484870935410576\n",
       "0.14642406201412245  2.442548521663482 ... 0.16835505490455663\n",
       "0.12984015618225475 2.4011022585219424 ... 0.15398809308199488\n",
       "0.13297494291235523 2.8571439553223152 ... 0.16930604452090672\n",
       "0.13533304561374288 2.8471186375248947 ... 0.14418922828232988\n",
       " 0.1225485287483555 2.7988239185092416 ...  0.1551139480949508\n",
       " 0.1415688339390113 2.5440045065323034 ... 0.13712329586497823\n",
       "0.14389614449197602 2.2905724436672545 ...  0.1565776166693334\n",
       " 0.1317927577675515  2.728616357233706 ...  0.1468761660892212"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11731657779722467"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([i['covariate_amplitude_0'] for i in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = [\n",
    "    #\n",
    "    # Unusable host data.\n",
    "    #\n",
    "    \n",
    "    # Photo Optical data are unusable and no SNfactory optical data.\n",
    "    \"PTF09fox\",\n",
    "    \"SN2004gs\",\n",
    "    \"SNF20080919-000\",\n",
    "    \"SNF20080626-002\",\n",
    "    \n",
    "    # Spectral Data are unuable\n",
    "    \"PTF13asv\",\n",
    "    \n",
    "    #\n",
    "    # Peculiar SNe Ia\n",
    "    #\n",
    "\n",
    "    # HUBBLIZER - Bad in the zoo, Nico removed it for any reason.\n",
    "    \"LSQ12gxj\",\n",
    "    \n",
    "    # PECULIARS - JAKOB / GREG\n",
    "    \"PTF10ygu\",\n",
    "    \"PTF10ops\",\n",
    "    \n",
    "    # SUPERC_91T\n",
    "    \"SNF20070528-003\",\"SNF20070803-005\",\"SN2007if\",\n",
    "    \"SNF20070912-000\",\"SNF20080522-000\",\"SNF20080723-012\", # SCALZO et al 2012\n",
    "    \"SN2012dn\", # Childress 2016 Super-C\n",
    "    \"LSQ12cyz\", \"PTF11bju\",\"SNNGC2691\", \"LSQ12gdj\",\"LSQ12fhe\", \"PTF11mkx\",\n",
    "    \n",
    "    #\n",
    "    # Political reasons\n",
    "    #\n",
    "\n",
    "    # PTF collaboration\n",
    "    # \"PTF13anh\",\"PTF13ayw\",\"PTF13azs\",\"PTF13asv\",\n",
    "    # \"PTF12jqh\",\"PTF11bgv\",\"PTF11drz\",\"PTF12eer\",\n",
    "    # \"PTF12evo\", \"PTF12fuu\",\"PTF12ghy\",\"PTF12grk\",\n",
    "    # \"PTF12ikt\",\n",
    "]\n",
    "\n",
    "extra_mask = np.array([i.name not in remove_list for i in a.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e467071be04312abf850865fe362d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=101, description='idx', max=202), Checkbox(value=False, description='sav…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_same_night(idx, save=False, **kwargs)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_same_night(idx, save=False, **kwargs):\n",
    "    night_flux = a.flux[a.target_map == idx]\n",
    "    phases = a.salt_phases[a.target_map == idx]\n",
    "    model = a.interpolation_result['maximum_flux'][idx]\n",
    "    model_err = a.interpolation_result['maximum_fluxerr'][idx]\n",
    "    fig1 = plt.figure(**kwargs)\n",
    "    for flux, phase in zip(night_flux, phases):\n",
    "        plt.plot(a.wave, flux * spectrum_plot_scale, label='Data (%.2f days)' % phase)\n",
    "    plt.plot(a.wave, model * spectrum_plot_scale, c='k', ls='--', label='Model (0 days)')\n",
    "    plt.fill_between(a.wave, (model - model_err) * spectrum_plot_scale,\n",
    "                     (model + model_err) * spectrum_plot_scale, facecolor='k', alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.title(a.targets[idx])\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('./figures/interpolation_model_%s.pdf' % a.targets[idx])\n",
    "    \n",
    "    # plt.figure()\n",
    "    # shift_frac = (a.interpolation_result['shift_fluxerr'] / a.interpolation_result['shift_flux'])[a.target_map == idx]\n",
    "    # plt.plot(a.wave, shift_frac.T)\n",
    "    # orig_frac = (a.fluxerr / a.flux)[a.target_map == idx]\n",
    "    # plt.plot(a.wave, orig_frac.T, ls='--')\n",
    "    \n",
    "    \n",
    "    phase_slope = a.interpolation_result['phase_slope']\n",
    "    phase_quadratic = a.interpolation_result['phase_quadratic']\n",
    "    gray_offsets = a.interpolation_result['gray_offsets'][a.target_map == idx]\n",
    "    model_diffs = a.interpolation_result['model_diffs'][a.target_map == idx]\n",
    "    \n",
    "    fig2 = plt.figure(**kwargs)\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        plt.plot(a.wave, -2.5*np.log10(flux / model), label='Data (%.2f days)' % phase, c='C%d' % i)\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        plt.plot(a.wave, model_diff, label='Model (%.2f days)' % phase, c='C%d' % i, ls='--')\n",
    "    plt.legend(ncol=2, loc=1)\n",
    "    plt.title(a.targets[idx])\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel('Difference from maximum light (mag)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('./figures/interpolation_difference_%s.pdf' % a.targets[idx])\n",
    "    \n",
    "    fig3 = plt.figure(**kwargs)\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        plt.plot(a.wave, -2.5*np.log10(flux / model) - model_diff, label='Residuals (%.2f days)' % phase, c='C%d' % i)\n",
    "    plt.legend()\n",
    "    plt.title(a.targets[idx])\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel('Interpolation residuals (mag)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('./figures/interpolation_residuals_%s.pdf' % a.targets[idx])\n",
    "        \n",
    "    return fig1, fig2, fig3\n",
    "    \n",
    "from ipywidgets import interact\n",
    "interact(plot_same_night, idx=(0, len(a.targets)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ManifoldTwinsAnalysis' object has no attribute 'interpolation_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f886405bd7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplot_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplot_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplot_same_night\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-4e8ca237feab>\u001b[0m in \u001b[0;36mplot_same_night\u001b[0;34m(idx, save, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnight_flux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_map\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalt_phases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_map\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximum_flux'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximum_fluxerr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfig1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ManifoldTwinsAnalysis' object has no attribute 'interpolation_result'"
     ]
    }
   ],
   "source": [
    "plot_targets = ['PTF13ayw', 'SN2004gc']\n",
    "for plot_target in plot_targets:\n",
    "    target_names = np.array([i.name for i in a.targets])\n",
    "    plot_idx = np.where(target_names == plot_target)[0][0]\n",
    "\n",
    "    plot_same_night(plot_idx, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_slope = a.interpolation_result['phase_slope']\n",
    "phase_quadratic = a.interpolation_result['phase_quadratic']\n",
    "phase_slope_x1 = a.interpolation_result['phase_slope_x1']\n",
    "phase_quadratic_x1 = a.interpolation_result['phase_quadratic_x1']\n",
    "\n",
    "def evaluate_phase_difference(phase, x1=0):\n",
    "    phase_difference = (\n",
    "        phase_slope * phase\n",
    "        + phase_quadratic * phase * phase\n",
    "        + phase_slope_x1 * x1 * phase\n",
    "        + phase_quadratic_x1 * x1 * phase * phase\n",
    "    )\n",
    "    \n",
    "    return phase_difference\n",
    "\n",
    "# Look at change in phase for the same x1\n",
    "max_phase = a.phase_width\n",
    "min_phase = -a.phase_width\n",
    "num_phases = 10\n",
    "phases = np.linspace(min_phase, max_phase, num_phases)\n",
    "\n",
    "plt.figure(figsize=spectrum_plot_figsize)\n",
    "# plt.figure()\n",
    "norm = plt.Normalize(vmin=min_phase, vmax=max_phase)\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array(phases)\n",
    "\n",
    "for phase in phases:\n",
    "    plt.plot(a.wave, evaluate_phase_difference(phase), c=cmap(norm(phase)), zorder=np.abs(phase))\n",
    "    \n",
    "plt.colorbar(sm, label='Phase (days)')\n",
    "\n",
    "# plt.xlim(-5.2, 5.2)\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel('Brightness relative to $t_{max,B}$ (mag)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_phase_difference.pdf')\n",
    "\n",
    "\n",
    "def plot_x1_difference(phase):\n",
    "    # Look at change in phase for the same x1\n",
    "    min_x1 = -2\n",
    "    max_x1 = 2\n",
    "    num_x1s = 10\n",
    "    x1s = np.linspace(min_x1, max_x1, num_x1s)\n",
    "\n",
    "    plt.figure(figsize=spectrum_plot_figsize)\n",
    "    norm = plt.Normalize(vmin=min_x1, vmax=max_x1)\n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array(x1s)\n",
    "\n",
    "    for x1 in x1s:\n",
    "        plt.plot(a.wave, evaluate_phase_difference(phase, x1) - evaluate_phase_difference(phase, 0), c=cmap(norm(x1)))\n",
    "\n",
    "    plt.colorbar(sm, label='SALT2 $x_1$')\n",
    "\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel('Difference relative to $x_1=0$ (mag)')\n",
    "    plt.title('Difference in interpolation at %+d days' % phase)\n",
    "    # plt.gca().invert_yaxis()\n",
    "    plt.ylim(0.4, -0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/interpolation_x1_difference_phase_%d.pdf' % phase)\n",
    "    \n",
    "for phase in [-5, -3, -1, 1, 3, 5]:\n",
    "    plot_x1_difference(phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gray dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.interpolation_result['gray_dispersion_scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.salt_phases, a.interpolation_result['gray_offsets'], s=3, label='Individual spectra')\n",
    "math.plot_binned_mean(a.salt_phases, a.interpolation_result['gray_offsets'], c='C2', lw=2, label='Binned mean')\n",
    "math.plot_binned_rms(a.salt_phases, a.interpolation_result['gray_offsets'], c='C3', lw=2, label='Binned RMS')\n",
    "plt.xlabel('SALT2 Phase (days)')\n",
    "plt.ylabel('Gray offset (mag)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/gray_offset_vs_phase.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    coefs = a.interpolation_result['phase_dispersion_coefficients']\n",
    "except KeyError:\n",
    "    coefs = a.stan_data['phase_dispersion_coefficients']\n",
    "num_phase_coefficients = len(coefs)\n",
    "\n",
    "def evaluate_phase_dispersion(phase):\n",
    "    phase_scale = np.abs((num_phase_coefficients / 2) * (phase / a.phase_width))\n",
    "    full_bins = int(np.floor(phase_scale))\n",
    "    remainder = phase_scale - full_bins\n",
    "    \n",
    "    phase_coefficients = np.zeros(num_phase_coefficients)\n",
    "    \n",
    "    for j in range(full_bins + 1):\n",
    "        if j == full_bins:\n",
    "            weight = remainder\n",
    "        else:\n",
    "            weight = 1\n",
    "            \n",
    "        if weight == 0:\n",
    "            break\n",
    "            \n",
    "        if phase > 0:\n",
    "            phase_bin = num_phase_coefficients // 2 + j\n",
    "        else:\n",
    "            phase_bin = num_phase_coefficients // 2 - 1 - j\n",
    "            \n",
    "        phase_coefficients[phase_bin] = weight\n",
    "        \n",
    "    fractional_dispersion = phase_coefficients.dot(coefs)\n",
    "    \n",
    "    # Convert to magnitudes\n",
    "    mag_dispersion = frac_to_mag(fractional_dispersion)\n",
    "    \n",
    "    return mag_dispersion\n",
    "\n",
    "phases = np.linspace(-a.phase_width, a.phase_width, 1 + num_phase_coefficients)\n",
    "\n",
    "eval_coefs = np.array([evaluate_phase_dispersion(phase) for phase in phases])\n",
    "\n",
    "# Uncertainties for different wavelengths\n",
    "plt.figure()\n",
    "num_wave = 10\n",
    "for i in range(num_wave):\n",
    "    min_wave = a.wave[0]\n",
    "    max_wave = a.wave[-1]\n",
    "    wave_range = max_wave - min_wave\n",
    "    target_wave = min_wave + wave_range * i / (num_wave - 1)\n",
    "    idx = np.argmin(np.abs(a.wave - target_wave))\n",
    "    use_wave = a.wave[idx]\n",
    "    color = plt.cm.rainbow((use_wave - min_wave) / wave_range)\n",
    "    plt.plot(phases, eval_coefs[:, idx], label='%d $\\AA$' % use_wave, c=color)\n",
    "    \n",
    "plt.xlim(-5.2, 5.2)\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Interpolation uncertainty (mag)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_phase.pdf')\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(phases)):\n",
    "    plt.plot(a.wave, eval_coefs[i], label='%.2f days' % phases[i])\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength $(\\AA$)')\n",
    "plt.ylabel('Interpolation uncertainty (mag)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_wavelength.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_flux = a.interpolation_result['maximum_flux']\n",
    "max_fluxerr = a.interpolation_result['maximum_fluxerr']\n",
    "\n",
    "max_magerr = frac_to_mag(max_fluxerr / max_flux)\n",
    "\n",
    "rbtl_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "\n",
    "def plot_uncertainties(show_rbtl=False):\n",
    "    plt.figure()\n",
    "    offset = 29\n",
    "    \n",
    "    # Make sure that we include the worst offender.\n",
    "    max_loc = np.argmax(np.sum(max_magerr**2, axis=1))\n",
    "    start = max_loc % offset\n",
    "    \n",
    "    for idx in range(start, len(a.targets), offset):\n",
    "        plt.plot(a.wave, max_magerr[idx], label=a.targets[idx].name)\n",
    "    plt.legend(ncol=2)\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    \n",
    "    if show_rbtl:\n",
    "        plt.plot(a.wave, rbtl_dispersion, label='SN intrinsic dispersion', c='k', lw=2, ls='--')\n",
    "        plt.ylabel('Dispersion (mag)')\n",
    "        path = './figures/interpolation_uncertainty_rbtl.pdf'\n",
    "    else:\n",
    "        plt.ylabel('Uncertainty on $f_{max}$ (mag)')\n",
    "        path = './figures/interpolation_uncertainty_norbtl.pdf'\n",
    "        \n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "        \n",
    "plot_uncertainties(False)\n",
    "plot_uncertainties(True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for idx in range(len(a.targets)):\n",
    "    if idx == 0:\n",
    "        label = 'Individual uncertainties of $f_{max}$'\n",
    "    else:\n",
    "        label = ''\n",
    "    plt.plot(a.wave, max_magerr[idx], label=label, alpha=0.02, c='C0')\n",
    "plt.plot(a.wave, rbtl_dispersion, label='Supernova intrinsic dispersion', lw=2, ls='--', c='k')\n",
    "plt.plot(a.wave, np.median(max_magerr, axis=0), label='Median uncertainty on $f_{max}$', lw=2, ls='--', c='C0')\n",
    "plt.plot(a.wave, np.max(max_magerr, axis=0), label='Maximum uncertainty on $f_{max}$', c='C1')\n",
    "plt.legend()\n",
    "plt.ylabel('Dispersion (magnitude)')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_median.pdf')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(a.wave, rbtl_dispersion, label='SN intrinsic dispersion', lw=2, ls='--', c='k')\n",
    "plt.plot(a.wave, np.min(max_magerr, axis=0), label='Minimum $\\sigma_{f,max}$')\n",
    "for percentile in (25, 50, 75):\n",
    "    plt.plot(a.wave, np.percentile(max_magerr, percentile, axis=0), label='%dth percentile $\\sigma_{f,max}$' % percentile)\n",
    "plt.plot(a.wave, np.max(max_magerr, axis=0), label='Maximum $\\sigma_{f,max}$')\n",
    "plt.legend(ncol=2)\n",
    "plt.ylabel('Dispersion (magnitude)')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_percentile.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution to the total interpolation uncertainty from various sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "diffs = []\n",
    "phases_1 = []\n",
    "phases_2 = []\n",
    "x1s = []\n",
    "gray_differences = []\n",
    "\n",
    "gray_offsets = a.interpolation_result['gray_offsets']\n",
    "\n",
    "center_specs = a.spectra[a.center_mask]\n",
    "center_gray_offsets = gray_offsets[a.center_mask]\n",
    "for target_idx in range(len(a.targets)):\n",
    "    near_max_spec = center_specs[target_idx]\n",
    "    \n",
    "    target_mask = (a.target_map == target_idx) & (~a.center_mask)\n",
    "    target_specs = a.spectra[target_mask]\n",
    "    target_gray_offsets = gray_offsets[target_mask]\n",
    "    \n",
    "    for spec_idx, target_spec in enumerate(target_specs):\n",
    "        phase_diff = target_spec.phase - near_max_spec.phase\n",
    "        # if np.abs(phase_diff) < 1:\n",
    "            # continue\n",
    "\n",
    "        targets.append(a.targets[target_idx])\n",
    "        diff = -2.5*np.log10(target_spec.flux / near_max_spec.flux)\n",
    "        diffs.append(diff)\n",
    "        phases_1.append(near_max_spec.phase)\n",
    "        phases_2.append(target_spec.phase)\n",
    "        x1s.append(a.salt_x1[target_idx])\n",
    "        \n",
    "        gray_differences.append(target_gray_offsets[spec_idx] - center_gray_offsets[target_idx])\n",
    "\n",
    "targets = np.array(targets)\n",
    "diffs = np.array(diffs)\n",
    "phases_1 = np.array(phases_1)\n",
    "phases_2 = np.array(phases_2)\n",
    "x1s = np.array(x1s)\n",
    "gray_differences = np.array(gray_differences)\n",
    "\n",
    "phase_diffs = phases_2 - phases_1\n",
    "\n",
    "def plot_diffs(diffs, model_subtracted=False):\n",
    "    sel_mask = np.zeros(len(diffs), dtype=bool)\n",
    "    sel_mask[4::50] = True\n",
    "    sel_mask[np.abs(phase_diffs) < 1] = False\n",
    "    \n",
    "    print(np.min(x1s[sel_mask]))\n",
    "    print(np.max(x1s[sel_mask]))\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    for use_idx in np.where(sel_mask)[0]:\n",
    "        target = targets[use_idx]\n",
    "        phase_1 = phases_1[use_idx]\n",
    "        phase_2 = phases_2[use_idx]\n",
    "        \n",
    "        if phase_1 > phase_2:\n",
    "            phase_1, phase_2 = phase_2, phase_1\n",
    "        \n",
    "        label = '%s, %.1f to %.1f days' % (target, phase_1, phase_2)\n",
    "        \n",
    "        plt.plot(a.wave, diffs[use_idx] / phase_diffs[use_idx], alpha=0.5, label=label)\n",
    "        \n",
    "    plt.legend(ncol=2)\n",
    "\n",
    "    plt.ylim(-0.25, 0.25)\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    if model_subtracted:\n",
    "        plt.ylabel('$\\Delta m / \\Delta t$ (data) - $\\Delta m / \\Delta t$ (model) (mag/day)')\n",
    "    else:\n",
    "        plt.ylabel('$\\Delta m / \\Delta t$ (data) (mag/day)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_diffs(diffs)\n",
    "plt.savefig('./figures/raw_phase_difference.pdf')\n",
    "\n",
    "residuals_no_x1 = []\n",
    "residuals_x1 = []\n",
    "for diff, phase_1, phase_2, x1 in zip(diffs, phases_1, phases_2, x1s):\n",
    "    model_no_x1 = evaluate_phase_difference(phase_2, 0) - evaluate_phase_difference(phase_1, 0)\n",
    "    model_x1 = evaluate_phase_difference(phase_2, x1) - evaluate_phase_difference(phase_1, x1)\n",
    "    residuals_no_x1.append(diff - model_no_x1)\n",
    "    residuals_x1.append(diff - model_x1)\n",
    "    \n",
    "residuals_no_x1 = np.array(residuals_no_x1)\n",
    "residuals_x1 = np.array(residuals_x1)\n",
    "\n",
    "residuals_gray_no_x1 = residuals_no_x1 - gray_differences[:, None]\n",
    "residuals_gray_x1 = residuals_x1 - gray_differences[:, None]\n",
    "\n",
    "plot_diffs(residuals_gray_no_x1, True)\n",
    "plt.savefig('./figures/corr_phase_difference_no_x1.pdf')\n",
    "\n",
    "plot_diffs(residuals_gray_x1, True)\n",
    "plt.savefig('./figures/corr_phase_difference_x1.pdf')\n",
    "\n",
    "def print_interpolation_residuals(min_days, max_days):\n",
    "    cut = (np.abs(phase_diffs) < max_days) & (np.abs(phase_diffs) > min_days)\n",
    "\n",
    "    def do_print(label, vals, cut):\n",
    "        cut_vals = vals[cut]\n",
    "        print('%20s: std=%.3f, NMAD=%.3f' % (label, math.rms(cut_vals), math.nmad(cut_vals)))\n",
    "\n",
    "    print(\"Interpolation of %.1f-%.1f days:\" % (min_days, max_days))\n",
    "    do_print('Raw', diffs, cut)    \n",
    "    do_print('Phase', residuals_no_x1, cut)    \n",
    "    do_print('Phase + x1', residuals_x1, cut)    \n",
    "    do_print('Phase + gray', residuals_gray_no_x1, cut)    \n",
    "    do_print('Phase + x1 + gray', residuals_gray_x1, cut)    \n",
    "    print(\"\")\n",
    "    \n",
    "print_interpolation_residuals(0., 1.5)\n",
    "print_interpolation_residuals(1.5, 2.5)\n",
    "print_interpolation_residuals(2.5, 5.5)\n",
    "print_interpolation_residuals(5.5, 10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.maximum_result['gray_offsets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_slope = a.interpolation_result['phase_slope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading between the lines plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show spectra before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, a.maximum_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "plt.plot(a.wave, a.maximum_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], lw=1.)\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.legend()\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/spectra_at_maximum.pdf')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(a.wave, a.scale_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "plt.plot(a.wave, a.scale_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], alpha=1., lw=1.)\n",
    "plt.plot(a.wave, a.mean_flux * spectrum_plot_scale, c='k', lw=2, ls='--', label='Mean spectrum')\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/scale_spectra.pdf')\n",
    "\n",
    "plt.figure()\n",
    "fractional_dispersion = a.rbtl_result['fractional_dispersion']\n",
    "plt.plot(a.wave, a.mean_flux * spectrum_plot_scale, c='k', lw=2, ls='--', label='Mean spectrum')\n",
    "plt.fill_between(a.wave, a.mean_flux * (1 - fractional_dispersion) * spectrum_plot_scale, a.mean_flux * (1 + fractional_dispersion) * spectrum_plot_scale, label='Supernova intrinsic dispersion', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/scale_spectra_model.pdf')\n",
    "\n",
    "plt.figure()\n",
    "intrinsic_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "plt.plot(a.wave, intrinsic_dispersion, c='k', lw=2, label='Supernova intrinsic dispersion')\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel('Intrinsic dispersion (mag)')\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/rbtl_intrinsic_dispersion.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined version\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(spectrum_plot_figsize[0], spectrum_plot_figsize[1] * 3 - 1.5), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(a.wave, a.maximum_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "ax.plot(a.wave, a.maximum_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], lw=1.)\n",
    "ax.set_ylabel(spectrum_plot_ylabel)\n",
    "ax.legend()\n",
    "ax.set_title('Original spectra')\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(a.wave, a.scale_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "ax.plot(a.wave, a.scale_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], alpha=1., lw=1.)\n",
    "ax.plot(a.wave, a.mean_flux * spectrum_plot_scale, c='k', lw=2, ls='--', label='Mean spectrum')\n",
    "ax.legend()\n",
    "ax.set_ylabel(spectrum_plot_ylabel)\n",
    "ax.set_title('Dereddened spectra')\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "ax = axes[2]\n",
    "intrinsic_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "ax.plot(a.wave, intrinsic_dispersion, c='k', lw=2, label='Supernova intrinsic dispersion')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "ax.set_ylabel('Intrinsic dispersion (mag)')\n",
    "ax.set_title('Recovered intrinsic dispersion')\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/rbtl_spectra_combined.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.interp_mask], a.mags[a.interp_mask], s=15, c='C3', label='Supernovae rejected by cuts')\n",
    "plt.scatter(a.redshifts[a.good_mag_mask], a.mags[a.good_mag_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "plt.axvline(0.02, lw=1, ls='--', c='k', label='Redshift cutoff')\n",
    "\n",
    "plt.xlim(0.001, 0.09)\n",
    "plt.ylim(-1, 1.5)\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('RBTL measured magnitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/rbtl_magnitude.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.interp_mask], a.salt_hr[a.interp_mask], s=15, c='C3', label='Supernovae rejected by cuts')\n",
    "plt.scatter(a.redshifts[a.good_salt_mask], a.salt_hr[a.good_salt_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "plt.axvline(0.02, lw=1, ls='--', c='k', label='Redshift cutoff')\n",
    "\n",
    "plt.xlim(0.001, 0.09)\n",
    "# plt.ylim(-1, 1.5)\n",
    "plt.ylim(-1, 2.)\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('SALT2 measured magnitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/salt_magnitude_redshift.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.good_mag_mask], a.mags[a.good_mag_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('RBTL measured magnitude')\n",
    "\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xlim(0.01, 0.09)\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.savefig('./figures/rbtl_magnitude_cut.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw RBTL mag std:  %.3f mag\" % np.std(a.mags[a.good_mag_mask & a.interp_mask]))\n",
    "print(\"Raw RBTL mag NMAD: %.3f mag\" % math.nmad(a.mags[a.good_mag_mask & a.interp_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.good_mag_mask], a.corr_mags[a.good_mag_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('RBTL corrected magnitude')\n",
    "\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xlim(0.01, 0.09)\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.savefig('./figures/rbtl_corr_magnitude_cut.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold learning plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.scatter(a.embedding[:, 2], vmin=-2, vmax=2, label='Component 3', linewidths=1, edgecolors='k', marker_size=60)\n",
    "a.scatter(a.embedding[:, 2], vmin=-2, vmax=2, label='Component 3')\n",
    "plt.savefig('./figures/embedding_components_12.pdf')\n",
    "a.scatter(a.embedding[:, 1], axis_1=0, axis_2=2, vmin=-3, vmax=3, label='Component 2')\n",
    "plt.savefig('./figures/embedding_components_13.pdf')\n",
    "a.scatter(a.embedding[:, 0], axis_1=1, axis_2=2, vmin=-4, vmax=4, label='Component 1')\n",
    "plt.savefig('./figures/embedding_components_23.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the total variance isn't defined for Isomap. The variances of the transfomed components\n",
    "# do map onto the variance of real components though. We provide a very rough estimate of the\n",
    "# measurement variance for comparison purposes... not sure how much it can be trusted...\n",
    "\n",
    "num_show = 10\n",
    "\n",
    "# Do an initial embedding with as many components as possible to get the full variance.\n",
    "a.generate_embedding(num_components=None)\n",
    "variances = np.var(a.embedding[a.interp_mask], axis=0)\n",
    "\n",
    "ref_var = np.sum(variances[:10])\n",
    "\n",
    "plot_ref = variances[0]\n",
    "\n",
    "print(variances[:10] / plot_ref)\n",
    "print(variances[:10] / np.cumsum(variances[:10]))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(num_show), variances[:num_show] / plot_ref, label='Contributed variance of each component')\n",
    "# plt.scatter(np.arange(num_show), variances[:num_show] / plot_ref, label='Contributed variance of each component')\n",
    "# plt.axhline(0.1 * ref_var / plot_ref, label='Approximate measurement variance cut', ls='--', c='C3')\n",
    "# plt.axhline(np.mean(a.interp_power_fraction[a.interp_mask]) * ref_var / plot_ref, label='Approximate mean measurement variance', ls='--', c='C2')\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel('Component number')\n",
    "plt.ylabel('Relative variance explained')\n",
    "plt.xticks(np.arange(num_show), np.arange(num_show) + 1)\n",
    "# plt.legend(markerfirst=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/isomap_component_variance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a.interp_power_fraction[a.interp_mask])# * ref_var / plot_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twin reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot where twins and non-twins end up for different number of components.\n",
    "# We also make a summary plot.\n",
    "confused_fraction = []\n",
    "\n",
    "plot_components = np.arange(1, 6)\n",
    "for n_components in plot_components:\n",
    "    a.do_embedding(n_components=n_components)\n",
    "    leakage_matrix = a.plot_twin_distances()\n",
    "    if n_components == 1:\n",
    "        title = '1 Component + Color'\n",
    "    else:\n",
    "        title = '%d Components + Color' % n_components\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Recovered twinness percentile in the embedded space')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/twins_recovery_%d_components.pdf' % n_components)\n",
    "    \n",
    "    confused_fraction.append(leakage_matrix[3, 0] + leakage_matrix[3, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(len(confused_fraction)) + 1, confused_fraction)\n",
    "plt.xticks(plot_components, plot_components)\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlabel('Number of components (in addition to color)')\n",
    "plt.ylabel('Fraction of non-twins confused as twins')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/twins_confusion.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot slices through the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the manifold learning embedding...\n"
     ]
    }
   ],
   "source": [
    "a.generate_embedding()\n",
    "\n",
    "def plot_slice(scan_component, closest_count=10, max_dist=1., loc=np.zeros(a.embedding.shape[1] - 1)):\n",
    "    loc = np.asarray(loc)\n",
    "    mask = a.interp_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "\n",
    "    other_embedding = np.delete(use_embedding, scan_component, axis=1)\n",
    "    dists = np.sqrt(np.sum((other_embedding - loc)**2, axis=1))\n",
    "\n",
    "    dist_limit = np.min([np.sort(dists)[closest_count], max_dist])\n",
    "    scan_cut = dists < dist_limit\n",
    "    \n",
    "    scan_embedding = use_embedding[scan_cut, scan_component]\n",
    "    \n",
    "    sort_embedding = np.sort(scan_embedding)\n",
    "    min_comp = sort_embedding[0]\n",
    "    max_comp = sort_embedding[-1]\n",
    "    cmap = plot_cmap\n",
    "\n",
    "    plt.figure(figsize=spectrum_plot_figsize)\n",
    "    for spec, val in zip(use_flux[scan_cut], scan_embedding):\n",
    "        plt.plot(a.wave, spec * spectrum_plot_scale, c=cmap((val - min_comp) / (max_comp - min_comp)))\n",
    "\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_comp, vmax=max_comp))\n",
    "    sm._A = []\n",
    "    plt.colorbar(sm, label='Value of Component %d' % (scan_component + 1))\n",
    "    plt.title('Component %d' % (scan_component + 1))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('./figures/component_%d_effect.pdf' % (scan_component + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(0, loc=[-0.5, -0.5])\n",
    "plot_slice(1)\n",
    "plot_slice(2, loc=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e4547f2ba14d7bbffd279f7a5ee8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot_gp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot steps through component values - combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f14ba621264e1d81866cf45fa4fa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(spectrum_plot_figsize[0], spectrum_plot_figsize[1] * 3 - 1.5), sharex=True)\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "for component in range(3):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask, component]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    ax = axes[component]\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val)\n",
    "        \n",
    "        ax.plot(a.wave, step_flux * spectrum_plot_scale, c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "        \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='2.5%', pad=0.1)\n",
    "    fig.colorbar(sm, cax=cax, orientation='vertical', label='Component Value')\n",
    "    # fig.colorbar(sm, cax=cax, orientation='vertical', label='Value of Component %d' % (component + 1))\n",
    "    # ax.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "    ax.set_title('Component %d' % (component + 1))\n",
    "    \n",
    "    if component == 2:\n",
    "        ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "    \n",
    "    ax.set_ylabel(spectrum_plot_ylabel)\n",
    "    ax.set_ylim(0, None)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/component_steps_combined.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22330f781324b839105d727133ade87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version for talks\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(spectrum_plot_figsize[0], spectrum_plot_figsize[1] * 3 - 1.5), sharex=True)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 7), sharex=True)\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "for component in range(3):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask, component]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    ax = axes[component]\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val)\n",
    "        \n",
    "        ax.plot(a.wave, step_flux * spectrum_plot_scale, c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "        \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='2.5%', pad=0.1)\n",
    "    fig.colorbar(sm, cax=cax, orientation='vertical', label='Component Value')\n",
    "    # fig.colorbar(sm, cax=cax, orientation='vertical', label='Value of Component %d' % (component + 1))\n",
    "    # ax.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "    # ax.set_title('Component %d' % (component + 1))\n",
    "    \n",
    "    if component == 2:\n",
    "        ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "    \n",
    "    # ax.set_ylabel(spectrum_plot_ylabel)\n",
    "    ax.set_ylabel('Flux')\n",
    "    ax.set_ylim(0, None)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/component_steps_combined_talk.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot steps through component values - single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_steps(component, num_steps=10, xlim=None, figsize=spectrum_plot_figsize, colorbar=True):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask, component]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "\n",
    "    if xlim is not None:\n",
    "        wave_mask = (a.wave > xlim[0] - 50) & (a.wave < xlim[1] + 50)\n",
    "    else:\n",
    "        wave_mask = np.ones(len(a.wave), dtype=bool)\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        # if step == 0:\n",
    "            # label = 'Median spectra in each component bin'\n",
    "        # else:\n",
    "            # label = ''\n",
    "            \n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val)\n",
    "        \n",
    "        # plt.plot(a.wave[wave_mask], step_flux[wave_mask], c=sm.to_rgba(mean_val), label=label)\n",
    "        plt.plot(a.wave[wave_mask], step_flux[wave_mask] * spectrum_plot_scale[wave_mask], c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "        \n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "        \n",
    "    if colorbar:\n",
    "        plt.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "        plt.title('Component %d' % (component + 1))\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "    plt.ylim(0, None)\n",
    "    \n",
    "    # plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if xlim is None:\n",
    "        plt.savefig('./figures/component_%d_steps.pdf' % (component + 1))\n",
    "    else:\n",
    "        plt.savefig('./figures/component_%d_steps_zoom_%d_%d.pdf' % (component + 1, xlim[0], xlim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in range(3):\n",
    "    plot_steps(component)\n",
    "    # plot_steps(component, xlim=(3300, 4500))\n",
    "    # plot_steps(component, xlim=(4900, 6700))\n",
    "    # plot_steps(component, xlim=(7200, 8600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Comparison to original twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hannah_list = np.genfromtxt('./data/fakhouri_atmax_list.txt', dtype='str')\n",
    "twins_mask = np.array([i.name in hannah_list for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_twin_pairings()\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/twin_dispersion.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twins that are poor brightness matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "mask = a.good_mag_mask\n",
    "\n",
    "raw_spec_dists = pdist(a.iso_diffs[mask])\n",
    "spec_dists = squareform(raw_spec_dists)\n",
    "mag_diffs = squareform(pdist(a.mags[mask][:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mask = spec_dists < np.percentile(raw_spec_dists, 20)\n",
    "plt.figure()\n",
    "plt.hist(mag_diffs[dist_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1, idx2 = np.where(dist_mask & (mag_diffs > 0.35))\n",
    "idx_mask = idx1 < idx2\n",
    "idx1 = idx1[idx_mask]\n",
    "idx2 = idx2[idx_mask]\n",
    "\n",
    "def print_pairs(vals):\n",
    "    for val_name, val in vals.items():\n",
    "        print(\"%13s_1\" % val_name, \"%13s_2\" % val_name, end='')\n",
    "    print('')\n",
    "        \n",
    "    for i, j in zip(idx1, idx2):\n",
    "        for val_name, val in vals.items():\n",
    "            try:\n",
    "                print('%15.3f' % val[mask][i], '%15.3f' % val[mask][j], end='')\n",
    "            except TypeError:\n",
    "                print('%15s' % val[mask][i], '%15s' % val[mask][j], end='')\n",
    "        print('')\n",
    "\n",
    "print_pairs({\n",
    "    'target': a.targets,\n",
    "    'redshift': a.redshifts,\n",
    "    'color': a.colors,\n",
    "    'mag': a.mags,\n",
    "    'salt_mag': a.salt_hr,\n",
    "    'embedding[0]': a.embedding[:, 0],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision to Branch classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_blondin_plot()\n",
    "plt.savefig('./figures/branch_classification.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot(axis_1=0, axis_2=2)\n",
    "plt.gca().get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot(axis_1=1, axis_2=2)\n",
    "plt.gca().get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot()\n",
    "plt.gca().get_legend().remove()\n",
    "plt.savefig('./figures/branch_labels_isomap.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation of Core Normal SNe Ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = a.get_indicators() \n",
    "\n",
    "s1 = indicators[\"EWSiII6355\"]\n",
    "s2 = indicators[\"EWSiII5972\"]\n",
    "\n",
    "component = 0\n",
    "\n",
    "core_normal_cut = (s2 < 30) & (s1 > 70) & (s1 < 100) & ~np.isnan(a.embedding[:, component])\n",
    "\n",
    "cut_flux = a.scale_flux[core_normal_cut]\n",
    "cut_coord = a.embedding[core_normal_cut][:, component]\n",
    "\n",
    "sort_flux = cut_flux[np.argsort(cut_coord)]\n",
    "sort_coord = cut_coord[np.argsort(cut_coord)]\n",
    "\n",
    "num_bins = 5\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=np.percentile(cut_coord, 100 / num_bins / 2), vmax=np.percentile(cut_coord, 100 * (1 - 1. / num_bins / 2))))\n",
    "sm._A = []\n",
    "\n",
    "def plot_spec(bin_idx):\n",
    "    min_idx = int(len(sort_coord) / num_bins * bin_idx)\n",
    "    max_idx = int(len(sort_coord) / num_bins * (bin_idx + 1))\n",
    "    bin_flux = sort_flux[min_idx:max_idx]\n",
    "    \n",
    "    f = np.median(bin_flux, axis=0)\n",
    "    \n",
    "    mean_val = np.mean(sort_coord[min_idx:max_idx])\n",
    "    \n",
    "    plt.plot(a.wave, f * spectrum_plot_scale, c=sm.to_rgba(mean_val), zorder=np.abs(mean_val))\n",
    "    \n",
    "plt.figure(figsize=spectrum_plot_figsize)\n",
    "for i in range(num_bins):\n",
    "    plot_spec(i)\n",
    "plt.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/core_normal_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering other indicators of intrinsic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an array to hold everything\n",
    "all_indicators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral features\n",
    "indicators = a.spectral_indicators\n",
    "\n",
    "name_map = {\n",
    "    'EWCaIIHK': 'pEW Ca II HK',\n",
    "    'EWSiII4000': 'pEW Si II 4000',#$\\AA$',\n",
    "    'EWSiII5972': 'pEW Si II 5972',#$\\AA$',\n",
    "    'EWSiII6355': 'pEW Si II 6355',#$\\AA$',\n",
    "    'vCaIIHK': 'Velocity Ca II HK',\n",
    "    'vSiII6355': 'Velocity Si II 6355',#$\\AA$',\n",
    "    'lamCaIIHK': 'Lambda Ca II HK',\n",
    "    'lamSiII6355': 'Lambda Si II 6355',#$\\AA$',\n",
    "}\n",
    "\n",
    "for key in indicators.keys():\n",
    "    values = indicators[key]\n",
    "\n",
    "    if key[:3] == 'lam':\n",
    "        continue\n",
    "        \n",
    "    if key[:1] == 'v':\n",
    "        # Use km/s and make everything positive.\n",
    "        values = values / -1000\n",
    "\n",
    "    all_indicators.append((name_map[key], values, a.uncertainty_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALT2 X1\n",
    "all_indicators.append(('SALT2 $x_1$', a.salt_x1, a.salt_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Sugar parameters\n",
    "pickle_data =  open('./data/sugar_parameters.pkl').read().replace('\\r\\n', '\\n').encode('latin1')\n",
    "sugar_data = pickle.loads(pickle_data, encoding='latin1')\n",
    "\n",
    "sugar_rows = []\n",
    "for target in a.targets:\n",
    "    try:\n",
    "        row = sugar_data[target.name.encode('latin1')]\n",
    "        sugar_rows.append([row['q1'], row['q2'], row['q3']])\n",
    "    except KeyError:\n",
    "        sugar_rows.append([np.nan] * 3)\n",
    "\n",
    "sugar_embedding = np.array(sugar_rows, dtype=float)\n",
    "sugar_mask = ~np.isnan(sugar_embedding[:, 0])\n",
    "\n",
    "for component in range(3):\n",
    "    all_indicators.append(('SUGAR Component %d\\n(Leget et al. 2019)' % (component + 1), sugar_embedding[:, component], sugar_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nordin colors\n",
    "nordin_bands = {\n",
    "    'uNi': (3300., 3510.),\n",
    "    'uTi': (3510., 3660.),\n",
    "    'uSi': (3660., 3760.),\n",
    "    'uCa': (3750., 3860.),\n",
    "}\n",
    "\n",
    "for label, (wave_min, wave_max) in nordin_bands.items():\n",
    "    cut = (a.wave > wave_min) & (a.wave < wave_max)\n",
    "    \n",
    "    values = -2.5*np.log10(np.sum(a.scale_flux[:, cut], axis=1) / np.sum(a.mean_flux[cut]))\n",
    "    \n",
    "    all_indicators.append(('U-band variation—%s\\n(Nordin et al. 2018)' % label, values, a.uncertainty_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNEMO parameters\n",
    "import pandas as pd\n",
    "snemo_data = pd.read_csv('./data/snemo_salt_coefficients_snf.csv').set_index('SN')\n",
    "\n",
    "nan_row = snemo_data.iloc[0].copy()\n",
    "nan_row[:] = np.nan\n",
    "\n",
    "snemo_rows = []\n",
    "for target in a.targets:\n",
    "    try:\n",
    "        row = snemo_data.loc[target.name]\n",
    "        snemo_rows.append(row)\n",
    "    except KeyError:\n",
    "        snemo_rows.append(nan_row)\n",
    "\n",
    "snemo_embedding = pd.DataFrame(snemo_rows)\n",
    "snemo_mask = ~np.isnan(snemo_embedding['salt_c'])\n",
    "snemo_labels = snemo_data.columns\n",
    "\n",
    "# SNEMO 2\n",
    "all_indicators.append(('SNEMO2 Component 1\\n(Saunders et al. 2018)', snemo_embedding['snemo2_c1'], snemo_mask))\n",
    "\n",
    "# SNEMO 7\n",
    "for component in range(6):\n",
    "    all_indicators.append(('SNEMO7 Component %d' % (component + 1), snemo_embedding[f'snemo7_c{component+1}'], snemo_mask))\n",
    "    \n",
    "# SNEMO 15\n",
    "# for component in range(14):\n",
    "    # all_indicators.append(('SNEMO15 Component %d' % (component + 1), snemo_embedding[f'snemo15_c{component+1}'], snemo_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def find_rotation(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def to_min(x):\n",
    "        diff = values - a.embedding.dot(x[1:]) - x[0]\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0, 0, 0, 0])\n",
    "\n",
    "    rotation = res.x[1:] / np.sqrt(np.sum(res.x[1:]**2))\n",
    "    best_guess = a.embedding.dot(res.x[1:]) + res.x[0]\n",
    "    \n",
    "    return rotation, best_guess\n",
    "\n",
    "def find_rotation_quadratic(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def evaluate(x):\n",
    "        e = a.embedding.T\n",
    "        \n",
    "        model = (\n",
    "            x[0]\n",
    "            + e[0] * x[1]\n",
    "            + e[1] * x[2]\n",
    "            + e[2] * x[3]\n",
    "            + e[0] * e[0] * x[4]\n",
    "            + e[1] * e[1] * x[5]\n",
    "            + e[2] * e[2] * x[6]\n",
    "            + e[0] * e[1] * x[7]\n",
    "            + e[0] * e[2] * x[8]\n",
    "            + e[1] * e[2] * x[9]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def to_min(x):\n",
    "        model = evaluate(x)\n",
    "        diff = values - model\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0] * 10)\n",
    "\n",
    "    best_guess = evaluate(res.x)\n",
    "    \n",
    "    return res.x, best_guess\n",
    "\n",
    "names = []\n",
    "data = []\n",
    "\n",
    "for name, values, mask in all_indicators[::-1]:\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    \n",
    "    params_quadratic, best_guess_quadratic = find_rotation_quadratic(values, mask)\n",
    "    corrcoef_quadratic = np.corrcoef(best_guess_quadratic[mask], values[mask])[0, 1]\n",
    "    \n",
    "    names.append(name)\n",
    "    data.append(np.hstack([rotation, corrcoef, corrcoef_quadratic]))\n",
    "\n",
    "    # print(f'{name} & {rotation[0]:.2f} & {rotation[1]:.2f} & {rotation[2]:.2f} & {corrcoef:.2f}')\n",
    "    \n",
    "data = np.array(data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5.0, 8))\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-1, vmax=1))\n",
    "sm._A = []\n",
    "\n",
    "def do_plot(ax, ax_data, xlabels, ylabels=None):\n",
    "    im = ax.imshow(ax_data, interpolation='nearest', cmap=cmap, vmin=-1, vmax=1)\n",
    "    ax.set(\n",
    "        xticks=np.arange(ax_data.shape[1]),\n",
    "        yticks=np.arange(ax_data.shape[0]),\n",
    "        xticklabels=xlabels,\n",
    "    )\n",
    "\n",
    "    if ylabels is not None:\n",
    "        ax.set_yticklabels(ylabels)\n",
    "    else:\n",
    "        ax.tick_params(axis='y', which='both', left=False, right=False)\n",
    "\n",
    "    ax.set_xlim(-0.5, ax_data.shape[1] - 0.5)\n",
    "    ax.set_ylim(-0.5, ax_data.shape[0] - 0.5)\n",
    "\n",
    "    # Ticks on top\n",
    "    ax.get_xaxis().set_ticks_position('top')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=70, ha=\"left\", va='center',\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.65\n",
    "    for i in range(ax_data.shape[0]):\n",
    "        for j in range(ax_data.shape[1]):\n",
    "            ax.text(j, i, format(ax_data[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if np.abs(ax_data[i, j]) > thresh else \"black\")\n",
    "            \n",
    "do_plot(axes[0], data[:, :3], ['Component 1 Rotation', 'Component 2 Rotation', 'Component 3 Rotation'], names)\n",
    "do_plot(axes[1], data[:, 3:], ['Linear Transformation\\nPearson Correlation', 'Quadratic Transformation\\nPearson Correlation'])\n",
    "\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes('right', size='30%', pad=0.23)\n",
    "fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/indicators_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "        \n",
    "    min_val = np.min([values[mask], best_guess[mask]])\n",
    "    max_val = np.max([values[mask], best_guess[mask]])\n",
    "    val_range = max_val - min_val\n",
    "    \n",
    "    plt.figure(figsize=(4, 3.8))\n",
    "    plt.scatter(best_guess[mask], values[mask])\n",
    "    \n",
    "    plt.text(min_val + 0.*val_range, max_val - 0.02*val_range, \"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    print(\"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    \n",
    "    plt.plot([min_val - val_range, min_val + val_range], [min_val - val_range, min_val + val_range], c='k', ls='--')\n",
    "\n",
    "    plt.xlabel('Transformation of the Isomap latent space')\n",
    "    \n",
    "    plt.ylabel(name)\n",
    "    # plt.ylabel(\"Original measurement\")\n",
    "    # plt.title(name)\n",
    "    \n",
    "    plt.xlim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.ylim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1), quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "        \n",
    "    min_val = np.min([values[mask], best_guess[mask]])\n",
    "    max_val = np.max([values[mask], best_guess[mask]])\n",
    "    val_range = max_val - min_val\n",
    "    \n",
    "    plt.figure(figsize=(2.5, 2.7))\n",
    "    plt.scatter(best_guess[mask], values[mask], s=10)\n",
    "    \n",
    "    plt.text(min_val + 0.*val_range, max_val - 0.04*val_range, \"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    print(\"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    \n",
    "    plt.plot([min_val - val_range, min_val + val_range], [min_val - val_range, min_val + val_range], c='k', ls='--')\n",
    "\n",
    "    # plt.xlabel('Transformation of the Isomap latent space')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # plt.ylabel(name)\n",
    "    # plt.ylabel(\"Original measurement\")\n",
    "    plt.title(name.split('\\n')[0])\n",
    "    \n",
    "    plt.xlim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.ylim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.tight_layout()\n",
    "\n",
    "interact(plot_component, idx=(0, len(data) - 1), quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    plot_component(i, quadratic=True)\n",
    "    plt.savefig('./figures/rotation_%d.png' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('SALT2 $x_1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.text(-0.3, 0.6, 'hi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component(6, quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(best_guess[mask], values[mask])\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Transformation of the Isomap latent space')\n",
    "    plt.ylabel(name)\n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for AAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1, mask=a.salt_mask, label='SALT2 $x_1$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Figure out what happened with SNBOSS38. Somehow the SALT2 fit is way off, but it doesn't fail the SALT2 fit cuts. Reject in manually for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[a.salt_mask, 1], a.salt_x1[a.salt_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (a.embedding[:, 0] > 2) & (a.embedding[:, 1] > 1) & (a.embedding[:, 1] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.where(mask)[0]:\n",
    "    print(a.targets[i], a.embedding[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.salt_mask[(a.salt_x1 > 1) & (a.embedding[:, 1] > 1)] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.salt_hr[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tt[2].fit_salt(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out what correlation coefficient we would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrcoef_linear = []\n",
    "all_corrcoef_quadratic = []\n",
    "\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    mask = a.interp_mask\n",
    "    values = np.random.normal(size=len(values))\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    all_corrcoef_linear.append(corrcoef)\n",
    "    \n",
    "    rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    all_corrcoef_quadratic.append(corrcoef)\n",
    "\n",
    "with open('./latex/correlation_simulation.tex', 'w') as f:\n",
    "    latex_command(f, 'correlationmeanlinear', '%.2f', np.mean(all_corrcoef_linear))\n",
    "    latex_command(f, 'correlationstdlinear', '%.2f', np.std(all_corrcoef_linear))\n",
    "    latex_command(f, 'correlationmeanquadratic', '%.2f', np.mean(all_corrcoef_quadratic))\n",
    "    latex_command(f, 'correlationstdquadratic', '%.2f', np.std(all_corrcoef_quadratic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot rotated spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_steps(idx, quadratic=False):\n",
    "    num_steps = 10\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.interp_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    use_embedding = best_guess[mask]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    plt.figure(figsize=spectrum_plot_figsize)\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        plt.plot(a.wave, step_flux * spectrum_plot_scale, c=sm.to_rgba(mean_val))\n",
    "        \n",
    "    plt.colorbar(sm, label='Rotated Isomap vSi II 6355$\\AA$\\nEstimate ($10^3$ km/s)')\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "    plt.ylim(0, None)\n",
    "    plt.title(name)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "interact(plot_steps, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear combinations of SUGAR components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indicators.append(('Isomap Component 1', a.embedding[:, 0], a.interp_mask))\n",
    "all_indicators.append(('Isomap Component 2', a.embedding[:, 1], a.interp_mask))\n",
    "all_indicators.append(('Isomap Component 3', a.embedding[:, 2], a.interp_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def find_rotation(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def to_min(x):\n",
    "        diff = values - sugar_embedding.dot(x[1:]) - x[0]\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0, 0, 0, 0])\n",
    "\n",
    "    rotation = res.x[1:] / np.sqrt(np.sum(res.x[1:]**2))\n",
    "    best_guess = sugar_embedding.dot(res.x[1:]) + res.x[0]\n",
    "    \n",
    "    return rotation, best_guess\n",
    "\n",
    "def find_rotation_quadratic(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def evaluate(x):\n",
    "        e = sugar_embedding.T\n",
    "        \n",
    "        model = (\n",
    "            x[0]\n",
    "            + e[0] * x[1]\n",
    "            + e[1] * x[2]\n",
    "            + e[2] * x[3]\n",
    "            + e[0] * e[0] * x[4]\n",
    "            + e[1] * e[1] * x[5]\n",
    "            + e[2] * e[2] * x[6]\n",
    "            + e[0] * e[1] * x[7]\n",
    "            + e[0] * e[2] * x[8]\n",
    "            + e[1] * e[2] * x[9]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def to_min(x):\n",
    "        model = evaluate(x)\n",
    "        diff = values - model\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0] * 10)\n",
    "\n",
    "    best_guess = evaluate(res.x)\n",
    "    \n",
    "    return res.x, best_guess\n",
    "\n",
    "names = []\n",
    "data = []\n",
    "\n",
    "for name, values, mask in all_indicators[::-1]:\n",
    "    mask = mask & sugar_mask\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    \n",
    "    params_quadratic, best_guess_quadratic = find_rotation_quadratic(values, mask)\n",
    "    corrcoef_quadratic = np.corrcoef(best_guess_quadratic[mask], values[mask])[0, 1]\n",
    "    \n",
    "    names.append(name)\n",
    "    data.append(np.hstack([rotation, corrcoef, corrcoef_quadratic]))\n",
    "\n",
    "    # print(f'{name} & {rotation[0]:.2f} & {rotation[1]:.2f} & {rotation[2]:.2f} & {corrcoef:.2f}')\n",
    "    \n",
    "data = np.array(data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5.0, 8))\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-1, vmax=1))\n",
    "sm._A = []\n",
    "\n",
    "def do_plot(ax, ax_data, xlabels, ylabels=None):\n",
    "    im = ax.imshow(ax_data, interpolation='nearest', cmap=cmap, vmin=-1, vmax=1)\n",
    "    ax.set(\n",
    "        xticks=np.arange(ax_data.shape[1]),\n",
    "        yticks=np.arange(ax_data.shape[0]),\n",
    "        xticklabels=xlabels,\n",
    "    )\n",
    "\n",
    "    if ylabels is not None:\n",
    "        ax.set_yticklabels(ylabels)\n",
    "    else:\n",
    "        ax.tick_params(axis='y', which='both', left=False, right=False)\n",
    "\n",
    "    ax.set_xlim(-0.5, ax_data.shape[1] - 0.5)\n",
    "    ax.set_ylim(-0.5, ax_data.shape[0] - 0.5)\n",
    "\n",
    "    # Ticks on top\n",
    "    ax.get_xaxis().set_ticks_position('top')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=70, ha=\"left\", va='center',\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.65\n",
    "    for i in range(ax_data.shape[0]):\n",
    "        for j in range(ax_data.shape[1]):\n",
    "            ax.text(j, i, format(ax_data[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if np.abs(ax_data[i, j]) > thresh else \"black\")\n",
    "            \n",
    "do_plot(axes[0], data[:, :3], ['Component 1 Rotation', 'Component 2 Rotation', 'Component 3 Rotation'], names)\n",
    "do_plot(axes[1], data[:, 3:5], ['Linear Rotation\\nPearson Correlation', 'Quadratic Rotation\\nPearson Correlation'])\n",
    "\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes('right', size='30%', pad=0.23)\n",
    "fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/indicators_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & sugar_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(best_guess[mask], values[mask], c=a.colors[mask], vmin=-0.2, vmax=0.2)\n",
    "    plt.title(name)\n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81729f79fb3a412ca16c44d0abe16f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.scatter(a.rbtl_colors, vmin=-0.3, vmax=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(-0.54*sugar_embedding[:, 0] + 0.84 * sugar_embedding[:, 2], a.salt_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[:, 1], a.colors, c=a.embedding[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d09d8a3b4ff4b60ba5426b1e9e4b288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.29906577117714916"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "m = (a.redshifts > 0.02) & (a.redshift_errs < 0.004) & (a.uncertainty_mask)\n",
    "plt.scatter(a.rbtl_colors[m] - np.median(a.rbtl_colors[m]), a.corr_mags[m])\n",
    "\n",
    "np.std(a.corr_mags[m & (a.rbtl_colors - np.median(a.rbtl_colors) > 0.5) & a.train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7725ea4f6709435ba4d662c9b926ed12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52fc124250>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, np.sqrt(np.mean(utils.frac_to_mag((a.maximum_fluxerr / a.maximum_flux)[a.uncertainty_mask])**2, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf881773d6487d8b54654064fadbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52fd013a50>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, 1/a.rbtl_result['fractional_dispersion']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bb5b6c4e2f4a9aae89dd44b6944f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f52fdc02890>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[a.uncertainty_mask, 0], a.embedding[a.uncertainty_mask, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.spectra[(a.trans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f52fd9e05d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(0.548, -0.830)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((a.rbtl_colors - np.median(a.rbtl_colors)) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Target(name=\"LSQ12gxj\"), Target(name=\"PTF10wnm\")], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.targets[dists < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5ad6fee4d34826b509b3ac214dd20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52fd7e3e10>,\n",
       " <matplotlib.lines.Line2D at 0x7f52fd6d6350>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, a.scale_flux[dists < 0.1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dists = np.sum((a.embedding - a.embedding[m & (a.corr_mags > 0.5)])**2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 91T/91bg labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_labels = {\n",
    "    # Scalzo++ 2014\n",
    "    \"SNF20070528-003\": \"91T-like\",\n",
    "    \"SNF20070803-005\": \"91T-like\",\n",
    "    \"SNF20070825-001\": \"91T-like\",\n",
    "    \"SNF20070912-000\": \"91T-like\",\n",
    "    \"SNF20080522-000\": \"91T-like\",\n",
    "    \"SNF20080723-012\": \"91T-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"SNF20080805-007\": \"91T-like\",\n",
    "    \"LSQ12cyz\": \"91T-like\",\n",
    "    \"LSQ12fhe\": \"91T-like\",\n",
    "    \"PTF11bju\": \"91T-like\",\n",
    "    \"PTF11mkx\": \"91T-like\",\n",
    "    \"LSQ12cfx\": \"91bg-like\",\n",
    "    \n",
    "    # Discussion between Kyle and Greg:\n",
    "    \"SNNGC2691\": \"91T-like\",\n",
    "    \n",
    "    # Maguire++ 2011\n",
    "    \"PTF10ops\": \"91bg-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"PTF11bkf\": \"91bg-like\",\n",
    "    \"PTF11kjn\": \"91bg-like\",\n",
    "    \"PTF11okh\": \"91bg-like\",\n",
    "    \"PTF11pra\": \"91bg-like\",\n",
    "    \"PTF12dwm\": \"91bg-like\",\n",
    "    \"SN2005bl\": \"91bg-like\",\n",
    "    \"SN2005dh\": \"91bg-like\",\n",
    "    \"SN2005dm\": \"91bg-like\",\n",
    "    \"SN2007ba\": \"91bg-like\",\n",
    "    \"SN2009hs\": \"91bg-like\",\n",
    "    \"SNNGC6430\": \"91bg-like\",\n",
    "    \"SN2005cc\": \"02cx-like\",\n",
    "    \n",
    "    # Foley++ 2013\n",
    "    \"SN2011ay\": \"02cx-like\",\n",
    "    \"LSQ12fhs\": \"02cx-like\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Target(name=\"LSQ12fhs\"), Target(name=\"SN2011ay\"),\n",
       "       Target(name=\"SNF20070528-003\")], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.targets[a.embedding[:, 0] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41be8fd0cd04af8bae99140877b0b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "colors = []\n",
    "labels = []\n",
    "for idx, sn in enumerate(a.targets):\n",
    "    if not a.uncertainty_mask[idx]:\n",
    "        continue\n",
    "\n",
    "    label = outlier_labels.get(sn.name, 'Other')\n",
    "    if label == 'Other':\n",
    "        c = 'silver'\n",
    "    elif label == '91bg-like':\n",
    "        c = 'C0'\n",
    "    elif label == '91T-like':\n",
    "        c = 'C2'\n",
    "    elif label == '02cx-like':\n",
    "        c = 'C3'\n",
    "        \n",
    "    if c in colors:\n",
    "        plot_label = ''\n",
    "    else:\n",
    "        plot_label = label\n",
    "\n",
    "    colors.append(c)\n",
    "    \n",
    "    plt.scatter(a.embedding[idx, 0], a.embedding[idx, 1], label=plot_label, facecolors=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.targets[np.array([i.name == 'SNF20070825-001' for i in a.targets])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2f868b104446babae1e476470ce58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_91t = np.array([outlier_labels.get(i.name, 'aa') == '91T-like' for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mask_91t & a.uncertainty_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mask_91t & a.redshift_color_mask & a.uncertainty_mask & a.train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.corr_mags, mask=a.good_mag_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.where((a.embedding[:, 0] > 4) & (a.embedding[:, 1] > -1.5))[0]:\n",
    "    target = a.targets[idx]\n",
    "    print(a.embedding[idx], target, outlier_labels.get(target.name, 'Other'), a.corr_mags[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.mags, a.good_mag_mask, vmin=-0.2, vmax=0.2, label='Residual magnitude', invert_colorbar=True)\n",
    "plt.savefig('./figures/components_12_residual_magnitude.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.mags, a.good_mag_mask, vmin=-0.2, vmax=0.2, axis_1=0, axis_2=2, label='Residual magnitude', invert_colorbar=True)\n",
    "plt.savefig('./figures/components_13_residual_magnitude.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.mags, a.good_mag_mask, vmin=-0.2, vmax=0.2, axis_1=1, axis_2=2, label='Residual magnitude', invert_colorbar=True)\n",
    "plt.savefig('./figures/components_23_residual_magnitude.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to defaults in case things got messed up\n",
    "a.do_embedding()\n",
    "a.fit_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_gp(axis_1=0, axis_2=1)\n",
    "plt.savefig('./figures/gp_mag_components_12.pdf')\n",
    "\n",
    "a.plot_gp(axis_1=0, axis_2=2)\n",
    "plt.savefig('./figures/gp_mag_components_13.pdf')\n",
    "\n",
    "a.plot_gp(axis_1=1, axis_2=2)\n",
    "plt.savefig('./figures/gp_mag_components_23.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check vs phases of original spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Get the mean phase for every target.\n",
    "mean_phases = []\n",
    "for i in range(len(a.targets)):\n",
    "    mean_phases.append(np.mean(a.salt_phases[a.target_map == i]))\n",
    "mean_phases = np.array(mean_phases)\n",
    "\n",
    "# plt.scatter(a.salt_phases[a.center_mask][a.good_mag_mask], a.corr_mags[a.good_mag_mask], label='Individual observations')\n",
    "# math.plot_binned_mean(a.salt_phases[a.center_mask][a.good_mag_mask], a.corr_mags[a.good_mag_mask], c='C2', label='Binned mean')\n",
    "plt.scatter(mean_phases[a.good_mag_mask], a.corr_mags[a.good_mag_mask], label='Individual observations')\n",
    "math.plot_binned_mean(mean_phases[a.good_mag_mask], a.corr_mags[a.good_mag_mask], c='C2', label='Binned mean')\n",
    "# plt.xlabel('Phase of closest spectrum to maximum (days)')\n",
    "plt.xlabel('Mean phase of observed spectra (days)')\n",
    "plt.ylabel('Residual magnitude')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALT2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SALT2 Hubble residuals\n",
    "a.calculate_salt_hubble_residuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.salt_color, a.colors, s=5)\n",
    "plt.xlabel('SALT2 Color ($c$)')\n",
    "plt.ylabel('RBTL Color ($A_V$)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/salt2_color_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1, a.interp_mask, label='SALT $x_1$')\n",
    "plt.savefig('./figures/salt2_x1_components_full.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1, a.interp_mask & a.good_salt_mask, axis_1=0, axis_2=1, label='SALT $x_1$', vmin=-2., vmax=1.5)\n",
    "plt.savefig('./figures/salt2_x1_components.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_gp(kind='salt_raw', vmin=-0.5, vmax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best predictor of x1\n",
    "def to_min(x):\n",
    "    diff = a.salt_x1 - a.embedding.dot(x)\n",
    "    return np.nanstd(diff[a.salt_mask])\n",
    "\n",
    "res = minimize(to_min, [0, 0, 0])\n",
    "\n",
    "norm_x = res.x / np.sqrt(np.sum(res.x**2))\n",
    "print(norm_x)\n",
    "\n",
    "plt.figure()\n",
    "# plt.scatter(a.embedding.dot(res.x), a.salt_x1, c=a.salt_mask)\n",
    "plt.scatter(a.embedding.dot(res.x)[~a.salt_mask], a.salt_x1[~a.salt_mask], c='C3', s=30, label='\"Bad\" SALT2 fits', alpha=0.8)\n",
    "plt.scatter(a.embedding.dot(res.x)[a.salt_mask], a.salt_x1[a.salt_mask], c='C0', s=30, label='\"Good\" SALT2 fits', alpha=0.8)\n",
    "plt.plot([-3, 3], [-3, 3], ls='--', c='k', label='One-to-one line')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel('Rotated Isomap components')\n",
    "plt.ylabel('SALT2 $x_1$')\n",
    "plt.legend()\n",
    "plt.savefig('./figures/rotated_isomap_salt_x1.pdf')\n",
    "\n",
    "\n",
    "print(np.corrcoef(a.embedding.dot(res.x)[a.interp_mask & a.salt_mask], a.salt_x1[a.interp_mask & a.salt_mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 outliers (Type Iax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iax_mask = (a.embedding[:, 0] > 4.) & (a.embedding[:, 1] < -3)\n",
    "a.targets[iax_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier spectra\n",
    "mask = (a.embedding[:, 0] > 4) & (a.embedding[:, 1] < -2)\n",
    "print(a.targets[mask])\n",
    "print(a.colors[mask])\n",
    "print(a.redshifts[mask])\n",
    "print(a.mags[mask])\n",
    "\n",
    "# Ref spectrum\n",
    "ref_target = 'SNF20070803-005'\n",
    "for idx2, target in enumerate(a.targets):\n",
    "    if target.name == ref_target:\n",
    "        break\n",
    "        \n",
    "# idx2 = np.where((a.embedding[:, 0] > 4.8) & (a.embedding[:, 1] < 2))[0][0]\n",
    "\n",
    "plt.figure()\n",
    "for i in np.where(mask)[0]:\n",
    "    plt.plot(a.wave, a.scale_flux[i] * spectrum_plot_scale, label=a.targets[i].name)\n",
    "    \n",
    "plt.plot(a.wave, a.scale_flux[idx2] * spectrum_plot_scale, c='k', ls='--', label=a.targets[idx2].name)\n",
    "print(a.embedding[idx2])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/type_iax_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.targets[(a.embedding[:, 1] > 4.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier spectra\n",
    "mask = (a.embedding[:, 0] < -4)\n",
    "print(a.targets[mask])\n",
    "print(a.colors[mask])\n",
    "print(a.redshifts[mask])\n",
    "print(a.mags[mask])\n",
    "\n",
    "# Ref spectrum\n",
    "# ref_target = 'SNF20070803-005'\n",
    "# for idx2, target in enumerate(a.targets):\n",
    "    # if target.name == ref_target:\n",
    "        # break\n",
    "        \n",
    "# idx2 = np.where((a.embedding[:, 0] > 4.8) & (a.embedding[:, 1] < 2))[0][0]\n",
    "\n",
    "plt.figure()\n",
    "for i in np.where(mask)[0]:\n",
    "    plt.plot(a.wave, a.scale_flux[i] * spectrum_plot_scale, label=a.targets[i].name)\n",
    "    \n",
    "# plt.plot(a.wave, a.scale_flux[idx2] * spectrum_plot_scale, c='k', ls='--', label=a.targets[idx2].name)\n",
    "print(a.embedding[idx2])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('./figures/type_iax_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 magnitudes vs components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_hr, mask=a.salt_mask & a.redshift_color_mask & a.uncertainty_mask, vmin=-0.3, vmax=0.3, label='SALT2-corrected residual magnitude', invert_colorbar=True)\n",
    "# a.scatter(a.salt_hr, mask=a.good_salt_mask & a.interp_mask, vmin=-0.3, vmax=0.3, label='SALT2 Hubble residuals', invert_colorbar=True)\n",
    "plt.savefig('./figures/salt2_hr_components.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "use_x = a.embedding[:, 0]\n",
    "\n",
    "mask = a.salt_mask & a.redshift_color_mask & a.uncertainty_mask\n",
    "plt.errorbar(use_x[mask], a.salt_hr[mask], a.salt_hr_uncertainties[mask], label='Individual supernovae', fmt='.', alpha=0.2, c='k')\n",
    "math.plot_binned_mean(use_x[mask], a.salt_hr[mask], c='C3', lw=2, label='Binned mean')\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('SALT2 Hubble residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/salt2_hr_component_1.pdf')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(a.salt_hr[(use_x < 2) & mask], 10, (-0.6, 0.4), alpha=0.3, color='C0', label='Component 1 < 2', density=True)\n",
    "plt.hist(a.salt_hr[(use_x < 2) & mask], 10, (-0.6, 0.4), histtype='step', lw=2, color='C0', density=True)\n",
    "plt.hist(a.salt_hr[(use_x > 2) & mask], 10, (-0.6, 0.4), alpha=0.3, color='C1', label='Component 1 > 2', density=True)\n",
    "plt.hist(a.salt_hr[(use_x > 2) & mask], 10, (-0.6, 0.4), histtype='step', lw=2, color='C1', density=True)\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "plt.xlabel('SALT2 residual magnitude')\n",
    "plt.ylabel('Normalized counts')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/salt2_hr_hist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 + Isomap standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Desired error not necessarily achieved due to precision loss.\n",
      "    Color scale:          3.108 ± 0.211\n",
      "    Intrinsic dispersion: 0.090 ± 0.014 mag\n",
      "    GP kernel amplitude:  0.358 ± 0.203 mag\n",
      "    GP length scale:      7.316 ± 4.765\n",
      "    Fit NMAD:             0.095 mag\n",
      "    Fit std:              0.119 mag\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cf5e93fb7c49a5b9b2e1afff760587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.fit_gp(kind='salt_raw')\n",
    "a.plot_gp(kind='salt_raw', vmin=-0.5, vmax=0.5)\n",
    "\n",
    "plt.savefig('./figures/salt_gp_component_12.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b10757c1d54400b26f8e35ef6504ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'ManifoldTwinsAnalysis' object has no attribute 'good_salt_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-4c0895442f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgood_salt_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalt_x1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr_mags\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalt_hr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoolwarm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert_yaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Value of Isomap component 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ManifoldTwinsAnalysis' object has no attribute 'good_salt_mask'"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "m = a.good_salt_mask & a.interp_mask\n",
    "plt.scatter(a.salt_x1[m], (a.corr_mags - a.salt_hr)[m], c=a.embedding[m, 0], cmap=plt.cm.coolwarm, vmin=-3, vmax=3)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar(label='Value of Isomap component 1')\n",
    "plt.xlabel('SALT2 $x_1$')\n",
    "plt.ylabel('Difference between SALT2 and\\nSALT2 + Isomap standardization (mag)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/salt_isomap_difference.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo the original GP fit to put the analysis back in the original state\n",
    "a.fit_gp(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'BOSS38'\n",
    "\n",
    "for j, i in enumerate(a.targets):\n",
    "    if target in i.name:\n",
    "        idx = j\n",
    "        break\n",
    "else:\n",
    "    raise Exception(f\"No target {target} found!\")\n",
    "    \n",
    "print(f\"target:        {a.targets[idx].name}\")\n",
    "print(f\"isomap coord:  {a.embedding[idx]}\")\n",
    "print(f\"SALT x1:       {a.salt_x1[idx]}\")\n",
    "\n",
    "gp_pred = a.predict_gp(a.embedding[idx], a.salt_color[idx], kind='salt_raw')[0]\n",
    "# salt_pred = a.salt_alpha * a.salt_x1[idx] - a.salt_beta * a.salt_color[idx]\n",
    "salt_pred = a.salt_hr_raw[idx] - a.salt_hr[idx]\n",
    "\n",
    "print(f\"GP prediction: {gp_pred}\")\n",
    "print(f\"SALT2 pred:    {salt_pred}\")\n",
    "print(f\"pred diff:     {salt_pred - gp_pred}\")\n",
    "\n",
    "# print(f\"HR difference: {(a.corr_mags - a.salt_hr)[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same SALT2 parameters but not at the same location in the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_diff(x):\n",
    "    return (x - x[:, None])\n",
    "\n",
    "count = np.array([len(i.spectra) for i in a.targets])\n",
    "first_phase = np.array([i.spectra[0].phase for i in a.targets])\n",
    "mask = (count > 8) & (a.redshifts > 0.03) & (first_phase < -2)\n",
    "\n",
    "salt_x1_diff = outer_diff(a.salt_x1)\n",
    "salt_c_diff = outer_diff(a.salt_color)\n",
    "salt_diff = outer_diff(a.salt_x1)**2 + 100 * outer_diff(a.salt_color)**2\n",
    "manif_diff = outer_diff(a.embedding[:, 0])**2 + outer_diff(a.embedding[:, 1])**2 + outer_diff(a.embedding[:, 2])**2\n",
    "\n",
    "phase_diff = outer_diff(a.salt_phases[a.center_mask])\n",
    "\n",
    "np.fill_diagonal(salt_diff, np.nan)\n",
    "np.fill_diagonal(manif_diff, np.nan)\n",
    "\n",
    "salt_diff[~mask] = np.nan\n",
    "salt_diff[:, ~mask] = np.nan\n",
    "manif_diff[~mask] = np.nan\n",
    "manif_diff[:, ~mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = (salt_x1_diff > 0) & (salt_x1_diff < 0.2) & (np.abs(salt_c_diff) < 0.02) & (manif_diff > 30) & (np.abs(phase_diff) < 1.0)\n",
    "print(\"Num objects:  %s\" % np.sum(cut))\n",
    "salt_diff_idx = [i[2] for i in np.where(cut)]\n",
    "\n",
    "t1 = a.targets[salt_diff_idx[0]]\n",
    "t2 = a.targets[salt_diff_idx[1]]\n",
    "\n",
    "print(\"target 1:     %s\" % t1)\n",
    "print(\"target 2:     %s\" % t2)\n",
    "print(\"redshifts:    %.4f, %.4f\" % (a.redshifts[salt_diff_idx[0]], a.redshifts[salt_diff_idx[1]]))\n",
    "print(\"x_1 values:   %+.3f, %+.3f\" % (a.salt_x1[salt_diff_idx[0]], a.salt_x1[salt_diff_idx[1]]))\n",
    "print(\"c values:     %+.3f, %+.3f\" % (a.salt_color[salt_diff_idx[0]], a.salt_color[salt_diff_idx[1]]))\n",
    "print(\"mags:         %.3f, %.3f\" % (a.mags[salt_diff_idx[0]], a.mags[salt_diff_idx[1]]))\n",
    "print(\"salt HRs:     %.3f, %.3f\" % (a.salt_hr[salt_diff_idx[0]], a.salt_hr[salt_diff_idx[1]]))\n",
    "print(\"corr mags:    %.3f, %.3f\" % (a.corr_mags[salt_diff_idx[0]], a.corr_mags[salt_diff_idx[1]]))\n",
    "print(\"embedding 1:  %s\" % a.embedding[salt_diff_idx[0]])\n",
    "print(\"embedding 2:  %s\" % a.embedding[salt_diff_idx[1]])\n",
    "\n",
    "salt_comparision_mb_diff = np.abs(\n",
    "    a.salt_hr[salt_diff_idx[0]]\n",
    "    - a.salt_hr[salt_diff_idx[1]]\n",
    ")\n",
    "dm_1 = frac_to_mag(t1.salt_fit['x0_err'] / t1.salt_fit['x0'])\n",
    "dm_2 = frac_to_mag(t2.salt_fit['x0_err'] / t2.salt_fit['x0'])\n",
    "\n",
    "salt_comparison_mb_diff_err = np.sqrt(dm_1**2 + dm_2**2)\n",
    "print(\"mag_diff:     %.3f +/- %.3f\" % (salt_comparision_mb_diff, salt_comparison_mb_diff_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['U', 'B', 'V', 'R', 'I']\n",
    "\n",
    "band_colors = {\n",
    "    'U': 'C4',\n",
    "    'B': 'C0',\n",
    "    'V': 'C2',\n",
    "    'R': 'C3',\n",
    "    'I': 'C1',\n",
    "}\n",
    "\n",
    "gap = 1.\n",
    "\n",
    "def plot_lightcurve(target, marker='o', ls='--', mfc='none', label_bands=True):\n",
    "    photometry = target.get_photometry(bands, clip_filter=True)\n",
    "    \n",
    "    # Cut late phases\n",
    "    photometry = photometry[photometry['time'] < 30]\n",
    "        \n",
    "    ref_mag = target.salt_fit['fitted_model'].source_peakmag('snfb', 'ab')\n",
    "    \n",
    "    for offset, band in enumerate(bands):\n",
    "        band_photometry = photometry[photometry['band'] == 'snf%s' % band.lower()]\n",
    "        \n",
    "        if band == 'B':\n",
    "            label = target.name\n",
    "        else:\n",
    "            label = ''\n",
    "            \n",
    "        color = band_colors[band]\n",
    "        \n",
    "        phases = band_photometry['time']\n",
    "        mags = -2.5*np.log10(band_photometry['flux']) - ref_mag - (offset - 1) * gap\n",
    "        magerrs = band_photometry['magerr']\n",
    "    \n",
    "        plt.errorbar(phases, mags, magerrs, fmt='none', c=color)\n",
    "        plt.plot(phases, mags, label=label, marker=marker, c=color, mfc=mfc, ls=ls)\n",
    "        \n",
    "        if label_bands:\n",
    "            plt.text(phases[-1] + 2, mags[-1] + 0.2, '%s%+d' % (band, offset - 1), c=color)\n",
    "            plt.xlim(None, phases[-1] + 9)\n",
    "            \n",
    "def plot_salt_lightcurve(target, phase_min=-6, phase_max=50):\n",
    "    model = target.salt_fit['fitted_model']\n",
    "    phases = np.linspace(phase_min, phase_max, 200)\n",
    "    \n",
    "    # Compute the reference magnitude for B-band at max.\n",
    "    ref_mag = model.source_peakmag('snfb', 'ab')\n",
    "\n",
    "    # Plot each light curve\n",
    "    for offset, band in enumerate(bands):\n",
    "        mags = model.bandmag('snf%s' % band.lower(), 'ab', phases) - ref_mag - (offset - 1) * gap\n",
    "        plt.plot(phases, mags, c='k')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plot_lightcurve(t1, marker='^', ls='', mfc=None, label_bands=False)\n",
    "plot_lightcurve(t2, marker='o', ls='', mfc='none', label_bands=True)\n",
    "# plot_salt_lightcurve(t1)\n",
    "plt.legend()\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Normalized magnitude + offset')\n",
    "plt.ylim(4.8, -2.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/same_salt_comparison.pdf')\n",
    "\n",
    "# plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "def plot_spec(idx):\n",
    "    spec = a.spectra[a.center_mask][idx]\n",
    "\n",
    "    ref_mag = spec.target.salt_fit['fitted_model'].source_peakmag('snfb', 'ab')\n",
    "    \n",
    "    label = '%s, %.2f days' % (spec.target.name, spec.phase)\n",
    "    \n",
    "    scale = 10**(+0.4*ref_mag)\n",
    "    \n",
    "    plt.plot(a.wave, spec.flux * scale * spectrum_plot_scale, label=label)\n",
    "\n",
    "plot_spec(salt_diff_idx[0])\n",
    "plot_spec(salt_diff_idx[1])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Restframe wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/same_salt_spectra.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump details to latex\n",
    "with open('latex/salt_comparison.tex', 'w') as f:\n",
    "    latex_print(f, \"\")\n",
    "    t1 = a.targets[salt_diff_idx[0]]\n",
    "    t2 = a.targets[salt_diff_idx[1]]\n",
    "    latex_command(f, 'saltcompnamea', '%s', t1.name)\n",
    "    latex_command(f, 'saltcompnameb', '%s', t2.name)\n",
    "    latex_command(f, 'saltcompxonea', '%.3f $\\\\pm$ %.3f', (t1['salt2.X1'], t1['salt2.X1.err']))\n",
    "    latex_command(f, 'saltcompxoneb', '%.3f $\\\\pm$ %.3f', (t2['salt2.X1'], t2['salt2.X1.err']))\n",
    "    latex_command(f, 'saltcompca', '%.3f $\\\\pm$ %.3f', (t1['salt2.Color'], t1['salt2.Color.err']))\n",
    "    latex_command(f, 'saltcompcb', '%.3f $\\\\pm$ %.3f', (t2['salt2.Color'], t2['salt2.Color.err']))\n",
    "    latex_command(f, 'saltcompcoorda', '%.2f', a.embedding[salt_diff_idx[0], 0])\n",
    "    latex_command(f, 'saltcompcoordb', '%.2f', a.embedding[salt_diff_idx[1], 0])\n",
    "    latex_command(f, 'saltcompmagbdiff', '%.3f $\\\\pm$ %.3f', (salt_comparision_mb_diff, salt_comparison_mb_diff_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Host galaxy correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Optimization terminated successfully.\n",
      "    Color scale:          -0.007 ± 0.070\n",
      "    Intrinsic dispersion: 0.065 ± 0.013 mag\n",
      "    GP kernel amplitude:  0.111 ± 0.042 mag\n",
      "    GP length scale:      3.348 ± 2.272\n",
      "    Fit NMAD:             0.072 mag\n",
      "    Fit std:              0.098 mag\n",
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Desired error not necessarily achieved due to precision loss.\n",
      "    Color scale:          3.108 ± 0.211\n",
      "    Intrinsic dispersion: 0.090 ± 0.014 mag\n",
      "    GP kernel amplitude:  0.358 ± 0.203 mag\n",
      "    GP length scale:      7.316 ± 4.765\n",
      "    Fit NMAD:             0.095 mag\n",
      "    Fit std:              0.119 mag\n"
     ]
    }
   ],
   "source": [
    "a.fit_gp(kind='rbtl')\n",
    "rbtl_isomap_mags = a.corr_mags\n",
    "a.fit_gp(kind='salt_raw')\n",
    "salt_isomap_mags = a.corr_mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_step(sample, sides, errs, axis=None):\n",
    "    vals_1 = np.average(sample, weights=sides / errs**2, axis=axis)\n",
    "    vals_2 = np.average(sample, weights=(1-sides) / errs**2, axis=axis)\n",
    "    \n",
    "    return vals_1, vals_2, vals_2 - vals_1\n",
    "\n",
    "def bootstrap_step(sample, sides, errs=1):\n",
    "    return math.bootstrap_statistic(calc_step, sample, sides, errs)\n",
    "\n",
    "def likelihood_step(residuals, prob, errs=0.):\n",
    "    def calc_likelihood(x):\n",
    "        s1, s2, err1, err2 = x\n",
    "\n",
    "        var1 = errs**2 + err1**2\n",
    "        var2 = errs**2 + err2**2\n",
    "\n",
    "        likelihood = np.sum(-np.log(\n",
    "            prob * 1 / np.sqrt(2 * np.pi * var1) * np.exp(-(residuals - s1)**2 / var1)\n",
    "            + (1 - prob) * 1 / np.sqrt(2 * np.pi * var2) * np.exp(-(residuals - s2)**2 / var2)\n",
    "        ))\n",
    "\n",
    "        return likelihood\n",
    "\n",
    "    res = minimize(calc_likelihood, [0., 0., 0.1, 0.1], method='BFGS')\n",
    "    param_errs = np.sqrt(np.diag(res.hess_inv))\n",
    "\n",
    "    # Estimate the variances with the intrinsic components.\n",
    "    total_vars = errs**2 + prob * res.x[2]**2 + (1 - prob) * res.x[3]**2\n",
    "\n",
    "    step_means = (res.x[0], res.x[1], res.x[1] - res.x[0])\n",
    "    step_errs = (param_errs[0], param_errs[1], np.sqrt(param_errs[0]**2 + param_errs[1]**2))\n",
    "\n",
    "    return step_means, step_errs, total_vars\n",
    "\n",
    "def int_disp(vals, pec_vel_disps, axis=None):\n",
    "    std = np.std(vals, ddof=1, axis=axis)\n",
    "    corr = np.mean(pec_vel_disps**2, axis=axis)\n",
    "    corr_std = np.sqrt(np.clip(std**2 - corr, 0, None))\n",
    "\n",
    "    return corr_std\n",
    "\n",
    "def analyze_host_variable(variable, mags, mask, uncertainties=None, threshold=None,\n",
    "                          use_probability=True, plot=True, bootstrap=None,\n",
    "                          y_label='Residual magnitudes'):\n",
    "    use_mask = np.where(mask & a.host_mask)[0]\n",
    "\n",
    "    if isinstance(bootstrap, int):\n",
    "        np.random.seed(bootstrap)\n",
    "        bootstrap_idx = np.random.choice(len(use_mask), len(use_mask))\n",
    "        use_mask = use_mask[bootstrap_idx]\n",
    "        \n",
    "    host_data = a.host_data[use_mask]\n",
    "    use_mags = mags[use_mask]\n",
    "    \n",
    "    use_var = host_data[variable]\n",
    "    # use_var_low = -host_data[variable + '_low']\n",
    "    # use_var_high = host_data[variable + '_up']\n",
    "    use_var_low = host_data[variable + '.err_down']\n",
    "    use_var_high = host_data[variable + '.err_up']\n",
    "    \n",
    "    # Default thresholds from Rigault et al. 2019\n",
    "    if threshold is None:\n",
    "        if variable == 'lssfr':\n",
    "            threshold = -10.8\n",
    "        elif variable == 'gmass':\n",
    "            threshold = 10\n",
    "        else:\n",
    "            # Default, use the median of the variable\n",
    "            threshold = np.median(use_var)\n",
    "\n",
    "    # Figure out labels.\n",
    "    if variable == 'lssfr':\n",
    "        x_label = 'log(lsSFR)'\n",
    "    elif variable == 'gmass':\n",
    "        x_label = 'log($M_* / M_\\odot$) (global)'\n",
    "\n",
    "    # Figure out which weights to use for the step. We want to actually use\n",
    "    # the probabilities if they are available rather than hard cuts as is done\n",
    "    # in Rigault et al. 2018.\n",
    "    label = variable\n",
    "    use_weights = None\n",
    "\n",
    "    if use_probability:\n",
    "        if variable == 'lssfr':\n",
    "            # plot_color = host_data['p_young']\n",
    "            # use_weights = 1 - host_data['p_young'] / 100\n",
    "            plot_color = host_data['p(prompt)']\n",
    "            use_weights = 1 - host_data['p(prompt)']\n",
    "            label = '$P_{Young}$'\n",
    "        elif variable == 'gmass':\n",
    "            # plot_color = host_data['p_highmass']\n",
    "            # use_weights = 1 - host_data['p_highmass'] / 100\n",
    "            plot_color = host_data['p(highgmass)']\n",
    "            use_weights = 1 - host_data['p(highgmass)']\n",
    "            label = '$P_{high\\ mass}$'\n",
    "\n",
    "    if use_weights is None:\n",
    "        # Backup: do hard cuts.\n",
    "        use_weights = use_var < threshold\n",
    "        plot_color = use_weights\n",
    "\n",
    "    if uncertainties is None:\n",
    "        # If we don't have explicit uncertainties, just use the peculiar velocity contributions.\n",
    "        uncertainties = a.get_peculiar_velocity_uncertainty()\n",
    "\n",
    "    use_uncertainties = uncertainties[use_mask]\n",
    "\n",
    "    step_means, step_errs, total_var = likelihood_step(use_mags, use_weights, use_uncertainties)\n",
    "\n",
    "    if plot:\n",
    "        print(\"Step size: %.3f ± %.3f mag\" % (step_means[2], step_errs[2]))\n",
    "        print(\"Median step: %.3f\" % (np.median(use_mags[use_weights < 0.5]) - np.median(use_mags[use_weights > 0.5])))\n",
    "        plt.figure()\n",
    "        plt.errorbar(use_var, use_mags, xerr=(use_var_low, use_var_high), yerr=np.sqrt(total_var), fmt='.', c='gray', alpha=0.5, zorder=-2)\n",
    "        plt.scatter(use_var, use_mags, s=100, c=plot_color, edgecolors='gray', cmap=plt.cm.viridis_r)\n",
    "\n",
    "        # Threshold\n",
    "        plt.axvline(threshold, c='k', lw=2, ls='--')\n",
    "\n",
    "        # Show means of each side\n",
    "        plot_min, plot_max = plt.xlim()\n",
    "        mean_low, mean_high, mean_diff = step_means\n",
    "        mean_low_err, mean_high_err, mean_diff_err = step_errs\n",
    "        plt.plot([plot_min, threshold], [mean_low, mean_low], c='k', zorder=-1)\n",
    "        plt.fill_between([plot_min, threshold], [mean_low - mean_low_err, mean_low - mean_low_err], [mean_low + mean_low_err, mean_low + mean_low_err], color=plt.cm.viridis(1000), alpha=0.5, zorder=-3)\n",
    "        plt.plot([threshold, plot_max], [mean_high, mean_high], c='k', zorder=-1)\n",
    "        plt.fill_between([threshold, plot_max], [mean_high - mean_high_err, mean_high - mean_high_err], [mean_high + mean_high_err, mean_high + mean_high_err], color=plt.cm.viridis(0), alpha=0.5, zorder=-3)\n",
    "        \n",
    "        # plt.axhline(np.median(use_mags[use_weights > 0.5]))\n",
    "        # plt.axhline(np.median(use_mags[use_weights < 0.5]))\n",
    "\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "        plt.xlim(plot_min, plot_max)\n",
    "        plt.ylim(-0.6, 0.6)\n",
    "        \n",
    "        print(step_means, step_errs)\n",
    "\n",
    "\n",
    "        plt.colorbar(label=label)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return step_means[-1], step_errs[-1]\n",
    "\n",
    "def bootstrap_step_difference(variable, mags_1, uncertainties_1, mags_2, uncertainties_2, mask,\n",
    "                              num_resamples=100, **kwargs):\n",
    "    step_diffs = []\n",
    "    for bootstrap_iter in range(num_resamples):\n",
    "        step_size_1, step_err_1 = analyze_host_variable(variable, mags_1, mask, uncertainties_1, bootstrap=bootstrap_iter, plot=False, **kwargs)\n",
    "        step_size_2, step_err_2 = analyze_host_variable(variable, mags_2, mask, uncertainties_2, bootstrap=bootstrap_iter, plot=False, **kwargs)\n",
    "        \n",
    "        step_diffs.append(step_size_2 - step_size_1)\n",
    "    \n",
    "    return np.mean(step_diffs), np.std(step_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.021615132882580122, 0.02875388947906787)\n",
      "(0.013833119908810608, 0.03035360492703955)\n",
      "(-0.026182550161478635, 0.031862275023164625)\n",
      "(0.03366179290776711, 0.03522787030751771)\n",
      "(0.0045674172788985066, 0.020624949152699183)\n",
      "(-0.019828672998956506, 0.025629890358623418)\n"
     ]
    }
   ],
   "source": [
    "print(bootstrap_step_difference('lssfr', a.salt_hr, a.salt_hr_raw_uncertainties, rbtl_isomap_mags, None,\n",
    "                          a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask))\n",
    "print(bootstrap_step_difference('gmass', a.salt_hr, a.salt_hr_raw_uncertainties, rbtl_isomap_mags, None,\n",
    "                          a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask))\n",
    "print(bootstrap_step_difference('lssfr', a.salt_hr, a.salt_hr_raw_uncertainties, salt_isomap_mags, a.salt_hr_raw_uncertainties,\n",
    "                          a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask))\n",
    "print(bootstrap_step_difference('gmass', a.salt_hr, a.salt_hr_raw_uncertainties, salt_isomap_mags, a.salt_hr_raw_uncertainties,\n",
    "                          a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask))\n",
    "print(bootstrap_step_difference('lssfr', salt_isomap_mags, a.salt_hr_raw_uncertainties, rbtl_isomap_mags, None,\n",
    "                          a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask))\n",
    "print(bootstrap_step_difference('gmass', salt_isomap_mags, a.salt_hr_raw_uncertainties, rbtl_isomap_mags, None,\n",
    "                          a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lsSFR plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading between the lines...\n",
      "Loaded cached stan model\n",
      "Using saved stan result\n",
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Optimization terminated successfully.\n",
      "    Color scale:          -0.007 ± 0.070\n",
      "    Intrinsic dispersion: 0.065 ± 0.013 mag\n",
      "    GP kernel amplitude:  0.111 ± 0.042 mag\n",
      "    GP length scale:      3.348 ± 2.272\n",
      "    Fit NMAD:             0.072 mag\n",
      "    Fit std:              0.098 mag\n"
     ]
    }
   ],
   "source": [
    "a.settings['blinded'] = True\n",
    "a.read_between_the_lines()\n",
    "a.fit_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: 0.063 ± 0.025 mag\n",
      "Median step: 0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a378388f7143c98646124a12c7df3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.02839692635279487, 0.034701827754462705, 0.06309875410725757) (0.01719251437000813, 0.01842279386612423, 0.025198846882280957)\n"
     ]
    }
   ],
   "source": [
    "analyze_host_variable('lssfr', a.salt_hr, a.salt_mask & a.uncertainty_mask & a.redshift_color_mask,# & ~np.array([i.name == 'PTF11mkx' for i in a.targets]),\n",
    "                      a.salt_hr_raw_uncertainties, y_label='SALT2 + $x_1$ residual magnitudes')\n",
    "plt.savefig('./figures/lssfr_salt_x1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: 0.060 ± 0.030 mag\n",
      "Median step: 0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a5a5ca36e94b47a661ce489fa28ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.012016793525258923, 0.04795269471070949, 0.05996948823596841) (0.022060544362963404, 0.02057447394983037, 0.030165818336364173)\n",
      "Step size: 0.041 ± 0.023 mag\n",
      "Median step: 0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db8efb261194afb991b9927b22d6c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.017535596937315604, 0.023856737963441014, 0.04139233490075662) (0.01919004920439598, 0.012484562825303228, 0.022893717422168076)\n",
      "Step size: 0.037 ± 0.029 mag\n",
      "Median step: 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:113: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba6b98f95b549e1b75c941f2d26bab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.007739005480027818, 0.029434319670545855, 0.03717332515057367) (0.022261155371062765, 0.019308111272019295, 0.029467986007653716)\n"
     ]
    }
   ],
   "source": [
    "analyze_host_variable('lssfr', a.salt_hr, a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask, a.salt_hr_raw_uncertainties, y_label='SALT2 + $x_1$ residual magnitudes')\n",
    "plt.savefig('./figures/lssfr_salt_x1_cuts.pdf')\n",
    "analyze_host_variable('lssfr', rbtl_isomap_mags, a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask, y_label='RBTL + Isomap residual magnitudes')\n",
    "plt.savefig('./figures/lssfr_rbtl_isomap_cuts.pdf')\n",
    "analyze_host_variable('lssfr', salt_isomap_mags, a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask, a.salt_hr_raw_uncertainties, y_label='SALT2 + Isomap residual magnitudes')\n",
    "plt.savefig('./figures/lssfr_salt_isomap_cuts.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global mass plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: -0.040 ± 0.026 mag\n",
      "Median step: -0.045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:114: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f6e8e2a1d44580b3790d88c55f2904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.025187826614678905, -0.015221528209334442, -0.040409354824013345) (0.02073988398205367, 0.015164576050075866, 0.025692550561740284)\n"
     ]
    }
   ],
   "source": [
    "analyze_host_variable('gmass', a.salt_hr, a.salt_mask & a.uncertainty_mask & a.redshift_color_mask, a.salt_hr_raw_uncertainties, y_label='SALT2 + $x_1$ residual magnitudes')\n",
    "plt.savefig('./figures/gmass_salt_x1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.host_mask & a.train_mask\n",
    "zz = a.host_data[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009203790391174835"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(zz['HR'][zz['p(prompt)'] > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20080300a3841158cfd647cd499ebff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f84abdf57d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.salt_colors[m], zz['HR_o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Target(name=\"PTF11mkx\")], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.targets[(a.salt_hr < -0.4) & (a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.host_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: -0.037 ± 0.032 mag\n",
      "Median step: 0.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4af1d40c93447dbb6628bed34c5a499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.03632344398195818, -0.00021574776434418226, -0.03653919174630236) (0.022685671770290454, 0.02221739851361818, 0.03175299199102782)\n",
      "Step size: -0.031 ± 0.022 mag\n",
      "Median step: -0.016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3e9fe115ba4cadafb76b9cba087243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.01920695685338997, -0.011999867262688303, -0.031206824116078273) (0.011602038954744636, 0.01831127382123058, 0.021677408905667123)\n",
      "Step size: -0.009 ± 0.030 mag\n",
      "Median step: 0.034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed66e0cae4340798b14be151defc365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.014017260024520525, 0.005269200270353779, -0.008748059754166745) (0.0199407252103083, 0.022625971803562277, 0.030159030521033334)\n"
     ]
    }
   ],
   "source": [
    "analyze_host_variable('gmass', a.salt_hr, a.train_mask & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask, y_label='SALT2 + $x_1$ residual magnitudes')\n",
    "plt.savefig('./figures/gmass_salt_x1_cuts.pdf')\n",
    "analyze_host_variable('gmass', rbtl_isomap_mags, a.train_mask & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask, y_label='RBTL + Isomap residual magnitudes')\n",
    "plt.savefig('./figures/gmass_rbtl_isomap_cuts.pdf')\n",
    "analyze_host_variable('gmass', salt_isomap_mags, a.train_mask & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask, y_label='SALT2 + Isomap residual magnitudes')\n",
    "plt.savefig('./figures/gmass_salt_isomap_cuts.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lmass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-bf940aaac8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmag_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmags\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmag_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_host_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalt_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muncertainty_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredshift_color_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmag_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar_sign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-40fc4607d358>\u001b[0m in \u001b[0;36manalyze_host_variable\u001b[0;34m(variable, mags, mask, uncertainties, threshold, use_probability, plot, bootstrap, y_label)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0muse_mags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muse_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0muse_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhost_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# use_var_low = -host_data[variable + '_low']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# use_var_high = host_data[variable + '_up']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/conda/lib/python3.7/site-packages/astropy/table/table.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/conda/lib/python3.7/site-packages/astropy/table/table.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lmass'"
     ]
    }
   ],
   "source": [
    "host_results = {}\n",
    "\n",
    "step_vars = [\n",
    "    ('gmass', 'Global Mass', -1),\n",
    "    ('lmass', 'Local Mass', -1),\n",
    "    ('lssfr', 'Local SSFR', +1),\n",
    "]\n",
    "\n",
    "mag_vars = [\n",
    "    ('SALT2 + $x_1$', a.salt_hr),\n",
    "    ('SALT2 + Manifold', salt_isomap_mags),\n",
    "    ('Spectrum + Manifold', rbtl_isomap_mags),\n",
    "]\n",
    "\n",
    "host_results = {}\n",
    "\n",
    "for var_name, var_label, var_sign in step_vars:\n",
    "    steps = {}\n",
    "    for mag_label, mags in mag_vars:\n",
    "        var, var_err = analyze_host_variable(var_name, mags, a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask, plot=False)\n",
    "        steps[mag_label] = (var * var_sign, var_err)\n",
    "        \n",
    "    host_results[var_label] = steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7bbe9f2c794f04aa30858c70c039bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "labels = []\n",
    "for prop_idx, (prop_label, prop_values) in enumerate(host_results.items()):\n",
    "    for mag_idx, (mag_label, mag_values) in enumerate(prop_values.items()):\n",
    "        step_value, step_err = mag_values\n",
    "        \n",
    "        marker = 'oooo'[mag_idx]\n",
    "        color = 'C%d' % (mag_idx)\n",
    "        if prop_idx == 0:\n",
    "            label = mag_label\n",
    "        else:\n",
    "            label = None\n",
    "            \n",
    "            \n",
    "        gap = 0.1\n",
    "        xpos = prop_idx - 0.5*gap + gap * mag_idx\n",
    "        plt.errorbar(xpos, step_value, step_err, c=color, alpha=1.)\n",
    "        plt.plot(xpos, step_value, marker=marker, c=color, label=label)\n",
    "        \n",
    "    labels.append(prop_label)\n",
    "\n",
    "plt.xticks(np.arange(len(labels)), labels=labels)\n",
    "plt.axhline(0., c='k')\n",
    "plt.xlim(-0.5, len(labels) - 0.5)\n",
    "plt.ylim(-0.045, 0.155)\n",
    "\n",
    "plt.ylabel('Step size (mag)')\n",
    "plt.legend(loc=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/host_correlations_summary.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these functions are defined in the Host galaxy correlations section. Make\n",
    "# sure to run that first.\n",
    "def print_row(f, mags, cut, label, cut_label):\n",
    "    step_vars = [\n",
    "        ('lssfr', '$\\\\Delta_{lsSFR}$', +1),\n",
    "        ('gmass', '$\\\\Delta_{mass}$', -1),\n",
    "    ]\n",
    "    stat_str = \"%20s & %20s\" % (label, cut_label)\n",
    "    for i, (var_name, var_label, var_sign) in enumerate(step_vars):\n",
    "        var, var_err = analyze_host_variable(var_name, mags, cut, plot=False)\n",
    "        stat_str += \" & %.3f $\\pm$ %.3f\" % (var_sign * var, var_err)\n",
    "        \n",
    "    stat_str += \" \\\\\\\\\"\n",
    "    latex_print(f, stat_str)\n",
    "    \n",
    "with open('./latex/host_steps.tex', 'w') as f:\n",
    "    print_row(f, a.salt_hr, a.good_salt_mask, 'SALT2 + $x_1$', 'SALT2')\n",
    "    print_row(f, a.salt_hr, a.good_salt_mask & a.good_mag_mask, 'SALT2 + $x_1$', 'SALT2 + max + train')\n",
    "    print_row(f, rbtl_isomap_mags, a.good_salt_mask & a.good_mag_mask, 'RBTL + Isomap', 'SALT2 + max + train')\n",
    "    print_row(f, salt_isomap_mags, a.good_salt_mask & a.good_mag_mask, 'SALT2 + Isomap', 'SALT2 + max + train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attrition and LaTeX variables for things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./latex/attrition_parametrization.tex', 'w') as f:\n",
    "    latex_print(f, \"\\\\textbf{General selection requirements} & \\\\\\\\\")\n",
    "    latex_print(f, \"Initial sample                                        & %d \\\\\\\\\" % len(a.dataset.targets))\n",
    "    latex_print(f, \"More than 5 spectra                                   & %d \\\\\\\\\" % a.attrition_enough_spectra)\n",
    "    latex_print(f, \"SALT2 date of maximum light uncertainty < 1 day       & %d \\\\\\\\\" % a.attrition_salt_daymax)\n",
    "    latex_print(f, \"At least one spectrum within 5 days of maximum light  & %d \\\\\\\\\" % a.attrition_range)\n",
    "    latex_print(f, \"At least one spectrum with S/N 3300-3800~\\AA\\ > 100   & %d \\\\\\\\\" % a.attrition_usable)\n",
    "    latex_print(f, \"\\hline\")\n",
    "    latex_print(f, \"\\\\textbf{Manifold learning selection requirements} & \\\\\\\\\")\n",
    "    latex_print(f, r\"\\textbf{(Section~\\ref{sec:isomap_sample})} & \\\\\")\n",
    "    latex_print(f, \"Spectrum at max. uncertainty < 10\\\\%% of intrinsic power        & %d \\\\\\\\\" % np.sum(a.interp_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./latex/attrition_standardization.tex', 'w') as f:\n",
    "    latex_print(f, \"\\\\textbf{General selection requirements} & \\\\\\\\\")\n",
    "    latex_print(f, \"Full SNfactory dataset                                & %d \\\\\\\\\" % len(a.dataset.targets))\n",
    "    latex_print(f, \"Included in Isomap latent space                       & %d \\\\\\\\\" % np.sum(a.interp_mask))\n",
    "    latex_print(f, \"\\hline\")\n",
    "    \n",
    "    latex_print(f, \"\\\\textbf{Standardization of near-maximum spectra} & \\\\\\\\\")\n",
    "    latex_print(f, \"Host galaxy redshift available                        & %d \\\\\\\\\" % np.sum(a.interp_mask & (a.redshift_errs < 0.004)))\n",
    "    latex_print(f, \"Host galaxy redshift above 0.02                       & %d \\\\\\\\\" % np.sum(a.interp_mask & (a.redshift_errs < 0.004) & (a.redshifts > 0.02)))\n",
    "    latex_print(f, \"Measured $A_V$ < 0.5 mag                              & %d \\\\\\\\\" % np.sum(a.interp_mask & a.redshift_color_mask))\n",
    "    latex_print(f, \"Blinded training subsample                            & %d \\\\\\\\\" % np.sum(a.good_mag_mask))\n",
    "    # latex_print(f, \"Validation subsample                                  & %d \\\\\\\\\" % np.sum(a.good_mag_mask))\n",
    "    latex_print(f, \"Validation subsample                                  & TODO \\\\\\\\\")\n",
    "    latex_print(f, \"\\hline\")\n",
    "    \n",
    "    latex_print(f, \"\\\\textbf{Comparisons to SALT2 standardization} & \\\\\\\\\")\n",
    "    latex_print(f, r\"\\textbf{(Section~\\ref{sec:salt2_standardization})} & \\\\\")\n",
    "    latex_print(f, \"SNfactory SALT2 selection requirements                & %d \\\\\\\\\"% np.sum(a.salt_mask & a.interp_mask))\n",
    "    latex_print(f, \"Passes host galaxy redshift and color requirements    & %d \\\\\\\\\"% np.sum(a.good_salt_mask & a.interp_mask))\n",
    "    latex_print(f, \"Has a valid interpolation to maximum light            & %d \\\\\\\\\"% np.sum(a.good_salt_mask & a.interp_mask))\n",
    "    latex_print(f, \"Blinded training subsample                            & %d \\\\\\\\\"% np.sum(a.good_salt_mask & a.good_mag_mask))\n",
    "    # latex_print(f, \"Validation subsample                                  & %d \\\\\\\\\"% np.sum(a.good_salt_mask & a.good_mag_mask))\n",
    "    latex_print(f, \"Validation subsample                                  & TODO \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./latex/attrition.tex', 'w') as f:\n",
    "    latex_print(f, \"\\\\textbf{General selection requirements} & \\\\\\\\\")\n",
    "    latex_print(f, \"Initial sample                                        & %d \\\\\\\\\" % len(a.dataset.targets))\n",
    "    latex_print(f, \"More than 5 spectra                                   & %d \\\\\\\\\" % a.attrition_enough_spectra)\n",
    "    latex_print(f, \"SALT2 date of maximum light uncertainty < 1 day       & %d \\\\\\\\\" % a.attrition_salt_daymax)\n",
    "    latex_print(f, \"At least one spectrum within 5 days of maximum light  & %d \\\\\\\\\" % a.attrition_range)\n",
    "    latex_print(f, \"At least one spectrum with S/N 3300-3800~\\AA\\ > 100   & %d \\\\\\\\\" % a.attrition_usable)\n",
    "    latex_print(f, \"\\hline\")\n",
    "    latex_print(f, \"\\\\textbf{Estimation of the spectra at maximum light} & \\\\\\\\\")\n",
    "    latex_print(f, r\"\\textbf{(Section~\\ref{sec:int_disp_uncertainty})} & \\\\\")\n",
    "    latex_print(f, \"Spectrum uncertainty < 10\\\\%% of intrinsic power        & %d \\\\\\\\\" % np.sum(a.interp_mask))\n",
    "    latex_print(f, \"\\hline\")\n",
    "    latex_print(f, \"\\\\textbf{Valid supernova brightness requirements} & \\\\\\\\\")\n",
    "    latex_print(f, r\"\\textbf{(Section~\\ref{sec:magnitude_requirements})} & \\\\\")\n",
    "    latex_print(f, \"Host galaxy redshift available                        & %d \\\\\\\\\" % np.sum(a.interp_mask & (a.redshift_errs < 0.004)))\n",
    "    latex_print(f, \"Host galaxy redshift above 0.02                       & %d \\\\\\\\\" % np.sum(a.interp_mask & (a.redshift_errs < 0.004) & (a.redshifts > 0.02)))\n",
    "    latex_print(f, \"Measured $A_V$ < 0.5 mag                              & %d \\\\\\\\\" % np.sum(a.interp_mask & a.redshift_color_mask))\n",
    "    latex_print(f, \"Blinded training subsample                            & %d \\\\\\\\\" % np.sum(a.good_mag_mask))\n",
    "    latex_print(f, \"\\hline\")\n",
    "    latex_print(f, \"\\\\textbf{Comparisons to SALT2 fits} & \\\\\\\\\")\n",
    "    latex_print(f, r\"\\textbf{(Section~\\ref{sec:salt2_standardization})} & \\\\\")\n",
    "    latex_print(f, \"SNfactory SALT2 selection requirements                & %d \\\\\\\\\"% np.sum(a.salt_mask))\n",
    "    latex_print(f, \"Passes host galaxy redshift and color requirements    & %d \\\\\\\\\"% np.sum(a.good_salt_mask))\n",
    "    latex_print(f, \"Has a valid interpolation to maximum light            & %d \\\\\\\\\"% np.sum(a.good_salt_mask & a.interp_mask))\n",
    "    latex_print(f, \"Blinded training subsample                            & %d \\\\\\\\\"% np.sum(a.good_salt_mask & a.good_mag_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bunch of functions to make things easier.\n",
    "def latex_host_step(file, name, var, mags, mask):\n",
    "    step, step_err = analyze_host_variable(var, mags, mask, plot=False)\n",
    "    latex_command(file, name, '%.3f $\\\\pm$ %.3f', (np.abs(step), step_err))\n",
    "\n",
    "a.fit_gp(kind='salt_raw', verbose=False)\n",
    "salt_isomap_mags = a.corr_mags.copy()\n",
    "\n",
    "a.fit_gp(verbose=False)\n",
    "rbtl_isomap_mags = a.corr_mags.copy()\n",
    "\n",
    "with open('latex/commands.tex', 'w') as f:\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numdatasetsne', '%d', len(a.dataset.targets))\n",
    "    latex_command(f, 'numdatasetspectra', '%d', np.sum([len(i.spectra) for i in a.dataset.targets]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'nummanifoldsne', '%d', len(a.targets))\n",
    "    latex_command(f, 'nummanifoldspectra', '%d', len(a.spectra))\n",
    "    latex_command(f, 'numinterpsne', '%d', np.sum(a.interp_mask))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numsnftrain', '%d', np.sum([i.subset == 'training' for i in a.targets[a.interp_mask]]))\n",
    "    latex_command(f, 'numsnfvalid', '%d', np.sum([i.subset == 'validation' for i in a.targets[a.interp_mask]]))\n",
    "    latex_command(f, 'numsnfother', '%d', np.sum([i.subset not in ['training', 'validation'] for i in a.targets[a.interp_mask]]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numsnredshift', '%d', np.sum(a.interp_mask & (a.redshift_errs >= 0.004)))\n",
    "    latex_command(f, 'numlowredshift', '%d', np.sum(a.interp_mask & (a.redshifts <= 0.02)))\n",
    "    latex_command(f, 'numhighav', '%d', np.sum(a.interp_mask & (a.colors - np.nanmedian(a.colors) >= 0.5)))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'nummagsne', '%d', np.sum(a.interp_mask & a.redshift_color_mask))\n",
    "    latex_command(f, 'nummagsnetrain', '%d', np.sum(a.good_mag_mask))\n",
    "    latex_command(f, 'nummagsnevalidation', '%d', np.sum(a.interp_mask & a.redshift_color_mask & ~a.good_mag_mask))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'saltparammb', '%.2f', a.salt_MB)\n",
    "    latex_command(f, 'saltparamalpha', '%.3f', a.salt_alpha)\n",
    "    latex_command(f, 'saltparambeta', '%.2f', a.salt_beta)\n",
    "    latex_command(f, 'saltparamsigmaint', '%.3f', a.salt_intrinsic_dispersion)\n",
    "    # latex_command(f, 'saltparamrms', '%.3f', np.std(a.salt_hr[a.good_salt_mask]))\n",
    "    latex_std(f, 'saltparamrms', a.salt_hr[a.good_salt_mask])\n",
    "    latex_nmad(f, 'saltparamnmad', a.salt_hr[a.good_salt_mask])\n",
    "    latex_command(f, 'saltparamwrms', '%.3f', a.salt_wrms)\n",
    "    latex_command(f, 'saltparammindisp', '%.2f', np.min(a.salt_hr_uncertainties[a.good_salt_mask]))\n",
    "    latex_command(f, 'saltparammaxdisp', '%.2f', np.max(a.salt_hr_uncertainties[a.good_salt_mask]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'rawrbtlmagstd', a.mags[a.good_mag_mask])\n",
    "    latex_nmad(f, 'rawrbtlmagnmad', a.mags[a.good_mag_mask])\n",
    "    # latex_print(f, \"\")\n",
    "    # latex_command(f, 'twinrbtlmagstd', '%.3f', a.twins_rms)\n",
    "    # latex_command(f, 'twinrbtlmagnmad', '%.3f', a.twins_nmad)\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'saltcomprawrbtlmagstd', a.mags[a.good_mag_mask & a.good_salt_mask])\n",
    "    latex_std(f, 'saltcompsaltmagstd', a.salt_hr[a.good_mag_mask & a.good_salt_mask])\n",
    "\n",
    "    a.fit_gp(verbose=False, kind='salt_raw')\n",
    "    gp_uncertainties = np.sqrt(np.diag(a.gp_hyperparameter_covariance))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'saltgpcolor', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[0], gp_uncertainties[0]))\n",
    "    latex_command(f, 'saltgpintdisp', '%.3f $\\\\pm$ %.3f', (a.gp_hyperparameters[1], gp_uncertainties[1]))\n",
    "    latex_command(f, 'saltgpkernelamp', '%.3f $\\\\pm$ %.3f', (np.abs(a.gp_hyperparameters[2]), gp_uncertainties[2]))\n",
    "    latex_command(f, 'saltgpkernellengthscale', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[3], gp_uncertainties[3]))\n",
    "    latex_std(f, 'saltgprms', a.corr_mags[a.good_salt_mask & a.interp_mask])\n",
    "    latex_std(f, 'saltgpcompsaltrms', a.salt_hr[a.good_salt_mask & a.interp_mask])\n",
    "\n",
    "    a.fit_gp(verbose=False)\n",
    "    gp_uncertainties = np.sqrt(np.diag(a.gp_hyperparameter_covariance))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'rbtlgpcolor', '%.2f $\\\\pm$ %.2f', (a.fiducial_rv * (1 + a.gp_hyperparameters[0]), a.fiducial_rv * gp_uncertainties[0]))\n",
    "    latex_command(f, 'rbtlgpintdisp', '%.3f $\\\\pm$ %.3f', (a.gp_hyperparameters[1], gp_uncertainties[1]))\n",
    "    latex_command(f, 'rbtlgpkernelamp', '%.3f $\\\\pm$ %.3f', (np.abs(a.gp_hyperparameters[2]), gp_uncertainties[2]))\n",
    "    latex_command(f, 'rbtlgpkernellengthscale', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[3], gp_uncertainties[3]))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'rbtlgprms', a.corr_mags[a.good_mag_mask])\n",
    "    latex_command(f, 'rbtlgpnmad', '%.3f', math.nmad(a.corr_mags[a.good_mag_mask]))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    x1 = a.salt_hr[(a.embedding[:, 0] < 3) & a.good_salt_mask & a.interp_mask]\n",
    "    x2 = a.salt_hr[(a.embedding[:, 0] > 3) & a.good_salt_mask & a.interp_mask]\n",
    "    m1 = np.mean(x1)\n",
    "    m2 = np.mean(x2)\n",
    "    err1 = np.std(x1) / np.sqrt(len(x1))\n",
    "    err2 = np.std(x2) / np.sqrt(len(x2))\n",
    "    latex_command(f, 'saltisomapdiff', '%.3f $\\\\pm$ %.3f', (np.abs(m1-m2), np.sqrt(err1**2 + err2**2)))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'pecvelcontribution', '%.3f', np.sqrt(np.mean(a.get_peculiar_velocity_uncertainty()[a.good_mag_mask & a.good_salt_mask]**2)))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_host_step(f, 'lssfrsaltxifull', 'lssfr', a.salt_hr, a.good_salt_mask)\n",
    "    latex_host_step(f, 'gmasssaltxifull', 'gmass', a.salt_hr, a.good_salt_mask)\n",
    "    latex_host_step(f, 'lssfrsaltxicut', 'lssfr', a.salt_hr, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmasssaltxicut', 'gmass', a.salt_hr, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'lssfrsaltisomapcut', 'lssfr', salt_isomap_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmasssaltisomapcut', 'gmass', salt_isomap_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'lssfrrbtlisomapcut', 'lssfr', a.corr_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmassrbtlisomapcut', 'gmass', a.corr_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_command(f, 'hostcutsnsnetrain', '%d', np.sum(a.good_mag_mask & a.good_salt_mask & a.host_mask))\n",
    "    latex_command(f, 'hostcutsnsnefull', '%d', np.sum(a.redshift_color_mask & a.interp_mask & a.good_salt_mask & a.host_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Optimization terminated successfully.\n",
      "    Color scale:          -0.127 ± 0.051\n",
      "    Intrinsic dispersion: 0.064 ± 0.009 mag\n",
      "    GP kernel amplitude:  0.177 ± 0.089 mag\n",
      "    GP length scale:      5.553 ± 3.271\n",
      "    Fit NMAD:             0.081 mag\n",
      "    Fit std:              0.100 mag\n",
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Desired error not necessarily achieved due to precision loss.\n",
      "    Color scale:          2.799 ± 0.151\n",
      "    Intrinsic dispersion: -0.087 ± 0.009 mag\n",
      "    GP kernel amplitude:  0.424 ± 0.250 mag\n",
      "    GP length scale:      9.365 ± 5.524\n",
      "    Fit NMAD:             0.103 mag\n",
      "    Fit std:              0.117 mag\n",
      "    Maximum spectrum &   134 &                 NMAD &   0.108 $\\pm$  0.013 &  0.081 $\\pm$  0.011 &                  -- &                  -- \\\\\n",
      "     + training cuts &       &   Standard deviation &   0.130 $\\pm$  0.010 &  0.100 $\\pm$  0.008 &                  -- &                  -- \\\\\n",
      "                     &       &    Pec. vel. removed &   0.113 $\\pm$  0.012 &  0.076 $\\pm$  0.010 &                  -- &                  -- \\\\\n",
      "\\hline\n",
      "      SALT2 fit cuts &   151 &                 NMAD &                   -- &                  -- &  0.110 $\\pm$  0.014 &                  -- \\\\\n",
      "                     &       &   Standard deviation &                   -- &                  -- &  0.156 $\\pm$  0.012 &                  -- \\\\\n",
      "                     &       &    Pec. vel. removed &                   -- &                  -- &  0.143 $\\pm$  0.013 &                  -- \\\\\n",
      "\\hline\n",
      "    Maximum spectrum &   127 &                 NMAD &   0.110 $\\pm$  0.012 &  0.081 $\\pm$  0.012 &  0.100 $\\pm$  0.013 &  0.103 $\\pm$  0.013 \\\\\n",
      "    + SALT2 fit cuts &       &   Standard deviation &   0.131 $\\pm$  0.011 &  0.100 $\\pm$  0.008 &  0.140 $\\pm$  0.013 &  0.117 $\\pm$  0.008 \\\\\n",
      "                     &       &    Pec. vel. removed &   0.114 $\\pm$  0.012 &  0.076 $\\pm$  0.010 &  0.125 $\\pm$  0.014 &  0.098 $\\pm$  0.009 \\\\\n",
      "\\hline\n",
      "            All cuts &   127 &                 NMAD &   0.110 $\\pm$  0.012 &  0.081 $\\pm$  0.012 &  0.100 $\\pm$  0.013 &  0.103 $\\pm$  0.013 \\\\\n",
      "                     &       &   Standard deviation &   0.131 $\\pm$  0.011 &  0.100 $\\pm$  0.008 &  0.140 $\\pm$  0.013 &  0.117 $\\pm$  0.008 \\\\\n",
      "                     &       &    Pec. vel. removed &   0.114 $\\pm$  0.012 &  0.076 $\\pm$  0.010 &  0.125 $\\pm$  0.015 &  0.098 $\\pm$  0.009 \\\\\n"
     ]
    }
   ],
   "source": [
    "def int_disp(vals, pec_vel_disps, axis=None):\n",
    "    std = np.std(vals, ddof=1, axis=axis)\n",
    "    corr = np.mean(pec_vel_disps**2, axis=axis)\n",
    "    corr_std = np.sqrt(np.clip(std**2 - corr, 0, None))\n",
    "\n",
    "    return corr_std\n",
    "\n",
    "def get_stat_str(all_mags, cut, function, *args):\n",
    "    line_str = \"\"\n",
    "    for mags in all_mags:\n",
    "        if line_str:\n",
    "            line_str += \" &\"\n",
    "            \n",
    "        use_mags = mags[cut]\n",
    "        if np.any(np.isnan(use_mags)):\n",
    "            line_str += \"%20s\" % \"--\"\n",
    "        else:\n",
    "            res, res_err = math.bootstrap_statistic(function, use_mags, *args)\n",
    "            line_str += \"%7.3f $\\pm$ %6.3f\" % (res, res_err)\n",
    "    \n",
    "    line_str += \" \\\\\\\\\"\n",
    "    \n",
    "    return line_str\n",
    "\n",
    "def make_table(f, all_mags, cut, label):\n",
    "    stats = {\n",
    "        'NMAD': (math.nmad,),\n",
    "        'Standard deviation': (np.std,),\n",
    "        'Pec. vel. removed': (int_disp, a.get_peculiar_velocity_uncertainty()[cut]),\n",
    "    }\n",
    "    for i, (stat_name, stat_args) in enumerate(stats.items()):\n",
    "        if len(label) > i:\n",
    "            prefix = label[i]\n",
    "        else:\n",
    "            prefix = \"\"\n",
    "            \n",
    "        if i == 0:\n",
    "            num_sne = \"%d\" % np.sum(cut)\n",
    "        else:\n",
    "            num_sne = \"\"\n",
    "            \n",
    "        stat_str = get_stat_str(all_mags, cut, *stat_args)\n",
    "        utils.latex_print(f, \"%20s & %5s & %20s & %s\" % (prefix, num_sne, stat_name, stat_str))\n",
    "        \n",
    "good_mag_mask = a.uncertainty_mask & a.redshift_color_mask\n",
    "good_salt_mask = a.redshift_color_mask & a.salt_mask\n",
    "good_salt_isomap_mask = a.uncertainty_mask & a.redshift_color_mask & a.salt_mask\n",
    "\n",
    "# RBTL only\n",
    "rbtl_mags = a.rbtl_mags.copy()\n",
    "rbtl_mags[~good_mag_mask] = np.nan\n",
    "        \n",
    "# RBTL + Isomap\n",
    "a.fit_gp()\n",
    "rbtl_isomap_mags = a.corr_mags.copy()\n",
    "rbtl_isomap_mags[~good_mag_mask] = np.nan\n",
    "\n",
    "# SALT2\n",
    "salt_mags = a.salt_hr.copy()\n",
    "salt_mags[~good_salt_mask] = np.nan\n",
    "\n",
    "# SALT2 + Isomap\n",
    "a.fit_gp(kind='salt_raw')\n",
    "salt_isomap_mags = a.corr_mags.copy()\n",
    "salt_isomap_mags[~good_salt_isomap_mask] = np.nan\n",
    "\n",
    "all_mags = [rbtl_mags, rbtl_isomap_mags, salt_mags, salt_isomap_mags]\n",
    "\n",
    "with open('./latex/dispersions.tex', 'w') as f:\n",
    "    # RBTL only\n",
    "    make_table(f, all_mags, good_mag_mask, ['Maximum spectrum', '+ training cuts'])\n",
    "    utils.latex_print(f, \"\\hline\")\n",
    "\n",
    "    # SALT2 only\n",
    "    make_table(f, all_mags, good_salt_mask, ['SALT2 fit cuts'])\n",
    "    utils.latex_print(f, \"\\hline\")\n",
    "\n",
    "    # SALT2 + Isomap\n",
    "    make_table(f, all_mags, good_salt_isomap_mask, ['Maximum spectrum', '+ SALT2 fit cuts'])\n",
    "    utils.latex_print(f, \"\\hline\")\n",
    "\n",
    "    # All\n",
    "    make_table(f, all_mags, good_salt_isomap_mask, ['All cuts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Optimization terminated successfully.\n",
      "    Color scale:          -0.127 ± 0.051\n",
      "    Intrinsic dispersion: 0.064 ± 0.009 mag\n",
      "    GP kernel amplitude:  0.177 ± 0.089 mag\n",
      "    GP length scale:      5.553 ± 3.271\n",
      "    Fit NMAD:             0.081 mag\n",
      "    Fit std:              0.100 mag\n"
     ]
    }
   ],
   "source": [
    "a.fit_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09975133114394495"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(a.corr_mags[a.uncertainty_mask & a.redshift_color_mask & a.salt_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'name': [i.name for i in a.targets],\n",
    "    't1': a.embedding[:, 0],\n",
    "    't2': a.embedding[:, 1],\n",
    "    't3': a.embedding[:, 2],\n",
    "    # 'salt_x1': a.salt_x1,\n",
    "    # 'salt_mag': a.salt_hr,\n",
    "}).to_csv('./manifold_parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for people after Dec. 12 VC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SN2006X comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: SN2006X fails the interpolation cut, so first have to add it back in.\n",
    "mask = np.array([i.name == 'SN2006X' for i in a.targets])\n",
    "a.interp_mask[mask] = True\n",
    "a.do_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(-a.embedding[:, 0], a.embedding[:, 1])\n",
    "\n",
    "plt.scatter(-a.embedding[mask, 0], a.embedding[mask, 1], label='SN2006X')\n",
    "plt.legend()\n",
    "plt.xlabel('Isomap Component 1')\n",
    "plt.ylabel('Isomap Component 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "m2 = a.embedding[:, 0] > 4\n",
    "plt.plot(a.wave, a.scale_flux[mask].T * spectrum_plot_scale[:, None], c='C1', label='SN2006X')\n",
    "plt.plot(a.wave, a.scale_flux[m2].T * spectrum_plot_scale[:, None], c='C0', label='Nearby SNe Ia')\n",
    "plt.plot(a.wave, a.scale_flux[mask].T * spectrum_plot_scale[:, None], c='C1', label='SN2006X')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.legend(['SN2006X', 'Nearby SNe Ia'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.interp_mask[mask] = False\n",
    "a.do_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[:, 0], a.embedding[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolations for unusual SNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_counts = np.array([np.sum(a.target_map == i) for i in range(len(a.targets))])\n",
    "\n",
    "found = np.where((a.embedding[:, 1] > 4) & (spec_counts >= 3))[0]\n",
    "print(found)\n",
    "a.targets[found]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"unusual_sne_interpolations.pdf\")\n",
    "\n",
    "plot_targets = ['PTF11mkx', 'SNF20071021-000', 'PTF11kjn']\n",
    "\n",
    "for plot_target in plot_targets:\n",
    "    target_names = np.array([i.name for i in a.targets])\n",
    "    plot_idx = np.where(target_names == plot_target)[0][0]\n",
    "\n",
    "    fig1, fig2, fig3 = plot_same_night(plot_idx, figsize=(8, 5))\n",
    "    \n",
    "    # pdf.savefig(fig1)\n",
    "    fig2.gca().set_title(f'{plot_target} - Model')\n",
    "    pdf.savefig(fig2)\n",
    "    fig3.gca().set_title(f'{plot_target} - Residuals')\n",
    "    pdf.savefig(fig3)\n",
    "    \n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran with only wavelengths bluer than 6000 AA and saved the results to this file.\n",
    "# np.savetxt('./test_blue_6000_intrinsic_dispersion.txt',\n",
    "           #np.vstack([a.wave, frac_to_mag(a.rbtl_result['fractional_dispersion'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave, int_disp = np.genfromtxt('./test_blue_6000_intrinsic_dispersion.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "intrinsic_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "\n",
    "plt.plot(a.wave, intrinsic_dispersion, label='Full fit')\n",
    "plt.plot(wave, int_disp, label='Fit to $\\lambda$<6000$\\AA$ only')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel('Intrinsic dispersion (mag)')\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/rbtl_intrinsic_dispersion.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-folding the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_interp_mask = a.interp_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (6., 5.)\n",
    "\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"k_fold_manifold.pdf\")\n",
    "\n",
    "folds = np.random.randint(0, 5, size=len(a.interp_mask))\n",
    "\n",
    "for i in range(5):\n",
    "    a.interp_mask = orig_interp_mask & (folds != i)\n",
    "    a.do_embedding()\n",
    "    a.do_component_blondin_plot()\n",
    "    pdf.savefig(plt.gcf())\n",
    "pdf.close()\n",
    "\n",
    "a.interp_mask = orig_interp_mask\n",
    "a.do_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of the size of the phase differences vs the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_diff = evaluate_phase_difference(2.5) - evaluate_phase_difference(-2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_max = np.median(a.scale_flux[a.embedding[:, 0] > np.nanpercentile(a.embedding[:, 0], 90)], axis=0)\n",
    "t1_min = np.median(a.scale_flux[a.embedding[:, 0] > np.nanpercentile(a.embedding[:, 0], 10)], axis=0)\n",
    "t2_max = np.median(a.scale_flux[a.embedding[:, 1] > np.nanpercentile(a.embedding[:, 1], 90)], axis=0)\n",
    "t2_min = np.median(a.scale_flux[a.embedding[:, 1] > np.nanpercentile(a.embedding[:, 1], 10)], axis=0)\n",
    "t3_max = np.median(a.scale_flux[a.embedding[:, 2] > np.nanpercentile(a.embedding[:, 2], 90)], axis=0)\n",
    "t3_min = np.median(a.scale_flux[a.embedding[:, 2] > np.nanpercentile(a.embedding[:, 2], 10)], axis=0)\n",
    "\n",
    "t1_diff = -2.5*np.log10(t1_max / t1_min)\n",
    "t2_diff = -2.5*np.log10(t2_max / t2_min)\n",
    "t3_diff = -2.5*np.log10(t3_max / t3_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(phase_diff**2))\n",
    "print(np.sum(t1_diff**2))\n",
    "print(np.sum(t2_diff**2))\n",
    "print(np.sum(t3_diff**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, t1_diff)\n",
    "plt.plot(a.wave, t2_diff)\n",
    "plt.plot(a.wave, t3_diff)\n",
    "plt.plot(a.wave, phase_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.interpolation_result['phase_slope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_phase = a.interpolation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNe Ia missing host galaxy properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in a.targets[0].meta.keys() if 'salt2' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.host_data['name'][-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a.host_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a.host_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = a.interp_mask & a.redshift_color_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.redshifts[np.array([i.name == 'SN2005ki' for i in a.targets])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a.targets[mm & ~a.good_mag_mask & ~a.host_mask]:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.redshifts, a.mags, c=a.good_mag_mask & ~a.host_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNfactory timeseries example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 7))\n",
    "a.targets[101].plot(f_nu=True, offset_factor=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_model = sncosmo.Model(source='salt2')\n",
    "\n",
    "salt_model.set(z=0.001)\n",
    "salt_model.set(t0=0)\n",
    "salt_model.set(x0=1.7e4)\n",
    "salt_model.set_source_peakmag(0, 'snfb', 'ab')\n",
    "\n",
    "times = np.linspace(-15, 30, 100)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "for x1 in np.arange(-2, 2, 0.5):\n",
    "    salt_model.set(x1=x1)\n",
    "    mag = salt_model.bandmag('snfb', 'ab', times) - 0.05 * x1\n",
    "    plt.plot(times, mag, c=plt.cm.coolwarm(x1 / 4 + 0.5))\n",
    "    \n",
    "plt.ylim(3, -0.5)\n",
    "plt.ylabel('Relative brightness (mag)')\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_model = sncosmo.Model(source='salt2')\n",
    "\n",
    "salt_model.set(z=0.001)\n",
    "salt_model.set(t0=0)\n",
    "salt_model.set(x0=1.7e4)\n",
    "salt_model.set_source_peakmag(0, 'snfb', 'ab')\n",
    "\n",
    "times = np.linspace(-15, 30, 100)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "for c in np.arange(0, 0.3, 0.04):\n",
    "    salt_model.set(c=c)\n",
    "    flux = salt_model.flux(0, a.wave)\n",
    "    # mag = salt_model.bandmag('snfb', 'ab', times) - 0.05 * x1\n",
    "    # plt.plot(times, mag, c=plt.cm.coolwarm(x1 / 4 + 0.5))\n",
    "    plt.plot(a.wave, flux*1e9 * 10**(0.4 * 3.1 * c), c=plt.cm.coolwarm_r(c / 0.3))\n",
    "    \n",
    "# plt.ylim(3, -0.5)\n",
    "plt.ylabel('Flux')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_model = sncosmo.Model(source='salt2')\n",
    "\n",
    "salt_model.set(z=0.001)\n",
    "salt_model.set(t0=0)\n",
    "salt_model.set(x0=1e14)\n",
    "# salt_model.set_source_peakmag(0, 'snfb', 'ab')\n",
    "\n",
    "times = np.linspace(-15, 30, 100)\n",
    "\n",
    "wave = a.wave\n",
    "\n",
    "ref_spec = salt_model.flux(0, wave)\n",
    "salt_model.set(x1=1)\n",
    "x1_spec = salt_model.flux(0, wave) - ref_spec\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(a.wave, ref_spec * spectrum_plot_scale)\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel('Flux')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(a.wave, x1_spec * spectrum_plot_scale)\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel('Flux')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1, 2), dpi=300)\n",
    "plt.title(\"$+ x_2 \\cdot$ ...\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_steps_values(values, num_steps=10, xlim=None, figsize=spectrum_plot_figsize, colorbar=True, label=''):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = values[mask]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "\n",
    "    # min_embedding = np.percentile(use_embedding, 5)\n",
    "    # max_embedding = np.percentile(use_embedding, 95)\n",
    "    min_embedding = np.min(use_embedding)\n",
    "    max_embedding = np.max(use_embedding)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    plt.figure(figsize=figsize, dpi=250)\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "\n",
    "    if xlim is not None:\n",
    "        wave_mask = (a.wave > xlim[0] - 50) & (a.wave < xlim[1] + 50)\n",
    "    else:\n",
    "        wave_mask = np.ones(len(a.wave), dtype=bool)\n",
    "        \n",
    "    all_step_flux = []\n",
    "    all_mean_vals = []\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        # if step == 0:\n",
    "            # label = 'Median spectra in each component bin'\n",
    "        # else:\n",
    "            # label = ''\n",
    "            \n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val - np.mean(values))\n",
    "        \n",
    "        # plt.plot(a.wave[wave_mask], step_flux[wave_mask], c=sm.to_rgba(mean_val), label=label)\n",
    "        plt.plot(a.wave[wave_mask], step_flux[wave_mask] * spectrum_plot_scale[wave_mask], c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "        \n",
    "        all_step_flux.append(step_flux)\n",
    "        all_mean_vals.append(mean_val)\n",
    "        \n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "        \n",
    "    if colorbar:\n",
    "        plt.colorbar(sm, label=label)\n",
    "        # plt.title('Component %d' % (component + 1))\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel('Flux')\n",
    "    plt.ylim(0, None)\n",
    "    \n",
    "    # plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # if xlim is None:\n",
    "        # plt.savefig('./figures/component_%d_steps.pdf' % (component + 1))\n",
    "    # else:\n",
    "        # plt.savefig('./figures/component_%d_steps_zoom_%d_%d.pdf' % (component + 1, xlim[0], xlim[1]))\n",
    "        \n",
    "    return np.array(all_mean_vals), np.array(all_step_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_vel, step_flux = plot_steps_values(-a.spectral_indicators['vSiII6355'] - 11000, 15, figsize=(4, 3), colorbar=False)\n",
    "# step_vel, step_flux = plot_steps_values(-a.spectral_indicators['vSiII6355'] / 1000, 20, xlim=(5800, 6400), figsize=(5, 3), label='Si II line velocity ($10^3$ km/s)')\n",
    "step_vel, step_flux = plot_steps_values(a.spectral_indicators['EWSiII6355'], 30, xlim=(5800, 6400), figsize=(4, 3), label='Si II line velocity ($10^3$ km/s)', colorbar=False)\n",
    "plt.ylim(0.1, 0.5)\n",
    "# plt.tight_layout()\n",
    "# plt.ylabel('Flux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = 182\n",
    "idx2 = 188\n",
    "plt.axvline(a.wave[idx1], ls='--', c='k', lw=2, zorder=1000)\n",
    "plt.axvline(a.wave[idx2], ls='--', c='k', lw=2, zorder=1000)\n",
    "\n",
    "plt.figure(figsize=(4, 3), dpi=250)\n",
    "plt.scatter(step_flux[:, 182], step_flux[:, 188], c=step_vel, cmap=plt.cm.coolwarm, s=50)\n",
    "plt.xlabel('Flux at %d $\\AA$' % a.wave[idx1])\n",
    "plt.ylabel('Flux at %d $\\AA$' % a.wave[idx2])\n",
    "plt.colorbar(label='Si II line velocity ($10^3$ km/s)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = 180\n",
    "plt.scatter(step_vel, step_flux[:, idx], label='%d $\\AA$' % a.wave[idx])\n",
    "idx = 183\n",
    "plt.scatter(step_vel, step_flux[:, idx], label='%d $\\AA$' % a.wave[idx])\n",
    "idx = 190\n",
    "plt.scatter(step_vel, step_flux[:, idx], label='%d $\\AA$' % a.wave[idx])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "wave = np.linspace(0, 100, 100)\n",
    "\n",
    "def sim_line(vel, depth):\n",
    "    val = 1 / np.sqrt(np.pi * )\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(a.wave, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_91t = [ \n",
    "    'SNF20070528-003', # Scalzo++ 2014\n",
    "    'SNF20070803-005', # Scalzo++ 2014\n",
    "    'SNF20070825-001', # Scalzo++ 2010\n",
    "    'SNF20070912-000', # Scalzo++ 2014\n",
    "    'SNF20080522-000', # Scalzo++ 2014\n",
    "    'SNF20080723-012', # Scalzo++ 2014\n",
    "    'SNF20080805-007', # Lin++ 2020\n",
    "    'LSQ12cyz', # Lin++ 2020\n",
    "    'LSQ12fhe', # Lin++ 2020\n",
    "    'PTF11bju', # Lin++ 2020\n",
    "    'PTF11mkx', # Lin++ 2020\n",
    "]\n",
    "\n",
    "outliers_91bg = [\n",
    "    'LSQ12cfx', # Lin++ 2020\n",
    "    'PTF10ops', # Maguire++ 2011\n",
    "    'PTF11bkf', # Lin++ 2020\n",
    "    'PTF11kjn', # Lin++ 2020\n",
    "    'PTF11okh', # Lin++ 2020\n",
    "    'PTF11pra', # Lin++ 2020\n",
    "    'PTF12dwm', # Lin++ 2020\n",
    "    'SN2005bl', # Lin++ 2020\n",
    "    'SN2005dh', # Lin++ 2020 \n",
    "    'SN2005dm', # Lin++ 2020\n",
    "    'SN2007ba', # Lin++ 2020\n",
    "    'SN2009hs', # Lin++ 2020\n",
    "    'SNNGC6430', # Lin++ 2020\n",
    "]\n",
    "\n",
    "outliers_02cx = [\n",
    "    'SN2005cc', # Lin++ 2020\n",
    "]\n",
    "\n",
    "mask_91t = np.array([i.name in outliers_91t for i in a.targets])\n",
    "mask_91bg = np.array([i.name in outliers_91bg for i in a.targets])\n",
    "mask_02cx = np.array([i.name in outliers_02cx for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09715c03ece242d5a5b5a512dd501f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "use_x = a.embedding[:, 0]\n",
    "\n",
    "mask = a.salt_mask & a.redshift_color_mask & a.uncertainty_mask\n",
    "plt.errorbar(use_x[mask], a.salt_hr[mask], a.salt_hr_uncertainties[mask], label='Individual supernovae', fmt='.', alpha=0.2, c='k')\n",
    "math.plot_binned_mean(use_x[mask], a.salt_hr[mask], c='C3', lw=2, label='Binned mean')\n",
    "\n",
    "# mask = mask & mask_91t\n",
    "# plt.scatter(use_x[mask], a.salt_hr[mask], label='91T-like SNe IA', c='C2', marker='s', zorder=10)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('SALT2 Hubble residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/home/kyle/supernova/meetings/2020_01_04_aas_hawaii/talk/salt_bias.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556449836c3248d7920913565b8bc327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_plot(label, mask=None, **kwargs):\n",
    "    if mask is None:\n",
    "        mask = a.uncertainty_mask\n",
    "    else:\n",
    "        mask = mask & a.uncertainty_mask\n",
    "\n",
    "    plt.scatter(a.embedding[mask, 0], a.embedding[mask, 1], label=label, s=50, **kwargs)\n",
    "    \n",
    "plt.figure()\n",
    "do_plot('All SNe Ia', c='k', alpha=0.1)\n",
    "do_plot('91T-like', mask_91t)\n",
    "do_plot('91bg-like', mask_91bg)\n",
    "do_plot('02cx-like', mask_02cx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 150\n",
    "loc = -0.5 + np.random.uniform(0, 2 * np.pi - 2, N)\n",
    "x = np.cos(loc) + np.random.normal(0, 0.1, N)\n",
    "y = np.sin(2 * loc) + np.random.normal(0, 0.1, N)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x, y, c='k', s=20)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/home/kyle/supernova/meetings/2020_01_04_aas_hawaii/talk/manifold_sim.png')\n",
    "\n",
    "for iter_x, iter_y in zip(x, y):\n",
    "    closest = np.argsort((x - iter_x)**2 + (y - iter_y)**2)\n",
    "    for i in closest[:8]:\n",
    "        plt.plot([iter_x, x[i]], [iter_y, y[i]], c='C3', alpha=0.3)\n",
    "        \n",
    "plt.savefig('/home/kyle/supernova/meetings/2020_01_04_aas_hawaii/talk/manifold_sim_neighbors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dataset.targets[100].spectra[0].wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([IdrSpectrum(target=\"SNF20080812-003\", name=\"SNF20080812-003_08229081003\", phase=-5.611)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dataset.get_target('SNF20080812-003').spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=bool)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.redshift_color_mask[np.array([i.name == 'SNF20080812-003' for i in a.targets])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_redshifts = Table.read('./data/greg_updated_redshifts.txt', format='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=55</i>\n",
       "<table id=\"table139703370437328\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>col1</th><th>col2</th><th>col3</th><th>col4</th><th>col5</th><th>col6</th></tr></thead>\n",
       "<thead><tr><th>str15</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>PTF11bnb</td><td>0.03</td><td>0.005</td><td>0.0416</td><td>0.0005</td><td>-0.0116</td></tr>\n",
       "<tr><td>SNF20080812-003</td><td>0.052</td><td>0.006</td><td>0.0617</td><td>0.0005</td><td>-0.0097</td></tr>\n",
       "<tr><td>SNF20080918-004</td><td>0.051</td><td>0.005</td><td>0.0574</td><td>0.0025</td><td>-0.0064</td></tr>\n",
       "<tr><td>PTF10qyz</td><td>0.065</td><td>0.005</td><td>0.0683</td><td>0.0025</td><td>-0.0033</td></tr>\n",
       "<tr><td>PTF13asv</td><td>0.034</td><td>0.005</td><td>0.0366</td><td>0.0025</td><td>-0.0026</td></tr>\n",
       "<tr><td>PTF11mkx</td><td>0.05482</td><td>0.001</td><td>0.0566</td><td>0.0005</td><td>-0.00178</td></tr>\n",
       "<tr><td>LSQ13bbz</td><td>0.06</td><td>0.02</td><td>0.0612</td><td>0.0005</td><td>-0.0012</td></tr>\n",
       "<tr><td>PTF10ops</td><td>0.06</td><td>0.01</td><td>0.0612</td><td>0.0025</td><td>-0.0012</td></tr>\n",
       "<tr><td>SNF20080905-005</td><td>0.0579</td><td>0.005</td><td>0.0588</td><td>0.0025</td><td>-0.0009</td></tr>\n",
       "<tr><td>SN2005ak</td><td>0.02671</td><td>0.00181</td><td>0.02744</td><td>6e-05</td><td>-0.00073</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>SN2006ac</td><td>0.02328</td><td>0.0</td><td>0.02311</td><td>4e-05</td><td>0.00017</td></tr>\n",
       "<tr><td>SNF20060514-003</td><td>0.088</td><td>0.005</td><td>0.0878</td><td>0.0025</td><td>0.0002</td></tr>\n",
       "<tr><td>SN2007qe</td><td>0.02397</td><td>4e-05</td><td>0.02371</td><td>0.00073</td><td>0.00025</td></tr>\n",
       "<tr><td>SN2005ki</td><td>0.01951</td><td>5e-05</td><td>0.01921</td><td>2e-05</td><td>0.0003</td></tr>\n",
       "<tr><td>SN2009hs</td><td>0.02779</td><td>4e-05</td><td>0.02746</td><td>8e-05</td><td>0.00033</td></tr>\n",
       "<tr><td>LSQ12hvj</td><td>0.07217</td><td>0.0005</td><td>0.0713</td><td>0.0005</td><td>0.00087</td></tr>\n",
       "<tr><td>PTF11ppn</td><td>0.07</td><td>0.005</td><td>0.0669</td><td>0.0005</td><td>0.0031</td></tr>\n",
       "<tr><td>SNF20070822-004</td><td>0.089</td><td>0.002</td><td>0.0858</td><td>0.0005</td><td>0.0032</td></tr>\n",
       "<tr><td>LSQ12hzj</td><td>0.037</td><td>0.01</td><td>0.0333</td><td>0.0005</td><td>0.0037</td></tr>\n",
       "<tr><td>LSQ12eks</td><td>0.094</td><td>0.005</td><td>0.0895</td><td>0.0005</td><td>0.0045</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=55>\n",
       "      col1        col2    col3    col4    col5    col6  \n",
       "     str15      float64 float64 float64 float64 float64 \n",
       "--------------- ------- ------- ------- ------- --------\n",
       "       PTF11bnb    0.03   0.005  0.0416  0.0005  -0.0116\n",
       "SNF20080812-003   0.052   0.006  0.0617  0.0005  -0.0097\n",
       "SNF20080918-004   0.051   0.005  0.0574  0.0025  -0.0064\n",
       "       PTF10qyz   0.065   0.005  0.0683  0.0025  -0.0033\n",
       "       PTF13asv   0.034   0.005  0.0366  0.0025  -0.0026\n",
       "       PTF11mkx 0.05482   0.001  0.0566  0.0005 -0.00178\n",
       "       LSQ13bbz    0.06    0.02  0.0612  0.0005  -0.0012\n",
       "       PTF10ops    0.06    0.01  0.0612  0.0025  -0.0012\n",
       "SNF20080905-005  0.0579   0.005  0.0588  0.0025  -0.0009\n",
       "       SN2005ak 0.02671 0.00181 0.02744   6e-05 -0.00073\n",
       "            ...     ...     ...     ...     ...      ...\n",
       "       SN2006ac 0.02328     0.0 0.02311   4e-05  0.00017\n",
       "SNF20060514-003   0.088   0.005  0.0878  0.0025   0.0002\n",
       "       SN2007qe 0.02397   4e-05 0.02371 0.00073  0.00025\n",
       "       SN2005ki 0.01951   5e-05 0.01921   2e-05   0.0003\n",
       "       SN2009hs 0.02779   4e-05 0.02746   8e-05  0.00033\n",
       "       LSQ12hvj 0.07217  0.0005  0.0713  0.0005  0.00087\n",
       "       PTF11ppn    0.07   0.005  0.0669  0.0005   0.0031\n",
       "SNF20070822-004   0.089   0.002  0.0858  0.0005   0.0032\n",
       "       LSQ12hzj   0.037    0.01  0.0333  0.0005   0.0037\n",
       "       LSQ12eks   0.094   0.005  0.0895  0.0005   0.0045"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = upd_redshifts\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [i.name for i in a.targets]\n",
    "\n",
    "use_mask = np.zeros(len(t), dtype=bool)\n",
    "\n",
    "for i, name in enumerate(t['col1']):\n",
    "    use_mask[i] = name in target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTF11mkx 0.0566 0.07212223217248948 mag\n",
      "SN2007bd 0.03102 0.04191017490165194 mag\n",
      "SN2005cg 0.03176 0.02532730616020018 mag\n",
      "SNF20060521-001 0.06698 0.010542177126986019 mag\n",
      "SNF20080514-002 0.02206 0.018081582166928456 mag\n",
      "SN2004ef 0.03098 0.010778463260528781 mag\n",
      "SN2007qe 0.02371 -0.024101040511794736 mag\n"
     ]
    }
   ],
   "source": [
    "m = (t['col3'] < 0.004)\n",
    "diffs = (t['col4'] - t['col2'])[m & use_mask]\n",
    "from astropy.cosmology import Planck15 as cosmo\n",
    "\n",
    "for row in t[m & use_mask]:\n",
    "    cosmo_diff = cosmo.distmod(row['col4']) - cosmo.distmod(row['col2'])\n",
    "    z = np.array([i.name == row['col1'] for i in a.targets])\n",
    "    if (np.abs(cosmo_diff.value) > 0.01) & a.redshift_color_mask[z]:\n",
    "        print(row['col1'], row['col4'], cosmo_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.069283])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([i.name == 'SN2004ef' for i in a.targets])\n",
    "a.corr_mags[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.train_mask[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0f39c3f710>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter([i['host.zhelio.err'] for i in a.targets[a.redshift_color_mask]], a.corr_mags[a.redshift_color_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a225a965e54a6a8e8c6955bb58a679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Component 2')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(np.sqrt(a.embedding[:, 0]**2 + a.embedding[:, 2]**2), a.embedding[:, 1], s=20)\n",
    "\n",
    "plt.xlabel('R = sqrt(C1^2 + C3^2)')\n",
    "plt.ylabel('Component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on with Mickael's sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03227949 -0.02095304  0.19496385  0.13502417 -0.01226244 -0.08559092]\n",
      "Step size: -0.053 ± 0.028 mag\n",
      "Median step: -0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n",
      "/home/kyle/packages/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py:697: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809692936e2f4cc3b71d13d4270c343d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.03227949291230736, -0.02095303978530645, -0.05323253269761381) (0.02287181031221938, 0.015494234564298468, 0.027625911961266476)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.05323253269761381, 0.027625911961266476)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rigault_data = Table.read('./data/host_properties_rigault_2019.txt', format='ascii')\n",
    "rigault_mask = np.array([a.iau_name_map.get(i.name, i.name) in rigault_data['name'] for i in a.targets])\n",
    "\n",
    "remove_list = [\n",
    "    # SNREDSHIFT - most likely wrong host\n",
    "    # \"CSS110918_01\",\n",
    "    # \"PTF10qyz\",\n",
    "    # \"PTF10ufj\",\n",
    "    # \"SNF20060908-004\",\n",
    "    # \"SNF20080918-004\",\n",
    "    # \"SNF20070817-003\",\n",
    "    \n",
    "    \n",
    "    # Photo Optical data are unusable and no SNfactory optical data.\n",
    "    \"PTF09fox\",\n",
    "    \"SN2004gs\",\n",
    "    \"SNF20080919-000\",\n",
    "    \"SNF20080626-002\",\n",
    "    \n",
    "    # Spectral Data are unuable\n",
    "    \"PTF13asv\",\n",
    "    \n",
    "    \n",
    "    # HUBBLIZER - Bad in the zoo, Nico removed it for any reason.\n",
    "    # \"LSQ12gxj\",\n",
    "    \n",
    "    # PECULIARS - JAKOB / GREG\n",
    "    # \"PTF10ygu\",\n",
    "    # \"PTF10ops\",\n",
    "    \n",
    "    # SUPERC_91T\n",
    "    # \"SNF20070528-003\",\"SNF20070803-005\",\"SN2007if\",\n",
    "    # \"SNF20070912-000\",\"SNF20080522-000\",\"SNF20080723-012\", # SCALZO et al 2012\n",
    "    # \"SN2012dn\", # Childress 2016 Super-C\n",
    "    # \"LSQ12cyz\", \"PTF11bju\",\"SNNGC2691\", \"LSQ12gdj\",\"LSQ12fhe\", \"PTF11mkx\",\n",
    "    \n",
    "    \n",
    "    # PTF collaboration\n",
    "    # \"PTF13anh\",\"PTF13ayw\",\"PTF13azs\",\"PTF13asv\",\n",
    "    # \"PTF12jqh\",\"PTF11bgv\",\"PTF11drz\",\"PTF12eer\",\n",
    "    # \"PTF12evo\", \"PTF12fuu\",\"PTF12ghy\",\"PTF12grk\",\n",
    "    # \"PTF12ikt\",\n",
    "]\n",
    "\n",
    "extra_mask = np.array([i.name not in remove_list for i in a.targets])\n",
    "\n",
    "analyze_host_variable(\n",
    "    'gmass',\n",
    "    \n",
    "    # rbtl_isomap_mags,\n",
    "    # salt_isomap_mags,\n",
    "    a.salt_hr,\n",
    "    # rigault_data['HR'],\n",
    "\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask & a.train_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask & a.train_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,# & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask,\n",
    "    # rigault_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask, #extra_mask & a.salt_mask,# & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & (a.maximum_uncertainty_fraction > 0.2),\n",
    "    # rigault_mask & a.train_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,#& a.redshift_color_mask & a.uncertainty_mask,\n",
    "    # rigault_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,\n",
    "    extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,# & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask,\n",
    "    # extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,# & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask,\n",
    "\n",
    "    a.salt_hr_raw_uncertainties,\n",
    "    # a.host_data['HR.err'],\n",
    "    y_label='SALT2 + $x_1$ residual magnitudes'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02660507560282821,\n",
       " 0.026354678600011283,\n",
       " 0.03136053025249885,\n",
       " 0.07040706468939884,\n",
       " 0.03293767593120367,\n",
       " 0.08108187220578844,\n",
       " 0.07214453551620825,\n",
       " 0.033426754770932154,\n",
       " 0.03331427608026649,\n",
       " 0.0573387253533606,\n",
       " 0.05357493286085502,\n",
       " 0.0564835940826256,\n",
       " 0.06567250373061562,\n",
       " 0.04863297118741028,\n",
       " 0.06936814625875565,\n",
       " 0.04408730097152369,\n",
       " 0.047075296617337115,\n",
       " 0.06349718249109948,\n",
       " 0.05418686093515612,\n",
       " 0.02583569279038378,\n",
       " 0.0303070618213106,\n",
       " 0.09327102520605712,\n",
       " 0.08149881202575204,\n",
       " 0.030443252892658368,\n",
       " 0.06917777445666973,\n",
       " 0.08342003469170711,\n",
       " 0.08834381831953686,\n",
       " 0.04627214726196316,\n",
       " 0.07484683494534972,\n",
       " 0.0851775007503206,\n",
       " 0.026714525990187532]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.redshift_cmb for i in a.targets[\n",
    "    rigault_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask\n",
    "    !=\n",
    "    extra_mask & a.salt_mask & a.redshift_color_mask & a.uncertainty_mask,\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "likelihood_step() missing 1 required positional argument: 'prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ba27e7fd5b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mrigault_data_cut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrigault_data_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextra_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihood_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrigault_data_cut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrigault_data_cut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p(highgmass)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrigault_data_cut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HR.err'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step size: %.3f $\\pm$ %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: likelihood_step() missing 1 required positional argument: 'prob'"
     ]
    }
   ],
   "source": [
    "rigault_data_full = Table.read('./data/host_properties_rigault_full.csv', format='csv')\n",
    "# rigault_mask = np.array([a.iau_name_map.get(i.name, i.name) in rigault_data['name'] for i in a.targets])\n",
    "\n",
    "remove_list = [\n",
    "    # HUBBLIZER - Bad in the zoo, Nico removed it for any reason.\n",
    "    \"LSQ12gxj\",\n",
    "    \n",
    "    # SNREDSHIFT - most likely wrong host\n",
    "    \"CSS110918_01\",\n",
    "    \"PTF10qyz\",\n",
    "    \"PTF10ufj\",\n",
    "    \"SNF20060908-004\",\n",
    "    \"SNF20080918-004\",\n",
    "    \"SNF20070817-003\",\n",
    "    \n",
    "    # PECULIARS - JAKOB / GREG\n",
    "    \"PTF10ygu\",\n",
    "    \"PTF10ops\",\n",
    "    \n",
    "    # Photo Optical data are unusable and no SNfactory optical data.\n",
    "    \"PTF09fox\",\n",
    "    \"SN2004gs\",\n",
    "    \"SNF20080919-000\",\n",
    "    \"SNF20080626-002\",\n",
    "    \n",
    "    # Spectral Data are unuable\n",
    "    \"PTF13asv\",\n",
    "    \n",
    "    # SUPERC_91T\n",
    "    \"SNF20070528-003\",\"SNF20070803-005\",\"SN2007if\",\n",
    "    \"SNF20070912-000\",\"SNF20080522-000\",\"SNF20080723-012\", # SCALZO et al 2012\n",
    "    \"SN2012dn\", # Childress 2016 Super-C\n",
    "    \"LSQ12cyz\", \"PTF11bju\",\"SNNGC2691\", \"LSQ12gdj\",\"LSQ12fhe\", \"PTF11mkx\",\n",
    "    \n",
    "    # PTF collaboration\n",
    "    \"PTF13anh\",\"PTF13ayw\",\"PTF13azs\",\"PTF13asv\",\n",
    "    \"PTF12jqh\",\"PTF11bgv\",\"PTF11drz\",\"PTF12eer\",\n",
    "    \"PTF12evo\", \"PTF12fuu\",\"PTF12ghy\",\"PTF12grk\",\n",
    "    \"PTF12ikt\",\n",
    "]\n",
    "\n",
    "extra_mask = np.array([i not in remove_list for i in rigault_data_full['name']])\n",
    "\n",
    "rigault_data_cut = rigault_data_full[extra_mask]\n",
    "\n",
    "res = likelihood_step(rigault_data_cut['HR'], rigault_data_cut['p(highgmass)'], rigault_data_cut['HR.err'])\n",
    "print(\"Step size: %.3f $\\pm$ %.3f\" % (res[0][2], res[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7671e496bad74813a5f926bede0051fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcc4c630990>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(rigault_data_cut['salt2.X1'], rigault_data_cut['HR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simultaneous host properties fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp_host(self, step_probabilities_1, step_probabilities_2, kind=\"rbtl\", start_hyperparameters=[0.0, 0.05, 0.2, 5, 0., 0.]):\n",
    "    \"\"\"Fit a Gaussian Process to predict the residual magnitudes.\"\"\"\n",
    "    self.print_verbose(\"Fitting GP hyperparameters...\")\n",
    "\n",
    "    # Fit the hyperparameters on the full conditioning sample.\n",
    "    coordinates, mags, mag_errs, colors, condition_mask = self.get_gp_data(kind)\n",
    "    \n",
    "    condition_mask &= self.host_mask\n",
    "\n",
    "    condition_coordinates = coordinates[condition_mask]\n",
    "    condition_mags = mags[condition_mask]\n",
    "    condition_mag_errs = mag_errs[condition_mask]\n",
    "    condition_colors = colors[condition_mask]\n",
    "    condition_step_probabilities_1 = step_probabilities_1[condition_mask]\n",
    "    condition_step_probabilities_2 = step_probabilities_2[condition_mask]\n",
    "\n",
    "    def negative_log_likelihood(hyperparameters):\n",
    "        gp, color_slope = self._build_gp(\n",
    "            condition_coordinates, condition_mag_errs, hyperparameters[:-2]\n",
    "        )\n",
    "        host_step_1 = hyperparameters[-2]\n",
    "        host_step_2 = hyperparameters[-1]\n",
    "        residuals = (\n",
    "            condition_mags\n",
    "            - condition_colors * color_slope\n",
    "            + host_step_1 * condition_step_probabilities_1\n",
    "            + host_step_2 * condition_step_probabilities_2\n",
    "        )\n",
    "        result = -gp.log_likelihood(residuals)\n",
    "\n",
    "        return result\n",
    "\n",
    "    res = minimize(negative_log_likelihood, start_hyperparameters)\n",
    "\n",
    "    self.gp_hyperparameters = res.x\n",
    "    self.gp_negative_log_likelihood = negative_log_likelihood\n",
    "\n",
    "    pred_mags, pred_vars = self._predict_gp_oos(\n",
    "        coordinates,\n",
    "        mags,\n",
    "        mag_errs,\n",
    "        colors,\n",
    "        condition_mask = condition_mask,\n",
    "        return_var=True,\n",
    "    )\n",
    "\n",
    "    self.corr_mags = mags - pred_mags\n",
    "    self.corr_vars = pred_vars + mag_errs**2\n",
    "    good_corr_mags = self.corr_mags[condition_mask]\n",
    "\n",
    "    # Calculate the parameter covariance using a custom code that numerically\n",
    "    # estimates the Hessian using a finite difference method with adaptive step\n",
    "    # sizes.\n",
    "    param_names = [\"param_%d\" for i in range(len(self.gp_hyperparameters))]\n",
    "    \n",
    "    print(self.gp_hyperparameters)\n",
    "\n",
    "    cov = math.calculate_covariance_finite_difference(\n",
    "        negative_log_likelihood,\n",
    "        param_names,\n",
    "        self.gp_hyperparameters,\n",
    "        [(None, None)] * len(param_names),\n",
    "        verbose=self.settings['verbosity'] > 2,\n",
    "    )\n",
    "    self.gp_hyperparameter_covariance = cov\n",
    "\n",
    "    uncertainties = np.sqrt(np.diag(cov))\n",
    "\n",
    "    self.print_verbose(\"    Fit result:           %s\" % res['message'])\n",
    "    self.print_verbose(\"    Color scale:          %.3f ± %.3f\"\n",
    "                       % (res.x[0], uncertainties[0]))\n",
    "    self.print_verbose(\"    Intrinsic dispersion: %.3f ± %.3f mag\"\n",
    "                       % (res.x[1], uncertainties[1]))\n",
    "    self.print_verbose(\"    GP kernel amplitude:  %.3f ± %.3f mag\"\n",
    "                       % (res.x[2], uncertainties[2]))\n",
    "    self.print_verbose(\"    GP length scale:      %.3f ± %.3f\"\n",
    "                       % (res.x[3], uncertainties[3]))\n",
    "    self.print_verbose(\"    lSSFR step size:      %.3f ± %.3f\"\n",
    "                       % (res.x[4], uncertainties[4]))\n",
    "    self.print_verbose(\"    gmass step size:      %.3f ± %.3f\"\n",
    "                       % (res.x[5], uncertainties[5]))\n",
    "\n",
    "    self.print_verbose(\"    Fit NMAD:             %.3f mag\"\n",
    "                       % math.nmad(good_corr_mags))\n",
    "    self.print_verbose(\"    Fit std:              %.3f mag\"\n",
    "                       % np.std(good_corr_mags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Desired error not necessarily achieved due to precision loss.\n",
      "    Color scale:          3.108 ± 0.211\n",
      "    Intrinsic dispersion: 0.090 ± 0.014 mag\n",
      "    GP kernel amplitude:  0.358 ± 0.203 mag\n",
      "    GP length scale:      7.316 ± 4.765\n",
      "    Fit NMAD:             0.095 mag\n",
      "    Fit std:              0.119 mag\n"
     ]
    }
   ],
   "source": [
    "a.fit_gp(kind='salt_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading between the lines...\n",
      "Loaded cached stan model\n",
      "Using saved stan result\n"
     ]
    }
   ],
   "source": [
    "a.read_between_the_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GP hyperparameters...\n",
      "[ 0.00284523  0.04228175  0.08850327  2.09917564 -0.03908652 -0.00441083]\n",
      "    Fit result:           Optimization terminated successfully.\n",
      "    Color scale:          0.003 ± 0.073\n",
      "    Intrinsic dispersion: 0.042 ± 0.043 mag\n",
      "    GP kernel amplitude:  0.089 ± 0.026 mag\n",
      "    GP length scale:      2.099 ± 3.159\n",
      "    lSSFR step size:      -0.039 ± 0.034\n",
      "    gmass step size:      -0.004 ± 0.026\n",
      "    Fit NMAD:             0.065 mag\n",
      "    Fit std:              0.095 mag\n"
     ]
    }
   ],
   "source": [
    "fit_gp_host(a, a.host_data['p(prompt)'], a.host_data['p(highgmass)'], kind='rbtl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 simultaneous host properties fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_step(residuals, x1, c, prob, errs=0.):\n",
    "    def calc_likelihood(x):\n",
    "        s1, s2, err1, err2, alpha, beta = x\n",
    "\n",
    "        var1 = errs**2 + err1**2\n",
    "        var2 = errs**2 + err2**2\n",
    "        \n",
    "        model_residuals = residuals - alpha * x1 + beta * c\n",
    "\n",
    "        # likelihood = np.sum(-np.log(\n",
    "            # prob * 1 / np.sqrt(2 * np.pi * var1) * np.exp(-(model_residuals - s1)**2 / var1)\n",
    "            # + (1 - prob) * 1 / np.sqrt(2 * np.pi * var2) * np.exp(-(model_residuals - s2)**2 / var2)\n",
    "        # ))\n",
    "        \n",
    "        likelihood = np.sum(-np.log(\n",
    "            1 / np.sqrt(2 * np.pi * var1) * np.exp(-(model_residuals - (prob * s1 + (1-prob) * s2))**2 / var1)\n",
    "            # prob * 1 / np.sqrt(2 * np.pi * var1) * np.exp(-(model_residuals - s1)**2 / var1)\n",
    "            # + (1 - prob) * 1 / np.sqrt(2 * np.pi * var2) * np.exp(-(model_residuals - s2)**2 / var2)\n",
    "        ))\n",
    "\n",
    "        return likelihood\n",
    "\n",
    "    res = minimize(calc_likelihood, [0., 0., 0.1, 0.1, 0.1, 3], method='BFGS')\n",
    "    param_errs = np.sqrt(np.diag(res.hess_inv))\n",
    "\n",
    "    # Estimate the variances with the intrinsic components.\n",
    "    total_vars = errs**2 + prob * res.x[2]**2 + (1 - prob) * res.x[3]**2\n",
    "\n",
    "    step_means = (res.x[0], res.x[1], res.x[1] - res.x[0])\n",
    "    step_errs = (param_errs[0], param_errs[1], np.sqrt(param_errs[0]**2 + param_errs[1]**2))\n",
    "    \n",
    "    corr_mags = residuals - res.x[4] * x1 + res.x[5] * c\n",
    "    \n",
    "    print(res.x)\n",
    "\n",
    "    return step_means, step_errs, total_vars, corr_mags\n",
    "\n",
    "def int_disp(vals, pec_vel_disps, axis=None):\n",
    "    std = np.std(vals, ddof=1, axis=axis)\n",
    "    corr = np.mean(pec_vel_disps**2, axis=axis)\n",
    "    corr_std = np.sqrt(np.clip(std**2 - corr, 0, None))\n",
    "\n",
    "    return corr_std\n",
    "\n",
    "def analyze_host_variable(variable, mags, mask, uncertainties=None, threshold=None,\n",
    "                          use_probability=True, plot=True, bootstrap=None,\n",
    "                          y_label='Residual magnitudes'):\n",
    "    use_mask = np.where(mask & a.host_mask)[0]\n",
    "\n",
    "    if isinstance(bootstrap, int):\n",
    "        np.random.seed(bootstrap)\n",
    "        bootstrap_idx = np.random.choice(len(use_mask), len(use_mask))\n",
    "        use_mask = use_mask[bootstrap_idx]\n",
    "        \n",
    "    host_data = a.host_data[use_mask]\n",
    "    use_mags = mags[use_mask]\n",
    "    \n",
    "    use_var = host_data[variable]\n",
    "    # use_var_low = -host_data[variable + '_low']\n",
    "    # use_var_high = host_data[variable + '_up']\n",
    "    use_var_low = host_data[variable + '.err_down']\n",
    "    use_var_high = host_data[variable + '.err_up']\n",
    "    \n",
    "    # Default thresholds from Rigault et al. 2019\n",
    "    if threshold is None:\n",
    "        if variable == 'lssfr':\n",
    "            threshold = -10.8\n",
    "        elif variable == 'gmass':\n",
    "            threshold = 10\n",
    "        else:\n",
    "            # Default, use the median of the variable\n",
    "            threshold = np.median(use_var)\n",
    "\n",
    "    # Figure out labels.\n",
    "    if variable == 'lssfr':\n",
    "        x_label = 'log(lsSFR)'\n",
    "    elif variable == 'gmass':\n",
    "        x_label = 'log($M_* / M_\\odot$) (global)'\n",
    "\n",
    "    # Figure out which weights to use for the step. We want to actually use\n",
    "    # the probabilities if they are available rather than hard cuts as is done\n",
    "    # in Rigault et al. 2018.\n",
    "    label = variable\n",
    "    use_weights = None\n",
    "\n",
    "    if use_probability:\n",
    "        if variable == 'lssfr':\n",
    "            # plot_color = host_data['p_young']\n",
    "            # use_weights = 1 - host_data['p_young'] / 100\n",
    "            plot_color = host_data['p(prompt)']\n",
    "            use_weights = 1 - host_data['p(prompt)']\n",
    "            label = '$P_{Young}$'\n",
    "        elif variable == 'gmass':\n",
    "            # plot_color = host_data['p_highmass']\n",
    "            # use_weights = 1 - host_data['p_highmass'] / 100\n",
    "            plot_color = host_data['p(highgmass)']\n",
    "            use_weights = 1 - host_data['p(highgmass)']\n",
    "            label = '$P_{high\\ mass}$'\n",
    "\n",
    "    if use_weights is None:\n",
    "        # Backup: do hard cuts.\n",
    "        use_weights = use_var < threshold\n",
    "        plot_color = use_weights\n",
    "\n",
    "    if uncertainties is None:\n",
    "        # If we don't have explicit uncertainties, just use the peculiar velocity contributions.\n",
    "        uncertainties = a.get_peculiar_velocity_uncertainty()\n",
    "\n",
    "    use_uncertainties = uncertainties[use_mask]\n",
    "\n",
    "    step_means, step_errs, total_var, corr_mags = likelihood_step(use_mags, a.salt_x1[use_mask],\n",
    "                                                       a.salt_colors[use_mask], use_weights,\n",
    "                                                       use_uncertainties)\n",
    "\n",
    "    if plot:\n",
    "        print(\"Step size: %.3f ± %.3f mag\" % (step_means[2], step_errs[2]))\n",
    "        print(\"Median step: %.3f\" % (np.median(corr_mags[use_weights < 0.5]) - np.median(corr_mags[use_weights > 0.5])))\n",
    "        plt.figure()\n",
    "        plt.errorbar(use_var, corr_mags, xerr=(use_var_low, use_var_high), yerr=np.sqrt(total_var), fmt='.', c='gray', alpha=0.5, zorder=-2)\n",
    "        plt.scatter(use_var, corr_mags, s=100, c=plot_color, edgecolors='gray', cmap=plt.cm.viridis_r)\n",
    "\n",
    "        # Threshold\n",
    "        plt.axvline(threshold, c='k', lw=2, ls='--')\n",
    "\n",
    "        # Show means of each side\n",
    "        plot_min, plot_max = plt.xlim()\n",
    "        mean_low, mean_high, mean_diff = step_means\n",
    "        mean_low_err, mean_high_err, mean_diff_err = step_errs\n",
    "        plt.plot([plot_min, threshold], [mean_low, mean_low], c='k', zorder=-1)\n",
    "        plt.fill_between([plot_min, threshold], [mean_low - mean_low_err, mean_low - mean_low_err], [mean_low + mean_low_err, mean_low + mean_low_err], color=plt.cm.viridis(1000), alpha=0.5, zorder=-3)\n",
    "        plt.plot([threshold, plot_max], [mean_high, mean_high], c='k', zorder=-1)\n",
    "        plt.fill_between([threshold, plot_max], [mean_high - mean_high_err, mean_high - mean_high_err], [mean_high + mean_high_err, mean_high + mean_high_err], color=plt.cm.viridis(0), alpha=0.5, zorder=-3)\n",
    "\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "\n",
    "        plt.xlim(plot_min, plot_max)\n",
    "        plt.ylim(-0.6, 0.6)\n",
    "        \n",
    "        print(step_means, step_errs)\n",
    "\n",
    "\n",
    "        plt.colorbar(label=label)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return step_means[-1], step_errs[-1]\n",
    "\n",
    "def bootstrap_step_difference(variable, mags_1, uncertainties_1, mags_2, uncertainties_2, mask,\n",
    "                              num_resamples=100, **kwargs):\n",
    "    step_diffs = []\n",
    "    for bootstrap_iter in range(num_resamples):\n",
    "        step_size_1, step_err_1 = analyze_host_variable(variable, mags_1, mask, uncertainties_1, bootstrap=bootstrap_iter, plot=False, **kwargs)\n",
    "        step_size_2, step_err_2 = analyze_host_variable(variable, mags_2, mask, uncertainties_2, bootstrap=bootstrap_iter, plot=False, **kwargs)\n",
    "        \n",
    "        step_diffs.append(step_size_2 - step_size_1)\n",
    "    \n",
    "    return np.mean(step_diffs), np.std(step_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14880984 -0.01468983  0.11297145  0.1        -0.18819478 -2.9538647 ]\n",
      "Step size: 0.134 ± 0.032 mag\n",
      "Median step: 0.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "/home/kyle/packages/conda/lib/python3.7/site-packages/scipy/optimize/optimize.py:697: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2041775a7b7b408f8d178a56dde72fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.1488098444463924, -0.014689834606313972, 0.1341200098400784) (0.019264453047408373, 0.025495588768845175, 0.03195534693734158)\n"
     ]
    }
   ],
   "source": [
    "analyze_host_variable('lssfr', a.salt_hr_raw, rigault_mask & a.salt_mask & a.uncertainty_mask & a.redshift_color_mask & a.train_mask,\n",
    "                      a.salt_hr_raw_uncertainties, y_label='SALT2 + $x_1$ residual magnitudes')\n",
    "plt.savefig('./figures/lssfr_salt_x1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output for Stella Yu's group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "m = a.uncertainty_mask\n",
    "\n",
    "hf = h5py.File('stella_yu_data.h5', 'w')\n",
    "hf.create_dataset('wavelength', data=a.wave)\n",
    "hf.create_dataset('flux', data=a.maximum_flux[m])\n",
    "hf.create_dataset('fluxerr', data=a.maximum_fluxerr[m])\n",
    "hf.create_dataset('color_law', data=a.rbtl_color_law)\n",
    "hf.create_dataset('magnitudes', data=a.rbtl_mags[m])\n",
    "hf.create_dataset('colors', data=a.rbtl_colors[m])\n",
    "hf.create_dataset('magnitude_measurement_errors', data=a.get_peculiar_velocity_uncertainty()[m])\n",
    "hf.create_dataset('mag_mask', data=a.redshift_color_mask[m])\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 288)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.maximum_flux[m].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ManifoldTwinsAnalysis' object has no attribute 'mag_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b0749567ac83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrbtl_mags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muncertainty_mask\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmag_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ManifoldTwinsAnalysis' object has no attribute 'mag_mask'"
     ]
    }
   ],
   "source": [
    "a.rbtl_mags[a.uncertainty_mask & a.mag_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3305.49675906, 3316.50858892, 3327.55710325, 3338.64242427,\n",
       "       3349.76467457, 3360.9239772 , 3372.12045558, 3383.35423357,\n",
       "       3394.62543542, 3405.9341858 , 3417.2806098 , 3428.66483293,\n",
       "       3440.08698111, 3451.54718068, 3463.04555841, 3474.58224148,\n",
       "       3486.15735749, 3497.7710345 , 3509.42340094, 3521.11458572,\n",
       "       3532.84471815, 3544.61392799, 3556.4223454 , 3568.27010101,\n",
       "       3580.15732587, 3592.08415147, 3604.05070972, 3616.057133  ,\n",
       "       3628.1035541 , 3640.19010628, 3652.31692322, 3664.48413907,\n",
       "       3676.69188841, 3688.94030626, 3701.22952812, 3713.55968991,\n",
       "       3725.93092802, 3738.3433793 , 3750.79718102, 3763.29247096,\n",
       "       3775.82938733, 3788.40806879, 3801.02865448, 3813.691284  ,\n",
       "       3826.39609741, 3839.14323524, 3851.9328385 , 3864.76504865,\n",
       "       3877.64000762, 3890.55785784, 3903.51874218, 3916.52280402,\n",
       "       3929.57018718, 3942.661036  , 3955.79549526, 3968.97371025,\n",
       "       3982.19582675, 3995.46199099, 4008.77234973, 4022.12705018,\n",
       "       4035.52624007, 4048.97006761, 4062.4586815 , 4075.99223094,\n",
       "       4089.57086563, 4103.19473576, 4116.86399204, 4130.57878565,\n",
       "       4144.3392683 , 4158.1455922 , 4171.99791006, 4185.89637511,\n",
       "       4199.84114107, 4213.8323622 , 4227.87019325, 4241.95478949,\n",
       "       4256.08630673, 4270.26490126, 4284.49072993, 4298.76395008,\n",
       "       4313.0847196 , 4327.45319689, 4341.86954087, 4356.33391103,\n",
       "       4370.84646734, 4385.40737033, 4400.01678106, 4414.67486113,\n",
       "       4429.38177268, 4444.13767838, 4458.94274145, 4473.79712565,\n",
       "       4488.70099529, 4503.65451521, 4518.65785083, 4533.71116811,\n",
       "       4548.81463353, 4563.96841418, 4579.17267766, 4594.42759216,\n",
       "       4609.73332641, 4625.0900497 , 4640.49793192, 4655.95714347,\n",
       "       4671.46785537, 4687.03023917, 4702.64446702, 4718.31071162,\n",
       "       4734.02914627, 4749.79994483, 4765.62328173, 4781.49933202,\n",
       "       4797.42827128, 4813.41027573, 4829.44552213, 4845.53418785,\n",
       "       4861.67645086, 4877.87248971, 4894.12248354, 4910.42661209,\n",
       "       4926.78505572, 4943.19799536, 4959.66561257, 4976.18808948,\n",
       "       4992.76560886, 5009.39835408, 5026.08650912, 5042.83025855,\n",
       "       5059.6297876 , 5076.48528208, 5093.39692844, 5110.36491373,\n",
       "       5127.38942564, 5144.47065249, 5161.60878321, 5178.80400737,\n",
       "       5196.05651517, 5213.36649744, 5230.73414565, 5248.1596519 ,\n",
       "       5265.64320895, 5283.18501019, 5300.78524963, 5318.44412198,\n",
       "       5336.16182254, 5353.93854731, 5371.7744929 , 5389.66985662,\n",
       "       5407.6248364 , 5425.63963084, 5443.71443922, 5461.84946145,\n",
       "       5480.04489813, 5498.30095053, 5516.61782059, 5534.99571089,\n",
       "       5553.43482473, 5571.93536607, 5590.49753954, 5609.12155046,\n",
       "       5627.80760484, 5646.55590936, 5665.36667141, 5684.24009904,\n",
       "       5703.17640103, 5722.17578683, 5741.2384666 , 5760.3646512 ,\n",
       "       5779.55455217, 5798.80838179, 5818.12635302, 5837.50867954,\n",
       "       5856.95557575, 5876.46725675, 5896.04393835, 5915.68583712,\n",
       "       5935.39317029, 5955.16615587, 5975.00501256, 5994.90995981,\n",
       "       6014.88121779, 6034.91900739, 6055.02355027, 6075.1950688 ,\n",
       "       6095.43378611, 6115.73992606, 6136.11371325, 6156.55537305,\n",
       "       6177.06513156, 6197.64321565, 6218.28985294, 6239.00527179,\n",
       "       6259.78970135, 6280.64337152, 6301.56651296, 6322.55935711,\n",
       "       6343.62213617, 6364.75508312, 6385.95843172, 6407.23241651,\n",
       "       6428.57727278, 6449.99323666, 6471.48054501, 6493.03943552,\n",
       "       6514.67014665, 6536.37291767, 6558.14798862, 6579.99560038,\n",
       "       6601.91599459, 6623.90941373, 6645.97610107, 6668.11630069,\n",
       "       6690.33025748, 6712.61821717, 6734.98042627, 6757.41713215,\n",
       "       6779.92858298, 6802.51502776, 6825.17671633, 6847.91389935,\n",
       "       6870.72682831, 6893.61575556, 6916.58093428, 6939.62261849,\n",
       "       6962.74106305, 6985.93652368, 7009.20925696, 7032.5595203 ,\n",
       "       7055.98757198, 7079.49367116, 7103.07807783, 7126.74105286,\n",
       "       7150.482858  , 7174.30375585, 7198.20400991, 7222.18388453,\n",
       "       7246.24364497, 7270.38355736, 7294.6038887 , 7318.90490691,\n",
       "       7343.28688077, 7367.75008   , 7392.29477517, 7416.92123778,\n",
       "       7441.62974022, 7466.42055581, 7491.29395876, 7516.25022419,\n",
       "       7541.28962816, 7566.41244762, 7591.61896047, 7616.90944552,\n",
       "       7642.28418251, 7667.74345211, 7693.28753594, 7718.91671654,\n",
       "       7744.6312774 , 7770.43150296, 7796.31767859, 7822.29009063,\n",
       "       7848.34902636, 7874.49477402, 7900.72762282, 7927.04786293,\n",
       "       7953.45578546, 7979.95168254, 8006.53584723, 8033.20857358,\n",
       "       8059.97015664, 8086.8208924 , 8113.76107788, 8140.79101106,\n",
       "       8167.91099092, 8195.12131745, 8222.42229161, 8249.81421541,\n",
       "       8277.29739181, 8304.87212481, 8332.53871943, 8360.29748169,\n",
       "       8388.14871864, 8416.09273833, 8444.12984987, 8472.26036338,\n",
       "       8500.48459001, 8528.80284196, 8557.21543245, 8585.72267578])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/home/kyle/Downloads/stella_yu_data.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False, False,  True, False, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True, False, False, False,  True,  True, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(f['mag_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named mask in the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-5ec9c3bed852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/kyle/Downloads/stella_yu_data.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/packages/conda/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                     )\n\u001b[1;32m    406\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_only_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_pathname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_close\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# if there is an error, close the store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/conda/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, key, where, start, stop, columns, iterator, chunksize, auto_close, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No object named {key} in the file\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m# create the storer and axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No object named mask in the file'"
     ]
    }
   ],
   "source": [
    "pd.read_hdf('/home/kyle/Downloads/stella_yu_data.h5', 'mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0f54adab2c4f9b98c4db6f03b081e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb797cddd10>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "m = (a.rbtl_colors < 0.5) & (a.redshift_errs < 0.004) & a.uncertainty_mask\n",
    "plt.scatter(a.redshifts[m], a.rbtl_mags[m], c='k', s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kara exposure list dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obs = [i['obs.exp'] for j in a.targets for i in j.spectra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2969"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./spectra_list.txt', 'w') as outfile:\n",
    "    for line in all_obs:\n",
    "        print(line, file=outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
