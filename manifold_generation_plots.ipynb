{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run manifold_twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ManifoldTwinsAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "    IDR:          BLACKSTON\n",
      "    Phase range: [-5.0, 5.0] days\n",
      "    Bin velocity: 1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [00:18<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating the spectra at maximum light...\n",
      "    Loaded cached stan model\n",
      "    Using saved stan result\n",
      "Reading between the lines...\n",
      "    Loaded cached stan model\n",
      "    Using saved stan result\n",
      "Building masks...\n",
      "    Masking 30/203 targets whose interpolation uncertainty power is \n",
      "    more than 0.100 of the intrinsic power.\n",
      "Generating the manifold learning embedding...\n",
      "Calculating spectral indicators...\n",
      "Fitting GP hyperparameters...\n",
      "    Fit result:           Optimization terminated successfully.\n",
      "    Color scale:          -0.007 ± 0.070\n",
      "    Intrinsic dispersion: 0.065 ± 0.013 mag\n",
      "    GP kernel amplitude:  0.111 ± 0.042 mag\n",
      "    GP length scale:      3.348 ± 2.272\n",
      "    Fit NMAD:             0.072 mag\n",
      "    Fit std:              0.098 mag\n",
      "Calculating SALT2 Hubble residuals...\n",
      "SALT2 Hubble fit: \n",
      "    ref_mag: -10.449\n",
      "    alpha:   0.142\n",
      "    beta:    2.665\n",
      "    σ_int:   0.134\n",
      "    RMS:     0.156\n",
      "    NMAD:    0.110\n",
      "    WRMS:    0.156\n",
      "Loading host galaxy data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "a.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default settings for matplotlib figures\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Choose how big to make figures. This will scale the text size.\n",
    "mpl.rcParams['figure.figsize'] = (5., 4.)\n",
    "\n",
    "# Choose the size of full-page spectra figures.\n",
    "spectrum_plot_figsize = (9., 4.)\n",
    "\n",
    "# Choose how to plot spectra. We use F_nu instead of F_lambda so that\n",
    "# the features at all wavelengths can be seen. The overall scale is\n",
    "# arbitrary and normalized to be ~1.\n",
    "spectrum_plot_scale = a.wave**2 / 5000**2\n",
    "spectrum_plot_ylabel = 'Normalized flux (erg/$cm^2$/s/Hz)'\n",
    "\n",
    "# Choose the colormap to use for all of the plots\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# crange = np.linspace(0, 1, 256)\n",
    "# plot_cmap = ListedColormap(plt.cm.plasma(crange)[:210])\n",
    "plot_cmap = plt.cm.coolwarm\n",
    "\n",
    "# Set the DPI. This will change how big things appear in Jupyter lab\n",
    "# mpl.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911533ec9a324fe7b4eea25f1fe58fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=101, description='idx', max=202), Checkbox(value=False, description='sav…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_same_night(idx, save=False, **kwargs)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_same_night(idx, save=False, **kwargs):\n",
    "    night_flux = a.flux[a.target_map == idx]\n",
    "    phases = a.salt_phases[a.target_map == idx]\n",
    "    model = a.maximum_result['maximum_flux'][idx]\n",
    "    model_err = a.maximum_result['maximum_fluxerr'][idx]\n",
    "    fig1 = plt.figure(**kwargs)\n",
    "    for flux, phase in zip(night_flux, phases):\n",
    "        plt.plot(a.wave, flux * spectrum_plot_scale, label='Data (%.2f days)' % phase)\n",
    "    plt.plot(a.wave, model * spectrum_plot_scale, c='k', ls='--', label='Model (0 days)')\n",
    "    plt.fill_between(a.wave, (model - model_err) * spectrum_plot_scale,\n",
    "                     (model + model_err) * spectrum_plot_scale, facecolor='k', alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.title(a.targets[idx])\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('./figures/interpolation_model_%s.pdf' % a.targets[idx])\n",
    "    \n",
    "    phase_slope = a.maximum_result['phase_slope']\n",
    "    phase_quadratic = a.maximum_result['phase_quadratic']\n",
    "    gray_offsets = a.maximum_result['gray_offsets'][a.target_map == idx]\n",
    "    model_diffs = a.maximum_result['model_diffs'][a.target_map == idx]\n",
    "    \n",
    "    fig2 = plt.figure(**kwargs)\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        plt.plot(a.wave, -2.5*np.log10(flux / model), label='Data (%.2f days)' % phase, c='C%d' % i)\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        plt.plot(a.wave, model_diff, label='Model (%.2f days)' % phase, c='C%d' % i, ls='--')\n",
    "    plt.legend(ncol=2, loc=1)\n",
    "    plt.title(a.targets[idx])\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel('Difference from maximum light (mag)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('./figures/interpolation_difference_%s.pdf' % a.targets[idx])\n",
    "    \n",
    "    fig3 = plt.figure(**kwargs)\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        plt.plot(a.wave, -2.5*np.log10(flux / model) - model_diff, label='Residuals (%.2f days)' % phase, c='C%d' % i)\n",
    "    plt.legend()\n",
    "    plt.title(a.targets[idx])\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel('Interpolation residuals (mag)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('./figures/interpolation_residuals_%s.pdf' % a.targets[idx])\n",
    "        \n",
    "    return fig1, fig2, fig3\n",
    "    \n",
    "from ipywidgets import interact\n",
    "interact(plot_same_night, idx=(0, len(a.targets)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ManifoldTwinsAnalysis' object has no attribute 'interpolation_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f886405bd7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplot_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplot_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplot_same_night\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-4e8ca237feab>\u001b[0m in \u001b[0;36mplot_same_night\u001b[0;34m(idx, save, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnight_flux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_map\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msalt_phases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_map\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximum_flux'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximum_fluxerr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfig1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ManifoldTwinsAnalysis' object has no attribute 'interpolation_result'"
     ]
    }
   ],
   "source": [
    "plot_targets = ['PTF13ayw', 'SN2004gc']\n",
    "for plot_target in plot_targets:\n",
    "    target_names = np.array([i.name for i in a.targets])\n",
    "    plot_idx = np.where(target_names == plot_target)[0][0]\n",
    "\n",
    "    plot_same_night(plot_idx, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_slope = a.interpolation_result['phase_slope']\n",
    "phase_quadratic = a.interpolation_result['phase_quadratic']\n",
    "phase_slope_x1 = a.interpolation_result['phase_slope_x1']\n",
    "phase_quadratic_x1 = a.interpolation_result['phase_quadratic_x1']\n",
    "\n",
    "def evaluate_phase_difference(phase, x1=0):\n",
    "    phase_difference = (\n",
    "        phase_slope * phase\n",
    "        + phase_quadratic * phase * phase\n",
    "        + phase_slope_x1 * x1 * phase\n",
    "        + phase_quadratic_x1 * x1 * phase * phase\n",
    "    )\n",
    "    \n",
    "    return phase_difference\n",
    "\n",
    "# Look at change in phase for the same x1\n",
    "max_phase = a.phase_width\n",
    "min_phase = -a.phase_width\n",
    "num_phases = 10\n",
    "phases = np.linspace(min_phase, max_phase, num_phases)\n",
    "\n",
    "plt.figure(figsize=spectrum_plot_figsize)\n",
    "# plt.figure()\n",
    "norm = plt.Normalize(vmin=min_phase, vmax=max_phase)\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array(phases)\n",
    "\n",
    "for phase in phases:\n",
    "    plt.plot(a.wave, evaluate_phase_difference(phase), c=cmap(norm(phase)), zorder=np.abs(phase))\n",
    "    \n",
    "plt.colorbar(sm, label='Phase (days)')\n",
    "\n",
    "# plt.xlim(-5.2, 5.2)\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel('Brightness relative to $t_{max,B}$ (mag)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_phase_difference.pdf')\n",
    "\n",
    "\n",
    "def plot_x1_difference(phase):\n",
    "    # Look at change in phase for the same x1\n",
    "    min_x1 = -2\n",
    "    max_x1 = 2\n",
    "    num_x1s = 10\n",
    "    x1s = np.linspace(min_x1, max_x1, num_x1s)\n",
    "\n",
    "    plt.figure(figsize=spectrum_plot_figsize)\n",
    "    norm = plt.Normalize(vmin=min_x1, vmax=max_x1)\n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array(x1s)\n",
    "\n",
    "    for x1 in x1s:\n",
    "        plt.plot(a.wave, evaluate_phase_difference(phase, x1) - evaluate_phase_difference(phase, 0), c=cmap(norm(x1)))\n",
    "\n",
    "    plt.colorbar(sm, label='SALT2 $x_1$')\n",
    "\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel('Difference relative to $x_1=0$ (mag)')\n",
    "    plt.title('Difference in interpolation at %+d days' % phase)\n",
    "    # plt.gca().invert_yaxis()\n",
    "    plt.ylim(0.4, -0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/interpolation_x1_difference_phase_%d.pdf' % phase)\n",
    "    \n",
    "for phase in [-5, -3, -1, 1, 3, 5]:\n",
    "    plot_x1_difference(phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gray dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.interpolation_result['gray_dispersion_scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.salt_phases, a.interpolation_result['gray_offsets'], s=3, label='Individual spectra')\n",
    "math.plot_binned_mean(a.salt_phases, a.interpolation_result['gray_offsets'], c='C2', lw=2, label='Binned mean')\n",
    "math.plot_binned_rms(a.salt_phases, a.interpolation_result['gray_offsets'], c='C3', lw=2, label='Binned RMS')\n",
    "plt.xlabel('SALT2 Phase (days)')\n",
    "plt.ylabel('Gray offset (mag)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/gray_offset_vs_phase.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    coefs = a.interpolation_result['phase_dispersion_coefficients']\n",
    "except KeyError:\n",
    "    coefs = a.stan_data['phase_dispersion_coefficients']\n",
    "num_phase_coefficients = len(coefs)\n",
    "\n",
    "def evaluate_phase_dispersion(phase):\n",
    "    phase_scale = np.abs((num_phase_coefficients / 2) * (phase / a.phase_width))\n",
    "    full_bins = int(np.floor(phase_scale))\n",
    "    remainder = phase_scale - full_bins\n",
    "    \n",
    "    phase_coefficients = np.zeros(num_phase_coefficients)\n",
    "    \n",
    "    for j in range(full_bins + 1):\n",
    "        if j == full_bins:\n",
    "            weight = remainder\n",
    "        else:\n",
    "            weight = 1\n",
    "            \n",
    "        if weight == 0:\n",
    "            break\n",
    "            \n",
    "        if phase > 0:\n",
    "            phase_bin = num_phase_coefficients // 2 + j\n",
    "        else:\n",
    "            phase_bin = num_phase_coefficients // 2 - 1 - j\n",
    "            \n",
    "        phase_coefficients[phase_bin] = weight\n",
    "        \n",
    "    fractional_dispersion = phase_coefficients.dot(coefs)\n",
    "    \n",
    "    # Convert to magnitudes\n",
    "    mag_dispersion = frac_to_mag(fractional_dispersion)\n",
    "    \n",
    "    return mag_dispersion\n",
    "\n",
    "phases = np.linspace(-a.phase_width, a.phase_width, 1 + num_phase_coefficients)\n",
    "\n",
    "eval_coefs = np.array([evaluate_phase_dispersion(phase) for phase in phases])\n",
    "\n",
    "# Uncertainties for different wavelengths\n",
    "plt.figure()\n",
    "num_wave = 10\n",
    "for i in range(num_wave):\n",
    "    min_wave = a.wave[0]\n",
    "    max_wave = a.wave[-1]\n",
    "    wave_range = max_wave - min_wave\n",
    "    target_wave = min_wave + wave_range * i / (num_wave - 1)\n",
    "    idx = np.argmin(np.abs(a.wave - target_wave))\n",
    "    use_wave = a.wave[idx]\n",
    "    color = plt.cm.rainbow((use_wave - min_wave) / wave_range)\n",
    "    plt.plot(phases, eval_coefs[:, idx], label='%d $\\AA$' % use_wave, c=color)\n",
    "    \n",
    "plt.xlim(-5.2, 5.2)\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Interpolation uncertainty (mag)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_phase.pdf')\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(phases)):\n",
    "    plt.plot(a.wave, eval_coefs[i], label='%.2f days' % phases[i])\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength $(\\AA$)')\n",
    "plt.ylabel('Interpolation uncertainty (mag)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_wavelength.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_flux = a.interpolation_result['maximum_flux']\n",
    "max_fluxerr = a.interpolation_result['maximum_fluxerr']\n",
    "\n",
    "max_magerr = frac_to_mag(max_fluxerr / max_flux)\n",
    "\n",
    "rbtl_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "\n",
    "def plot_uncertainties(show_rbtl=False):\n",
    "    plt.figure()\n",
    "    offset = 29\n",
    "    \n",
    "    # Make sure that we include the worst offender.\n",
    "    max_loc = np.argmax(np.sum(max_magerr**2, axis=1))\n",
    "    start = max_loc % offset\n",
    "    \n",
    "    for idx in range(start, len(a.targets), offset):\n",
    "        plt.plot(a.wave, max_magerr[idx], label=a.targets[idx].name)\n",
    "    plt.legend(ncol=2)\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    \n",
    "    if show_rbtl:\n",
    "        plt.plot(a.wave, rbtl_dispersion, label='SN intrinsic dispersion', c='k', lw=2, ls='--')\n",
    "        plt.ylabel('Dispersion (mag)')\n",
    "        path = './figures/interpolation_uncertainty_rbtl.pdf'\n",
    "    else:\n",
    "        plt.ylabel('Uncertainty on $f_{max}$ (mag)')\n",
    "        path = './figures/interpolation_uncertainty_norbtl.pdf'\n",
    "        \n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "        \n",
    "plot_uncertainties(False)\n",
    "plot_uncertainties(True)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for idx in range(len(a.targets)):\n",
    "    if idx == 0:\n",
    "        label = 'Individual uncertainties of $f_{max}$'\n",
    "    else:\n",
    "        label = ''\n",
    "    plt.plot(a.wave, max_magerr[idx], label=label, alpha=0.02, c='C0')\n",
    "plt.plot(a.wave, rbtl_dispersion, label='Supernova intrinsic dispersion', lw=2, ls='--', c='k')\n",
    "plt.plot(a.wave, np.median(max_magerr, axis=0), label='Median uncertainty on $f_{max}$', lw=2, ls='--', c='C0')\n",
    "plt.plot(a.wave, np.max(max_magerr, axis=0), label='Maximum uncertainty on $f_{max}$', c='C1')\n",
    "plt.legend()\n",
    "plt.ylabel('Dispersion (magnitude)')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_median.pdf')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(a.wave, rbtl_dispersion, label='SN intrinsic dispersion', lw=2, ls='--', c='k')\n",
    "plt.plot(a.wave, np.min(max_magerr, axis=0), label='Minimum $\\sigma_{f,max}$')\n",
    "for percentile in (25, 50, 75):\n",
    "    plt.plot(a.wave, np.percentile(max_magerr, percentile, axis=0), label='%dth percentile $\\sigma_{f,max}$' % percentile)\n",
    "plt.plot(a.wave, np.max(max_magerr, axis=0), label='Maximum $\\sigma_{f,max}$')\n",
    "plt.legend(ncol=2)\n",
    "plt.ylabel('Dispersion (magnitude)')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/interpolation_uncertainty_percentile.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution to the total interpolation uncertainty from various sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "diffs = []\n",
    "phases_1 = []\n",
    "phases_2 = []\n",
    "x1s = []\n",
    "gray_differences = []\n",
    "\n",
    "gray_offsets = a.interpolation_result['gray_offsets']\n",
    "\n",
    "center_specs = a.spectra[a.center_mask]\n",
    "center_gray_offsets = gray_offsets[a.center_mask]\n",
    "for target_idx in range(len(a.targets)):\n",
    "    near_max_spec = center_specs[target_idx]\n",
    "    \n",
    "    target_mask = (a.target_map == target_idx) & (~a.center_mask)\n",
    "    target_specs = a.spectra[target_mask]\n",
    "    target_gray_offsets = gray_offsets[target_mask]\n",
    "    \n",
    "    for spec_idx, target_spec in enumerate(target_specs):\n",
    "        phase_diff = target_spec.phase - near_max_spec.phase\n",
    "        # if np.abs(phase_diff) < 1:\n",
    "            # continue\n",
    "\n",
    "        targets.append(a.targets[target_idx])\n",
    "        diff = -2.5*np.log10(target_spec.flux / near_max_spec.flux)\n",
    "        diffs.append(diff)\n",
    "        phases_1.append(near_max_spec.phase)\n",
    "        phases_2.append(target_spec.phase)\n",
    "        x1s.append(a.salt_x1[target_idx])\n",
    "        \n",
    "        gray_differences.append(target_gray_offsets[spec_idx] - center_gray_offsets[target_idx])\n",
    "\n",
    "targets = np.array(targets)\n",
    "diffs = np.array(diffs)\n",
    "phases_1 = np.array(phases_1)\n",
    "phases_2 = np.array(phases_2)\n",
    "x1s = np.array(x1s)\n",
    "gray_differences = np.array(gray_differences)\n",
    "\n",
    "phase_diffs = phases_2 - phases_1\n",
    "\n",
    "def plot_diffs(diffs, model_subtracted=False):\n",
    "    sel_mask = np.zeros(len(diffs), dtype=bool)\n",
    "    sel_mask[4::50] = True\n",
    "    sel_mask[np.abs(phase_diffs) < 1] = False\n",
    "    \n",
    "    print(np.min(x1s[sel_mask]))\n",
    "    print(np.max(x1s[sel_mask]))\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    for use_idx in np.where(sel_mask)[0]:\n",
    "        target = targets[use_idx]\n",
    "        phase_1 = phases_1[use_idx]\n",
    "        phase_2 = phases_2[use_idx]\n",
    "        \n",
    "        if phase_1 > phase_2:\n",
    "            phase_1, phase_2 = phase_2, phase_1\n",
    "        \n",
    "        label = '%s, %.1f to %.1f days' % (target, phase_1, phase_2)\n",
    "        \n",
    "        plt.plot(a.wave, diffs[use_idx] / phase_diffs[use_idx], alpha=0.5, label=label)\n",
    "        \n",
    "    plt.legend(ncol=2)\n",
    "\n",
    "    plt.ylim(-0.25, 0.25)\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    if model_subtracted:\n",
    "        plt.ylabel('$\\Delta m / \\Delta t$ (data) - $\\Delta m / \\Delta t$ (model) (mag/day)')\n",
    "    else:\n",
    "        plt.ylabel('$\\Delta m / \\Delta t$ (data) (mag/day)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_diffs(diffs)\n",
    "plt.savefig('./figures/raw_phase_difference.pdf')\n",
    "\n",
    "residuals_no_x1 = []\n",
    "residuals_x1 = []\n",
    "for diff, phase_1, phase_2, x1 in zip(diffs, phases_1, phases_2, x1s):\n",
    "    model_no_x1 = evaluate_phase_difference(phase_2, 0) - evaluate_phase_difference(phase_1, 0)\n",
    "    model_x1 = evaluate_phase_difference(phase_2, x1) - evaluate_phase_difference(phase_1, x1)\n",
    "    residuals_no_x1.append(diff - model_no_x1)\n",
    "    residuals_x1.append(diff - model_x1)\n",
    "    \n",
    "residuals_no_x1 = np.array(residuals_no_x1)\n",
    "residuals_x1 = np.array(residuals_x1)\n",
    "\n",
    "residuals_gray_no_x1 = residuals_no_x1 - gray_differences[:, None]\n",
    "residuals_gray_x1 = residuals_x1 - gray_differences[:, None]\n",
    "\n",
    "plot_diffs(residuals_gray_no_x1, True)\n",
    "plt.savefig('./figures/corr_phase_difference_no_x1.pdf')\n",
    "\n",
    "plot_diffs(residuals_gray_x1, True)\n",
    "plt.savefig('./figures/corr_phase_difference_x1.pdf')\n",
    "\n",
    "def print_interpolation_residuals(min_days, max_days):\n",
    "    cut = (np.abs(phase_diffs) < max_days) & (np.abs(phase_diffs) > min_days)\n",
    "\n",
    "    def do_print(label, vals, cut):\n",
    "        cut_vals = vals[cut]\n",
    "        print('%20s: std=%.3f, NMAD=%.3f' % (label, math.rms(cut_vals), math.nmad(cut_vals)))\n",
    "\n",
    "    print(\"Interpolation of %.1f-%.1f days:\" % (min_days, max_days))\n",
    "    do_print('Raw', diffs, cut)    \n",
    "    do_print('Phase', residuals_no_x1, cut)    \n",
    "    do_print('Phase + x1', residuals_x1, cut)    \n",
    "    do_print('Phase + gray', residuals_gray_no_x1, cut)    \n",
    "    do_print('Phase + x1 + gray', residuals_gray_x1, cut)    \n",
    "    print(\"\")\n",
    "    \n",
    "print_interpolation_residuals(0., 1.5)\n",
    "print_interpolation_residuals(1.5, 2.5)\n",
    "print_interpolation_residuals(2.5, 5.5)\n",
    "print_interpolation_residuals(5.5, 10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.maximum_result['gray_offsets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_slope = a.interpolation_result['phase_slope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading between the lines plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show spectra before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, a.maximum_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "plt.plot(a.wave, a.maximum_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], lw=1.)\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.legend()\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/spectra_at_maximum.pdf')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(a.wave, a.scale_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "plt.plot(a.wave, a.scale_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], alpha=1., lw=1.)\n",
    "plt.plot(a.wave, a.mean_flux * spectrum_plot_scale, c='k', lw=2, ls='--', label='Mean spectrum')\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/scale_spectra.pdf')\n",
    "\n",
    "plt.figure()\n",
    "fractional_dispersion = a.rbtl_result['fractional_dispersion']\n",
    "plt.plot(a.wave, a.mean_flux * spectrum_plot_scale, c='k', lw=2, ls='--', label='Mean spectrum')\n",
    "plt.fill_between(a.wave, a.mean_flux * (1 - fractional_dispersion) * spectrum_plot_scale, a.mean_flux * (1 + fractional_dispersion) * spectrum_plot_scale, label='Supernova intrinsic dispersion', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/scale_spectra_model.pdf')\n",
    "\n",
    "plt.figure()\n",
    "intrinsic_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "plt.plot(a.wave, intrinsic_dispersion, c='k', lw=2, label='Supernova intrinsic dispersion')\n",
    "plt.legend()\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel('Intrinsic dispersion (mag)')\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/rbtl_intrinsic_dispersion.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined version\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(spectrum_plot_figsize[0], spectrum_plot_figsize[1] * 3 - 1.5), sharex=True)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(a.wave, a.maximum_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "ax.plot(a.wave, a.maximum_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], lw=1.)\n",
    "ax.set_ylabel(spectrum_plot_ylabel)\n",
    "ax.legend()\n",
    "ax.set_title('Original spectra')\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(a.wave, a.scale_flux[a.interp_mask][0] * spectrum_plot_scale, alpha=1, lw=1., label='Individual spectra')\n",
    "ax.plot(a.wave, a.scale_flux[a.interp_mask][1:].T * spectrum_plot_scale[:, None], alpha=1., lw=1.)\n",
    "ax.plot(a.wave, a.mean_flux * spectrum_plot_scale, c='k', lw=2, ls='--', label='Mean spectrum')\n",
    "ax.legend()\n",
    "ax.set_ylabel(spectrum_plot_ylabel)\n",
    "ax.set_title('Dereddened spectra')\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "ax = axes[2]\n",
    "intrinsic_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "ax.plot(a.wave, intrinsic_dispersion, c='k', lw=2, label='Supernova intrinsic dispersion')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "ax.set_ylabel('Intrinsic dispersion (mag)')\n",
    "ax.set_title('Recovered intrinsic dispersion')\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/rbtl_spectra_combined.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.interp_mask], a.mags[a.interp_mask], s=15, c='C3', label='Supernovae rejected by cuts')\n",
    "plt.scatter(a.redshifts[a.good_mag_mask], a.mags[a.good_mag_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "plt.axvline(0.02, lw=1, ls='--', c='k', label='Redshift cutoff')\n",
    "\n",
    "plt.xlim(0.001, 0.09)\n",
    "plt.ylim(-1, 1.5)\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('RBTL measured magnitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/rbtl_magnitude.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.interp_mask], a.salt_hr[a.interp_mask], s=15, c='C3', label='Supernovae rejected by cuts')\n",
    "plt.scatter(a.redshifts[a.good_salt_mask], a.salt_hr[a.good_salt_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "plt.axvline(0.02, lw=1, ls='--', c='k', label='Redshift cutoff')\n",
    "\n",
    "plt.xlim(0.001, 0.09)\n",
    "# plt.ylim(-1, 1.5)\n",
    "plt.ylim(-1, 2.)\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('SALT2 measured magnitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/salt_magnitude_redshift.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.good_mag_mask], a.mags[a.good_mag_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('RBTL measured magnitude')\n",
    "\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xlim(0.01, 0.09)\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.savefig('./figures/rbtl_magnitude_cut.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw RBTL mag std:  %.3f mag\" % np.std(a.mags[a.good_mag_mask & a.interp_mask]))\n",
    "print(\"Raw RBTL mag NMAD: %.3f mag\" % math.nmad(a.mags[a.good_mag_mask & a.interp_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(a.redshifts[a.good_mag_mask], a.corr_mags[a.good_mag_mask], s=15, c='C0', label='Supernovae passing cuts')\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('RBTL corrected magnitude')\n",
    "\n",
    "\n",
    "z_range = np.linspace(0.001, 0.09, 100)\n",
    "pec_vel_disp = 0.00217 / z_range\n",
    "plt.fill_between(z_range, -pec_vel_disp, pec_vel_disp, alpha=0.2, label='Peculiar velocity dispersion')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xlim(0.01, 0.09)\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.savefig('./figures/rbtl_corr_magnitude_cut.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold learning plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.scatter(a.embedding[:, 2], vmin=-2, vmax=2, label='Component 3', linewidths=1, edgecolors='k', marker_size=60)\n",
    "a.scatter(a.embedding[:, 2], vmin=-2, vmax=2, label='Component 3')\n",
    "plt.savefig('./figures/embedding_components_12.pdf')\n",
    "a.scatter(a.embedding[:, 1], axis_1=0, axis_2=2, vmin=-3, vmax=3, label='Component 2')\n",
    "plt.savefig('./figures/embedding_components_13.pdf')\n",
    "a.scatter(a.embedding[:, 0], axis_1=1, axis_2=2, vmin=-4, vmax=4, label='Component 1')\n",
    "plt.savefig('./figures/embedding_components_23.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the total variance isn't defined for Isomap. The variances of the transfomed components\n",
    "# do map onto the variance of real components though. We provide a very rough estimate of the\n",
    "# measurement variance for comparison purposes... not sure how much it can be trusted...\n",
    "\n",
    "num_show = 10\n",
    "\n",
    "# Do an initial embedding with as many components as possible to get the full variance.\n",
    "a.generate_embedding(num_components=None)\n",
    "variances = np.var(a.embedding[a.interp_mask], axis=0)\n",
    "\n",
    "ref_var = np.sum(variances[:10])\n",
    "\n",
    "plot_ref = variances[0]\n",
    "\n",
    "print(variances[:10] / plot_ref)\n",
    "print(variances[:10] / np.cumsum(variances[:10]))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(num_show), variances[:num_show] / plot_ref, label='Contributed variance of each component')\n",
    "# plt.scatter(np.arange(num_show), variances[:num_show] / plot_ref, label='Contributed variance of each component')\n",
    "# plt.axhline(0.1 * ref_var / plot_ref, label='Approximate measurement variance cut', ls='--', c='C3')\n",
    "# plt.axhline(np.mean(a.interp_power_fraction[a.interp_mask]) * ref_var / plot_ref, label='Approximate mean measurement variance', ls='--', c='C2')\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel('Component number')\n",
    "plt.ylabel('Relative variance explained')\n",
    "plt.xticks(np.arange(num_show), np.arange(num_show) + 1)\n",
    "# plt.legend(markerfirst=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/isomap_component_variance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(a.interp_power_fraction[a.interp_mask])# * ref_var / plot_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twin reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot where twins and non-twins end up for different number of components.\n",
    "# We also make a summary plot.\n",
    "confused_fraction = []\n",
    "\n",
    "plot_components = np.arange(1, 6)\n",
    "for n_components in plot_components:\n",
    "    a.do_embedding(n_components=n_components)\n",
    "    leakage_matrix = a.plot_twin_distances()\n",
    "    if n_components == 1:\n",
    "        title = '1 Component + Color'\n",
    "    else:\n",
    "        title = '%d Components + Color' % n_components\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Recovered twinness percentile in the embedded space')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/twins_recovery_%d_components.pdf' % n_components)\n",
    "    \n",
    "    confused_fraction.append(leakage_matrix[3, 0] + leakage_matrix[3, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(len(confused_fraction)) + 1, confused_fraction)\n",
    "plt.xticks(plot_components, plot_components)\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlabel('Number of components (in addition to color)')\n",
    "plt.ylabel('Fraction of non-twins confused as twins')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/twins_confusion.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot slices through the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the manifold learning embedding...\n"
     ]
    }
   ],
   "source": [
    "a.generate_embedding()\n",
    "\n",
    "def plot_slice(scan_component, closest_count=10, max_dist=1., loc=np.zeros(a.embedding.shape[1] - 1)):\n",
    "    loc = np.asarray(loc)\n",
    "    mask = a.interp_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "\n",
    "    other_embedding = np.delete(use_embedding, scan_component, axis=1)\n",
    "    dists = np.sqrt(np.sum((other_embedding - loc)**2, axis=1))\n",
    "\n",
    "    dist_limit = np.min([np.sort(dists)[closest_count], max_dist])\n",
    "    scan_cut = dists < dist_limit\n",
    "    \n",
    "    scan_embedding = use_embedding[scan_cut, scan_component]\n",
    "    \n",
    "    sort_embedding = np.sort(scan_embedding)\n",
    "    min_comp = sort_embedding[0]\n",
    "    max_comp = sort_embedding[-1]\n",
    "    cmap = plot_cmap\n",
    "\n",
    "    plt.figure(figsize=spectrum_plot_figsize)\n",
    "    for spec, val in zip(use_flux[scan_cut], scan_embedding):\n",
    "        plt.plot(a.wave, spec * spectrum_plot_scale, c=cmap((val - min_comp) / (max_comp - min_comp)))\n",
    "\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_comp, vmax=max_comp))\n",
    "    sm._A = []\n",
    "    plt.colorbar(sm, label='Value of Component %d' % (scan_component + 1))\n",
    "    plt.title('Component %d' % (scan_component + 1))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('./figures/component_%d_effect.pdf' % (scan_component + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(0, loc=[-0.5, -0.5])\n",
    "plot_slice(1)\n",
    "plot_slice(2, loc=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e4547f2ba14d7bbffd279f7a5ee8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot_gp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot steps through component values - combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f14ba621264e1d81866cf45fa4fa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(spectrum_plot_figsize[0], spectrum_plot_figsize[1] * 3 - 1.5), sharex=True)\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "for component in range(3):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask, component]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    ax = axes[component]\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val)\n",
    "        \n",
    "        ax.plot(a.wave, step_flux * spectrum_plot_scale, c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "        \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='2.5%', pad=0.1)\n",
    "    fig.colorbar(sm, cax=cax, orientation='vertical', label='Component Value')\n",
    "    # fig.colorbar(sm, cax=cax, orientation='vertical', label='Value of Component %d' % (component + 1))\n",
    "    # ax.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "    ax.set_title('Component %d' % (component + 1))\n",
    "    \n",
    "    if component == 2:\n",
    "        ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "    \n",
    "    ax.set_ylabel(spectrum_plot_ylabel)\n",
    "    ax.set_ylim(0, None)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/component_steps_combined.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22330f781324b839105d727133ade87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version for talks\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# fig, axes = plt.subplots(3, 1, figsize=(spectrum_plot_figsize[0], spectrum_plot_figsize[1] * 3 - 1.5), sharex=True)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 7), sharex=True)\n",
    "\n",
    "num_steps = 10\n",
    "\n",
    "for component in range(3):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask, component]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    ax = axes[component]\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val)\n",
    "        \n",
    "        ax.plot(a.wave, step_flux * spectrum_plot_scale, c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "        \n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='2.5%', pad=0.1)\n",
    "    fig.colorbar(sm, cax=cax, orientation='vertical', label='Component Value')\n",
    "    # fig.colorbar(sm, cax=cax, orientation='vertical', label='Value of Component %d' % (component + 1))\n",
    "    # ax.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "    # ax.set_title('Component %d' % (component + 1))\n",
    "    \n",
    "    if component == 2:\n",
    "        ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "    \n",
    "    # ax.set_ylabel(spectrum_plot_ylabel)\n",
    "    ax.set_ylabel('Flux')\n",
    "    ax.set_ylim(0, None)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/component_steps_combined_talk.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot steps through component values - single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_steps(component, num_steps=10, xlim=None, figsize=spectrum_plot_figsize, colorbar=True):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask, component]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "\n",
    "    if xlim is not None:\n",
    "        wave_mask = (a.wave > xlim[0] - 50) & (a.wave < xlim[1] + 50)\n",
    "    else:\n",
    "        wave_mask = np.ones(len(a.wave), dtype=bool)\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        # if step == 0:\n",
    "            # label = 'Median spectra in each component bin'\n",
    "        # else:\n",
    "            # label = ''\n",
    "            \n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val)\n",
    "        \n",
    "        # plt.plot(a.wave[wave_mask], step_flux[wave_mask], c=sm.to_rgba(mean_val), label=label)\n",
    "        plt.plot(a.wave[wave_mask], step_flux[wave_mask] * spectrum_plot_scale[wave_mask], c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "        \n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "        \n",
    "    if colorbar:\n",
    "        plt.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "        plt.title('Component %d' % (component + 1))\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "    plt.ylim(0, None)\n",
    "    \n",
    "    # plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if xlim is None:\n",
    "        plt.savefig('./figures/component_%d_steps.pdf' % (component + 1))\n",
    "    else:\n",
    "        plt.savefig('./figures/component_%d_steps_zoom_%d_%d.pdf' % (component + 1, xlim[0], xlim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component in range(3):\n",
    "    plot_steps(component)\n",
    "    # plot_steps(component, xlim=(3300, 4500))\n",
    "    # plot_steps(component, xlim=(4900, 6700))\n",
    "    # plot_steps(component, xlim=(7200, 8600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Comparison to original twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hannah_list = np.genfromtxt('./data/fakhouri_atmax_list.txt', dtype='str')\n",
    "twins_mask = np.array([i.name in hannah_list for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_twin_pairings()\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/twin_dispersion.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twins that are poor brightness matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "mask = a.good_mag_mask\n",
    "\n",
    "raw_spec_dists = pdist(a.iso_diffs[mask])\n",
    "spec_dists = squareform(raw_spec_dists)\n",
    "mag_diffs = squareform(pdist(a.mags[mask][:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mask = spec_dists < np.percentile(raw_spec_dists, 20)\n",
    "plt.figure()\n",
    "plt.hist(mag_diffs[dist_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1, idx2 = np.where(dist_mask & (mag_diffs > 0.35))\n",
    "idx_mask = idx1 < idx2\n",
    "idx1 = idx1[idx_mask]\n",
    "idx2 = idx2[idx_mask]\n",
    "\n",
    "def print_pairs(vals):\n",
    "    for val_name, val in vals.items():\n",
    "        print(\"%13s_1\" % val_name, \"%13s_2\" % val_name, end='')\n",
    "    print('')\n",
    "        \n",
    "    for i, j in zip(idx1, idx2):\n",
    "        for val_name, val in vals.items():\n",
    "            try:\n",
    "                print('%15.3f' % val[mask][i], '%15.3f' % val[mask][j], end='')\n",
    "            except TypeError:\n",
    "                print('%15s' % val[mask][i], '%15s' % val[mask][j], end='')\n",
    "        print('')\n",
    "\n",
    "print_pairs({\n",
    "    'target': a.targets,\n",
    "    'redshift': a.redshifts,\n",
    "    'color': a.colors,\n",
    "    'mag': a.mags,\n",
    "    'salt_mag': a.salt_hr,\n",
    "    'embedding[0]': a.embedding[:, 0],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision to Branch classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_blondin_plot()\n",
    "plt.savefig('./figures/branch_classification.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot(axis_1=0, axis_2=2)\n",
    "plt.gca().get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot(axis_1=1, axis_2=2)\n",
    "plt.gca().get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot()\n",
    "plt.gca().get_legend().remove()\n",
    "plt.savefig('./figures/branch_labels_isomap.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation of Core Normal SNe Ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = a.get_indicators() \n",
    "\n",
    "s1 = indicators[\"EWSiII6355\"]\n",
    "s2 = indicators[\"EWSiII5972\"]\n",
    "\n",
    "component = 0\n",
    "\n",
    "core_normal_cut = (s2 < 30) & (s1 > 70) & (s1 < 100) & ~np.isnan(a.embedding[:, component])\n",
    "\n",
    "cut_flux = a.scale_flux[core_normal_cut]\n",
    "cut_coord = a.embedding[core_normal_cut][:, component]\n",
    "\n",
    "sort_flux = cut_flux[np.argsort(cut_coord)]\n",
    "sort_coord = cut_coord[np.argsort(cut_coord)]\n",
    "\n",
    "num_bins = 5\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=np.percentile(cut_coord, 100 / num_bins / 2), vmax=np.percentile(cut_coord, 100 * (1 - 1. / num_bins / 2))))\n",
    "sm._A = []\n",
    "\n",
    "def plot_spec(bin_idx):\n",
    "    min_idx = int(len(sort_coord) / num_bins * bin_idx)\n",
    "    max_idx = int(len(sort_coord) / num_bins * (bin_idx + 1))\n",
    "    bin_flux = sort_flux[min_idx:max_idx]\n",
    "    \n",
    "    f = np.median(bin_flux, axis=0)\n",
    "    \n",
    "    mean_val = np.mean(sort_coord[min_idx:max_idx])\n",
    "    \n",
    "    plt.plot(a.wave, f * spectrum_plot_scale, c=sm.to_rgba(mean_val), zorder=np.abs(mean_val))\n",
    "    \n",
    "plt.figure(figsize=spectrum_plot_figsize)\n",
    "for i in range(num_bins):\n",
    "    plot_spec(i)\n",
    "plt.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/core_normal_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering other indicators of intrinsic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an array to hold everything\n",
    "all_indicators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral features\n",
    "indicators = a.spectral_indicators\n",
    "\n",
    "name_map = {\n",
    "    'EWCaIIHK': 'pEW Ca II HK',\n",
    "    'EWSiII4000': 'pEW Si II 4000',#$\\AA$',\n",
    "    'EWSiII5972': 'pEW Si II 5972',#$\\AA$',\n",
    "    'EWSiII6355': 'pEW Si II 6355',#$\\AA$',\n",
    "    'vCaIIHK': 'Velocity Ca II HK',\n",
    "    'vSiII6355': 'Velocity Si II 6355',#$\\AA$',\n",
    "    'lamCaIIHK': 'Lambda Ca II HK',\n",
    "    'lamSiII6355': 'Lambda Si II 6355',#$\\AA$',\n",
    "}\n",
    "\n",
    "for key in indicators.keys():\n",
    "    values = indicators[key]\n",
    "\n",
    "    if key[:3] == 'lam':\n",
    "        continue\n",
    "        \n",
    "    if key[:1] == 'v':\n",
    "        # Use km/s and make everything positive.\n",
    "        values = values / -1000\n",
    "\n",
    "    all_indicators.append((name_map[key], values, a.uncertainty_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALT2 X1\n",
    "all_indicators.append(('SALT2 $x_1$', a.salt_x1, a.salt_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Sugar parameters\n",
    "pickle_data =  open('./data/sugar_parameters.pkl').read().replace('\\r\\n', '\\n').encode('latin1')\n",
    "sugar_data = pickle.loads(pickle_data, encoding='latin1')\n",
    "\n",
    "sugar_rows = []\n",
    "for target in a.targets:\n",
    "    try:\n",
    "        row = sugar_data[target.name.encode('latin1')]\n",
    "        sugar_rows.append([row['q1'], row['q2'], row['q3']])\n",
    "    except KeyError:\n",
    "        sugar_rows.append([np.nan] * 3)\n",
    "\n",
    "sugar_embedding = np.array(sugar_rows, dtype=float)\n",
    "sugar_mask = ~np.isnan(sugar_embedding[:, 0])\n",
    "\n",
    "for component in range(3):\n",
    "    all_indicators.append(('SUGAR Component %d\\n(Leget et al. 2019)' % (component + 1), sugar_embedding[:, component], sugar_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nordin colors\n",
    "nordin_bands = {\n",
    "    'uNi': (3300., 3510.),\n",
    "    'uTi': (3510., 3660.),\n",
    "    'uSi': (3660., 3760.),\n",
    "    'uCa': (3750., 3860.),\n",
    "}\n",
    "\n",
    "for label, (wave_min, wave_max) in nordin_bands.items():\n",
    "    cut = (a.wave > wave_min) & (a.wave < wave_max)\n",
    "    \n",
    "    values = -2.5*np.log10(np.sum(a.scale_flux[:, cut], axis=1) / np.sum(a.mean_flux[cut]))\n",
    "    \n",
    "    all_indicators.append(('U-band variation—%s\\n(Nordin et al. 2018)' % label, values, a.uncertainty_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNEMO parameters\n",
    "import pandas as pd\n",
    "snemo_data = pd.read_csv('./data/snemo_salt_coefficients_snf.csv').set_index('SN')\n",
    "\n",
    "nan_row = snemo_data.iloc[0].copy()\n",
    "nan_row[:] = np.nan\n",
    "\n",
    "snemo_rows = []\n",
    "for target in a.targets:\n",
    "    try:\n",
    "        row = snemo_data.loc[target.name]\n",
    "        snemo_rows.append(row)\n",
    "    except KeyError:\n",
    "        snemo_rows.append(nan_row)\n",
    "\n",
    "snemo_embedding = pd.DataFrame(snemo_rows)\n",
    "snemo_mask = ~np.isnan(snemo_embedding['salt_c'])\n",
    "snemo_labels = snemo_data.columns\n",
    "\n",
    "# SNEMO 2\n",
    "all_indicators.append(('SNEMO2 Component 1\\n(Saunders et al. 2018)', snemo_embedding['snemo2_c1'], snemo_mask))\n",
    "\n",
    "# SNEMO 7\n",
    "for component in range(6):\n",
    "    all_indicators.append(('SNEMO7 Component %d' % (component + 1), snemo_embedding[f'snemo7_c{component+1}'], snemo_mask))\n",
    "    \n",
    "# SNEMO 15\n",
    "# for component in range(14):\n",
    "    # all_indicators.append(('SNEMO15 Component %d' % (component + 1), snemo_embedding[f'snemo15_c{component+1}'], snemo_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def find_rotation(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def to_min(x):\n",
    "        diff = values - a.embedding.dot(x[1:]) - x[0]\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0, 0, 0, 0])\n",
    "\n",
    "    rotation = res.x[1:] / np.sqrt(np.sum(res.x[1:]**2))\n",
    "    best_guess = a.embedding.dot(res.x[1:]) + res.x[0]\n",
    "    \n",
    "    return rotation, best_guess\n",
    "\n",
    "def find_rotation_quadratic(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def evaluate(x):\n",
    "        e = a.embedding.T\n",
    "        \n",
    "        model = (\n",
    "            x[0]\n",
    "            + e[0] * x[1]\n",
    "            + e[1] * x[2]\n",
    "            + e[2] * x[3]\n",
    "            + e[0] * e[0] * x[4]\n",
    "            + e[1] * e[1] * x[5]\n",
    "            + e[2] * e[2] * x[6]\n",
    "            + e[0] * e[1] * x[7]\n",
    "            + e[0] * e[2] * x[8]\n",
    "            + e[1] * e[2] * x[9]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def to_min(x):\n",
    "        model = evaluate(x)\n",
    "        diff = values - model\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0] * 10)\n",
    "\n",
    "    best_guess = evaluate(res.x)\n",
    "    \n",
    "    return res.x, best_guess\n",
    "\n",
    "names = []\n",
    "data = []\n",
    "\n",
    "for name, values, mask in all_indicators[::-1]:\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    \n",
    "    params_quadratic, best_guess_quadratic = find_rotation_quadratic(values, mask)\n",
    "    corrcoef_quadratic = np.corrcoef(best_guess_quadratic[mask], values[mask])[0, 1]\n",
    "    \n",
    "    names.append(name)\n",
    "    data.append(np.hstack([rotation, corrcoef, corrcoef_quadratic]))\n",
    "\n",
    "    # print(f'{name} & {rotation[0]:.2f} & {rotation[1]:.2f} & {rotation[2]:.2f} & {corrcoef:.2f}')\n",
    "    \n",
    "data = np.array(data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5.0, 8))\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-1, vmax=1))\n",
    "sm._A = []\n",
    "\n",
    "def do_plot(ax, ax_data, xlabels, ylabels=None):\n",
    "    im = ax.imshow(ax_data, interpolation='nearest', cmap=cmap, vmin=-1, vmax=1)\n",
    "    ax.set(\n",
    "        xticks=np.arange(ax_data.shape[1]),\n",
    "        yticks=np.arange(ax_data.shape[0]),\n",
    "        xticklabels=xlabels,\n",
    "    )\n",
    "\n",
    "    if ylabels is not None:\n",
    "        ax.set_yticklabels(ylabels)\n",
    "    else:\n",
    "        ax.tick_params(axis='y', which='both', left=False, right=False)\n",
    "\n",
    "    ax.set_xlim(-0.5, ax_data.shape[1] - 0.5)\n",
    "    ax.set_ylim(-0.5, ax_data.shape[0] - 0.5)\n",
    "\n",
    "    # Ticks on top\n",
    "    ax.get_xaxis().set_ticks_position('top')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=70, ha=\"left\", va='center',\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.65\n",
    "    for i in range(ax_data.shape[0]):\n",
    "        for j in range(ax_data.shape[1]):\n",
    "            ax.text(j, i, format(ax_data[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if np.abs(ax_data[i, j]) > thresh else \"black\")\n",
    "            \n",
    "do_plot(axes[0], data[:, :3], ['Component 1 Rotation', 'Component 2 Rotation', 'Component 3 Rotation'], names)\n",
    "do_plot(axes[1], data[:, 3:], ['Linear Transformation\\nPearson Correlation', 'Quadratic Transformation\\nPearson Correlation'])\n",
    "\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes('right', size='30%', pad=0.23)\n",
    "fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/indicators_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "        \n",
    "    min_val = np.min([values[mask], best_guess[mask]])\n",
    "    max_val = np.max([values[mask], best_guess[mask]])\n",
    "    val_range = max_val - min_val\n",
    "    \n",
    "    plt.figure(figsize=(4, 3.8))\n",
    "    plt.scatter(best_guess[mask], values[mask])\n",
    "    \n",
    "    plt.text(min_val + 0.*val_range, max_val - 0.02*val_range, \"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    print(\"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    \n",
    "    plt.plot([min_val - val_range, min_val + val_range], [min_val - val_range, min_val + val_range], c='k', ls='--')\n",
    "\n",
    "    plt.xlabel('Transformation of the Isomap latent space')\n",
    "    \n",
    "    plt.ylabel(name)\n",
    "    # plt.ylabel(\"Original measurement\")\n",
    "    # plt.title(name)\n",
    "    \n",
    "    plt.xlim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.ylim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1), quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "        \n",
    "    min_val = np.min([values[mask], best_guess[mask]])\n",
    "    max_val = np.max([values[mask], best_guess[mask]])\n",
    "    val_range = max_val - min_val\n",
    "    \n",
    "    plt.figure(figsize=(2.5, 2.7))\n",
    "    plt.scatter(best_guess[mask], values[mask], s=10)\n",
    "    \n",
    "    plt.text(min_val + 0.*val_range, max_val - 0.04*val_range, \"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    print(\"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    \n",
    "    plt.plot([min_val - val_range, min_val + val_range], [min_val - val_range, min_val + val_range], c='k', ls='--')\n",
    "\n",
    "    # plt.xlabel('Transformation of the Isomap latent space')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # plt.ylabel(name)\n",
    "    # plt.ylabel(\"Original measurement\")\n",
    "    plt.title(name.split('\\n')[0])\n",
    "    \n",
    "    plt.xlim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.ylim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.tight_layout()\n",
    "\n",
    "interact(plot_component, idx=(0, len(data) - 1), quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    plot_component(i, quadratic=True)\n",
    "    plt.savefig('./figures/rotation_%d.png' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('SALT2 $x_1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.text(-0.3, 0.6, 'hi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component(6, quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(best_guess[mask], values[mask])\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Transformation of the Isomap latent space')\n",
    "    plt.ylabel(name)\n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for AAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1, mask=a.salt_mask, label='SALT2 $x_1$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Figure out what happened with SNBOSS38. Somehow the SALT2 fit is way off, but it doesn't fail the SALT2 fit cuts. Reject in manually for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[a.salt_mask, 1], a.salt_x1[a.salt_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (a.embedding[:, 0] > 2) & (a.embedding[:, 1] > 1) & (a.embedding[:, 1] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.where(mask)[0]:\n",
    "    print(a.targets[i], a.embedding[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.salt_mask[(a.salt_x1 > 1) & (a.embedding[:, 1] > 1)] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.salt_hr[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tt[2].fit_salt(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out what correlation coefficient we would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrcoef_linear = []\n",
    "all_corrcoef_quadratic = []\n",
    "\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    mask = a.interp_mask\n",
    "    values = np.random.normal(size=len(values))\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    all_corrcoef_linear.append(corrcoef)\n",
    "    \n",
    "    rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    all_corrcoef_quadratic.append(corrcoef)\n",
    "\n",
    "with open('./latex/correlation_simulation.tex', 'w') as f:\n",
    "    latex_command(f, 'correlationmeanlinear', '%.2f', np.mean(all_corrcoef_linear))\n",
    "    latex_command(f, 'correlationstdlinear', '%.2f', np.std(all_corrcoef_linear))\n",
    "    latex_command(f, 'correlationmeanquadratic', '%.2f', np.mean(all_corrcoef_quadratic))\n",
    "    latex_command(f, 'correlationstdquadratic', '%.2f', np.std(all_corrcoef_quadratic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot rotated spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_steps(idx, quadratic=False):\n",
    "    num_steps = 10\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.interp_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    use_embedding = best_guess[mask]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    plt.figure(figsize=spectrum_plot_figsize)\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        plt.plot(a.wave, step_flux * spectrum_plot_scale, c=sm.to_rgba(mean_val))\n",
    "        \n",
    "    plt.colorbar(sm, label='Rotated Isomap vSi II 6355$\\AA$\\nEstimate ($10^3$ km/s)')\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "    plt.ylim(0, None)\n",
    "    plt.title(name)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "interact(plot_steps, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear combinations of SUGAR components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indicators.append(('Isomap Component 1', a.embedding[:, 0], a.interp_mask))\n",
    "all_indicators.append(('Isomap Component 2', a.embedding[:, 1], a.interp_mask))\n",
    "all_indicators.append(('Isomap Component 3', a.embedding[:, 2], a.interp_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def find_rotation(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def to_min(x):\n",
    "        diff = values - sugar_embedding.dot(x[1:]) - x[0]\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0, 0, 0, 0])\n",
    "\n",
    "    rotation = res.x[1:] / np.sqrt(np.sum(res.x[1:]**2))\n",
    "    best_guess = sugar_embedding.dot(res.x[1:]) + res.x[0]\n",
    "    \n",
    "    return rotation, best_guess\n",
    "\n",
    "def find_rotation_quadratic(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def evaluate(x):\n",
    "        e = sugar_embedding.T\n",
    "        \n",
    "        model = (\n",
    "            x[0]\n",
    "            + e[0] * x[1]\n",
    "            + e[1] * x[2]\n",
    "            + e[2] * x[3]\n",
    "            + e[0] * e[0] * x[4]\n",
    "            + e[1] * e[1] * x[5]\n",
    "            + e[2] * e[2] * x[6]\n",
    "            + e[0] * e[1] * x[7]\n",
    "            + e[0] * e[2] * x[8]\n",
    "            + e[1] * e[2] * x[9]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def to_min(x):\n",
    "        model = evaluate(x)\n",
    "        diff = values - model\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0] * 10)\n",
    "\n",
    "    best_guess = evaluate(res.x)\n",
    "    \n",
    "    return res.x, best_guess\n",
    "\n",
    "names = []\n",
    "data = []\n",
    "\n",
    "for name, values, mask in all_indicators[::-1]:\n",
    "    mask = mask & sugar_mask\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    \n",
    "    params_quadratic, best_guess_quadratic = find_rotation_quadratic(values, mask)\n",
    "    corrcoef_quadratic = np.corrcoef(best_guess_quadratic[mask], values[mask])[0, 1]\n",
    "    \n",
    "    names.append(name)\n",
    "    data.append(np.hstack([rotation, corrcoef, corrcoef_quadratic]))\n",
    "\n",
    "    # print(f'{name} & {rotation[0]:.2f} & {rotation[1]:.2f} & {rotation[2]:.2f} & {corrcoef:.2f}')\n",
    "    \n",
    "data = np.array(data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5.0, 8))\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-1, vmax=1))\n",
    "sm._A = []\n",
    "\n",
    "def do_plot(ax, ax_data, xlabels, ylabels=None):\n",
    "    im = ax.imshow(ax_data, interpolation='nearest', cmap=cmap, vmin=-1, vmax=1)\n",
    "    ax.set(\n",
    "        xticks=np.arange(ax_data.shape[1]),\n",
    "        yticks=np.arange(ax_data.shape[0]),\n",
    "        xticklabels=xlabels,\n",
    "    )\n",
    "\n",
    "    if ylabels is not None:\n",
    "        ax.set_yticklabels(ylabels)\n",
    "    else:\n",
    "        ax.tick_params(axis='y', which='both', left=False, right=False)\n",
    "\n",
    "    ax.set_xlim(-0.5, ax_data.shape[1] - 0.5)\n",
    "    ax.set_ylim(-0.5, ax_data.shape[0] - 0.5)\n",
    "\n",
    "    # Ticks on top\n",
    "    ax.get_xaxis().set_ticks_position('top')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=70, ha=\"left\", va='center',\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.65\n",
    "    for i in range(ax_data.shape[0]):\n",
    "        for j in range(ax_data.shape[1]):\n",
    "            ax.text(j, i, format(ax_data[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if np.abs(ax_data[i, j]) > thresh else \"black\")\n",
    "            \n",
    "do_plot(axes[0], data[:, :3], ['Component 1 Rotation', 'Component 2 Rotation', 'Component 3 Rotation'], names)\n",
    "do_plot(axes[1], data[:, 3:5], ['Linear Rotation\\nPearson Correlation', 'Quadratic Rotation\\nPearson Correlation'])\n",
    "\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes('right', size='30%', pad=0.23)\n",
    "fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/indicators_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & sugar_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(best_guess[mask], values[mask], c=a.colors[mask], vmin=-0.2, vmax=0.2)\n",
    "    plt.title(name)\n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81729f79fb3a412ca16c44d0abe16f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.scatter(a.rbtl_colors, vmin=-0.3, vmax=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(-0.54*sugar_embedding[:, 0] + 0.84 * sugar_embedding[:, 2], a.salt_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[:, 1], a.colors, c=a.embedding[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d09d8a3b4ff4b60ba5426b1e9e4b288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.29906577117714916"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "m = (a.redshifts > 0.02) & (a.redshift_errs < 0.004) & (a.uncertainty_mask)\n",
    "plt.scatter(a.rbtl_colors[m] - np.median(a.rbtl_colors[m]), a.corr_mags[m])\n",
    "\n",
    "np.std(a.corr_mags[m & (a.rbtl_colors - np.median(a.rbtl_colors) > 0.5) & a.train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7725ea4f6709435ba4d662c9b926ed12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52fc124250>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, np.sqrt(np.mean(utils.frac_to_mag((a.maximum_fluxerr / a.maximum_flux)[a.uncertainty_mask])**2, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf881773d6487d8b54654064fadbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52fd013a50>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, 1/a.rbtl_result['fractional_dispersion']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bb5b6c4e2f4a9aae89dd44b6944f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f52fdc02890>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[a.uncertainty_mask, 0], a.embedding[a.uncertainty_mask, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.spectra[(a.trans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f52fd9e05d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(0.548, -0.830)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((a.rbtl_colors - np.median(a.rbtl_colors)) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Target(name=\"LSQ12gxj\"), Target(name=\"PTF10wnm\")], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.targets[dists < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5ad6fee4d34826b509b3ac214dd20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52fd7e3e10>,\n",
       " <matplotlib.lines.Line2D at 0x7f52fd6d6350>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, a.scale_flux[dists < 0.1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dists = np.sum((a.embedding - a.embedding[m & (a.corr_mags > 0.5)])**2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 91T/91bg labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_labels = {\n",
    "    # Scalzo++ 2014\n",
    "    \"SNF20070528-003\": \"91T-like\",\n",
    "    \"SNF20070803-005\": \"91T-like\",\n",
    "    \"SNF20070825-001\": \"91T-like\",\n",
    "    \"SNF20070912-000\": \"91T-like\",\n",
    "    \"SNF20080522-000\": \"91T-like\",\n",
    "    \"SNF20080723-012\": \"91T-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"SNF20080805-007\": \"91T-like\",\n",
    "    \"LSQ12cyz\": \"91T-like\",\n",
    "    \"LSQ12fhe\": \"91T-like\",\n",
    "    \"PTF11bju\": \"91T-like\",\n",
    "    \"PTF11mkx\": \"91T-like\",\n",
    "    \"LSQ12cfx\": \"91bg-like\",\n",
    "    \n",
    "    # Discussion between Kyle and Greg:\n",
    "    \"SNNGC2691\": \"91T-like\",\n",
    "    \n",
    "    # Maguire++ 2011\n",
    "    \"PTF10ops\": \"91bg-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"PTF11bkf\": \"91bg-like\",\n",
    "    \"PTF11kjn\": \"91bg-like\",\n",
    "    \"PTF11okh\": \"91bg-like\",\n",
    "    \"PTF11pra\": \"91bg-like\",\n",
    "    \"PTF12dwm\": \"91bg-like\",\n",
    "    \"SN2005bl\": \"91bg-like\",\n",
    "    \"SN2005dh\": \"91bg-like\",\n",
    "    \"SN2005dm\": \"91bg-like\",\n",
    "    \"SN2007ba\": \"91bg-like\",\n",
    "    \"SN2009hs\": \"91bg-like\",\n",
    "    \"SNNGC6430\": \"91bg-like\",\n",
    "    \"SN2005cc\": \"02cx-like\",\n",
    "    \n",
    "    # Foley++ 2013\n",
    "    \"SN2011ay\": \"02cx-like\",\n",
    "    \"LSQ12fhs\": \"02cx-like\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Target(name=\"LSQ12fhs\"), Target(name=\"SN2011ay\"),\n",
       "       Target(name=\"SNF20070528-003\")], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.targets[a.embedding[:, 0] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41be8fd0cd04af8bae99140877b0b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "colors = []\n",
    "labels = []\n",
    "for idx, sn in enumerate(a.targets):\n",
    "    if not a.uncertainty_mask[idx]:\n",
    "        continue\n",
    "\n",
    "    label = outlier_labels.get(sn.name, 'Other')\n",
    "    if label == 'Other':\n",
    "        c = 'silver'\n",
    "    elif label == '91bg-like':\n",
    "        c = 'C0'\n",
    "    elif label == '91T-like':\n",
    "        c = 'C2'\n",
    "    elif label == '02cx-like':\n",
    "        c = 'C3'\n",
    "        \n",
    "    if c in colors:\n",
    "        plot_label = ''\n",
    "    else:\n",
    "        plot_label = label\n",
    "\n",
    "    colors.append(c)\n",
    "    \n",
    "    plt.scatter(a.embedding[idx, 0], a.embedding[idx, 1], label=plot_label, facecolors=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.targets[np.array([i.name == 'SNF20070825-001' for i in a.targets])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2f868b104446babae1e476470ce58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_91t = np.array([outlier_labels.get(i.name, 'aa') == '91T-like' for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mask_91t & a.uncertainty_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mask_91t & a.redshift_color_mask & a.uncertainty_mask & a.train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.corr_mags, mask=a.good_mag_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.where((a.embedding[:, 0] > 4) & (a.embedding[:, 1] > -1.5))[0]:\n",
    "    target = a.targets[idx]\n",
    "    print(a.embedding[idx], target, outlier_labels.get(target.name, 'Other'), a.corr_mags[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALT2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SALT2 Hubble residuals\n",
    "a.calculate_salt_hubble_residuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.salt_color, a.colors, s=5)\n",
    "plt.xlabel('SALT2 Color ($c$)')\n",
    "plt.ylabel('RBTL Color ($A_V$)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/salt2_color_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1, a.interp_mask, label='SALT $x_1$')\n",
    "plt.savefig('./figures/salt2_x1_components_full.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1, a.interp_mask & a.good_salt_mask, axis_1=0, axis_2=1, label='SALT $x_1$', vmin=-2., vmax=1.5)\n",
    "plt.savefig('./figures/salt2_x1_components.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_gp(kind='salt_raw', vmin=-0.5, vmax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best predictor of x1\n",
    "def to_min(x):\n",
    "    diff = a.salt_x1 - a.embedding.dot(x)\n",
    "    return np.nanstd(diff[a.salt_mask])\n",
    "\n",
    "res = minimize(to_min, [0, 0, 0])\n",
    "\n",
    "norm_x = res.x / np.sqrt(np.sum(res.x**2))\n",
    "print(norm_x)\n",
    "\n",
    "plt.figure()\n",
    "# plt.scatter(a.embedding.dot(res.x), a.salt_x1, c=a.salt_mask)\n",
    "plt.scatter(a.embedding.dot(res.x)[~a.salt_mask], a.salt_x1[~a.salt_mask], c='C3', s=30, label='\"Bad\" SALT2 fits', alpha=0.8)\n",
    "plt.scatter(a.embedding.dot(res.x)[a.salt_mask], a.salt_x1[a.salt_mask], c='C0', s=30, label='\"Good\" SALT2 fits', alpha=0.8)\n",
    "plt.plot([-3, 3], [-3, 3], ls='--', c='k', label='One-to-one line')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel('Rotated Isomap components')\n",
    "plt.ylabel('SALT2 $x_1$')\n",
    "plt.legend()\n",
    "plt.savefig('./figures/rotated_isomap_salt_x1.pdf')\n",
    "\n",
    "\n",
    "print(np.corrcoef(a.embedding.dot(res.x)[a.interp_mask & a.salt_mask], a.salt_x1[a.interp_mask & a.salt_mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 outliers (Type Iax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iax_mask = (a.embedding[:, 0] > 4.) & (a.embedding[:, 1] < -3)\n",
    "a.targets[iax_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier spectra\n",
    "mask = (a.embedding[:, 0] > 4) & (a.embedding[:, 1] < -2)\n",
    "print(a.targets[mask])\n",
    "print(a.colors[mask])\n",
    "print(a.redshifts[mask])\n",
    "print(a.mags[mask])\n",
    "\n",
    "# Ref spectrum\n",
    "ref_target = 'SNF20070803-005'\n",
    "for idx2, target in enumerate(a.targets):\n",
    "    if target.name == ref_target:\n",
    "        break\n",
    "        \n",
    "# idx2 = np.where((a.embedding[:, 0] > 4.8) & (a.embedding[:, 1] < 2))[0][0]\n",
    "\n",
    "plt.figure()\n",
    "for i in np.where(mask)[0]:\n",
    "    plt.plot(a.wave, a.scale_flux[i] * spectrum_plot_scale, label=a.targets[i].name)\n",
    "    \n",
    "plt.plot(a.wave, a.scale_flux[idx2] * spectrum_plot_scale, c='k', ls='--', label=a.targets[idx2].name)\n",
    "print(a.embedding[idx2])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/type_iax_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.targets[(a.embedding[:, 1] > 4.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier spectra\n",
    "mask = (a.embedding[:, 0] < -4)\n",
    "print(a.targets[mask])\n",
    "print(a.colors[mask])\n",
    "print(a.redshifts[mask])\n",
    "print(a.mags[mask])\n",
    "\n",
    "# Ref spectrum\n",
    "# ref_target = 'SNF20070803-005'\n",
    "# for idx2, target in enumerate(a.targets):\n",
    "    # if target.name == ref_target:\n",
    "        # break\n",
    "        \n",
    "# idx2 = np.where((a.embedding[:, 0] > 4.8) & (a.embedding[:, 1] < 2))[0][0]\n",
    "\n",
    "plt.figure()\n",
    "for i in np.where(mask)[0]:\n",
    "    plt.plot(a.wave, a.scale_flux[i] * spectrum_plot_scale, label=a.targets[i].name)\n",
    "    \n",
    "# plt.plot(a.wave, a.scale_flux[idx2] * spectrum_plot_scale, c='k', ls='--', label=a.targets[idx2].name)\n",
    "print(a.embedding[idx2])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('./figures/type_iax_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same SALT2 parameters but not at the same location in the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_diff(x):\n",
    "    return (x - x[:, None])\n",
    "\n",
    "count = np.array([len(i.spectra) for i in a.targets])\n",
    "first_phase = np.array([i.spectra[0].phase for i in a.targets])\n",
    "mask = (count > 8) & (a.redshifts > 0.03) & (first_phase < -2)\n",
    "\n",
    "salt_x1_diff = outer_diff(a.salt_x1)\n",
    "salt_c_diff = outer_diff(a.salt_color)\n",
    "salt_diff = outer_diff(a.salt_x1)**2 + 100 * outer_diff(a.salt_color)**2\n",
    "manif_diff = outer_diff(a.embedding[:, 0])**2 + outer_diff(a.embedding[:, 1])**2 + outer_diff(a.embedding[:, 2])**2\n",
    "\n",
    "phase_diff = outer_diff(a.salt_phases[a.center_mask])\n",
    "\n",
    "np.fill_diagonal(salt_diff, np.nan)\n",
    "np.fill_diagonal(manif_diff, np.nan)\n",
    "\n",
    "salt_diff[~mask] = np.nan\n",
    "salt_diff[:, ~mask] = np.nan\n",
    "manif_diff[~mask] = np.nan\n",
    "manif_diff[:, ~mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = (salt_x1_diff > 0) & (salt_x1_diff < 0.2) & (np.abs(salt_c_diff) < 0.02) & (manif_diff > 30) & (np.abs(phase_diff) < 1.0)\n",
    "print(\"Num objects:  %s\" % np.sum(cut))\n",
    "salt_diff_idx = [i[2] for i in np.where(cut)]\n",
    "\n",
    "t1 = a.targets[salt_diff_idx[0]]\n",
    "t2 = a.targets[salt_diff_idx[1]]\n",
    "\n",
    "print(\"target 1:     %s\" % t1)\n",
    "print(\"target 2:     %s\" % t2)\n",
    "print(\"redshifts:    %.4f, %.4f\" % (a.redshifts[salt_diff_idx[0]], a.redshifts[salt_diff_idx[1]]))\n",
    "print(\"x_1 values:   %+.3f, %+.3f\" % (a.salt_x1[salt_diff_idx[0]], a.salt_x1[salt_diff_idx[1]]))\n",
    "print(\"c values:     %+.3f, %+.3f\" % (a.salt_color[salt_diff_idx[0]], a.salt_color[salt_diff_idx[1]]))\n",
    "print(\"mags:         %.3f, %.3f\" % (a.mags[salt_diff_idx[0]], a.mags[salt_diff_idx[1]]))\n",
    "print(\"salt HRs:     %.3f, %.3f\" % (a.salt_hr[salt_diff_idx[0]], a.salt_hr[salt_diff_idx[1]]))\n",
    "print(\"corr mags:    %.3f, %.3f\" % (a.corr_mags[salt_diff_idx[0]], a.corr_mags[salt_diff_idx[1]]))\n",
    "print(\"embedding 1:  %s\" % a.embedding[salt_diff_idx[0]])\n",
    "print(\"embedding 2:  %s\" % a.embedding[salt_diff_idx[1]])\n",
    "\n",
    "salt_comparision_mb_diff = np.abs(\n",
    "    a.salt_hr[salt_diff_idx[0]]\n",
    "    - a.salt_hr[salt_diff_idx[1]]\n",
    ")\n",
    "dm_1 = frac_to_mag(t1.salt_fit['x0_err'] / t1.salt_fit['x0'])\n",
    "dm_2 = frac_to_mag(t2.salt_fit['x0_err'] / t2.salt_fit['x0'])\n",
    "\n",
    "salt_comparison_mb_diff_err = np.sqrt(dm_1**2 + dm_2**2)\n",
    "print(\"mag_diff:     %.3f +/- %.3f\" % (salt_comparision_mb_diff, salt_comparison_mb_diff_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['U', 'B', 'V', 'R', 'I']\n",
    "\n",
    "band_colors = {\n",
    "    'U': 'C4',\n",
    "    'B': 'C0',\n",
    "    'V': 'C2',\n",
    "    'R': 'C3',\n",
    "    'I': 'C1',\n",
    "}\n",
    "\n",
    "gap = 1.\n",
    "\n",
    "def plot_lightcurve(target, marker='o', ls='--', mfc='none', label_bands=True):\n",
    "    photometry = target.get_photometry(bands, clip_filter=True)\n",
    "    \n",
    "    # Cut late phases\n",
    "    photometry = photometry[photometry['time'] < 30]\n",
    "        \n",
    "    ref_mag = target.salt_fit['fitted_model'].source_peakmag('snfb', 'ab')\n",
    "    \n",
    "    for offset, band in enumerate(bands):\n",
    "        band_photometry = photometry[photometry['band'] == 'snf%s' % band.lower()]\n",
    "        \n",
    "        if band == 'B':\n",
    "            label = target.name\n",
    "        else:\n",
    "            label = ''\n",
    "            \n",
    "        color = band_colors[band]\n",
    "        \n",
    "        phases = band_photometry['time']\n",
    "        mags = -2.5*np.log10(band_photometry['flux']) - ref_mag - (offset - 1) * gap\n",
    "        magerrs = band_photometry['magerr']\n",
    "    \n",
    "        plt.errorbar(phases, mags, magerrs, fmt='none', c=color)\n",
    "        plt.plot(phases, mags, label=label, marker=marker, c=color, mfc=mfc, ls=ls)\n",
    "        \n",
    "        if label_bands:\n",
    "            plt.text(phases[-1] + 2, mags[-1] + 0.2, '%s%+d' % (band, offset - 1), c=color)\n",
    "            plt.xlim(None, phases[-1] + 9)\n",
    "            \n",
    "def plot_salt_lightcurve(target, phase_min=-6, phase_max=50):\n",
    "    model = target.salt_fit['fitted_model']\n",
    "    phases = np.linspace(phase_min, phase_max, 200)\n",
    "    \n",
    "    # Compute the reference magnitude for B-band at max.\n",
    "    ref_mag = model.source_peakmag('snfb', 'ab')\n",
    "\n",
    "    # Plot each light curve\n",
    "    for offset, band in enumerate(bands):\n",
    "        mags = model.bandmag('snf%s' % band.lower(), 'ab', phases) - ref_mag - (offset - 1) * gap\n",
    "        plt.plot(phases, mags, c='k')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plot_lightcurve(t1, marker='^', ls='', mfc=None, label_bands=False)\n",
    "plot_lightcurve(t2, marker='o', ls='', mfc='none', label_bands=True)\n",
    "# plot_salt_lightcurve(t1)\n",
    "plt.legend()\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Normalized magnitude + offset')\n",
    "plt.ylim(4.8, -2.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/same_salt_comparison.pdf')\n",
    "\n",
    "# plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "def plot_spec(idx):\n",
    "    spec = a.spectra[a.center_mask][idx]\n",
    "\n",
    "    ref_mag = spec.target.salt_fit['fitted_model'].source_peakmag('snfb', 'ab')\n",
    "    \n",
    "    label = '%s, %.2f days' % (spec.target.name, spec.phase)\n",
    "    \n",
    "    scale = 10**(+0.4*ref_mag)\n",
    "    \n",
    "    plt.plot(a.wave, spec.flux * scale * spectrum_plot_scale, label=label)\n",
    "\n",
    "plot_spec(salt_diff_idx[0])\n",
    "plot_spec(salt_diff_idx[1])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Restframe wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/same_salt_spectra.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump details to latex\n",
    "with open('latex/salt_comparison.tex', 'w') as f:\n",
    "    latex_print(f, \"\")\n",
    "    t1 = a.targets[salt_diff_idx[0]]\n",
    "    t2 = a.targets[salt_diff_idx[1]]\n",
    "    latex_command(f, 'saltcompnamea', '%s', t1.name)\n",
    "    latex_command(f, 'saltcompnameb', '%s', t2.name)\n",
    "    latex_command(f, 'saltcompxonea', '%.3f $\\\\pm$ %.3f', (t1['salt2.X1'], t1['salt2.X1.err']))\n",
    "    latex_command(f, 'saltcompxoneb', '%.3f $\\\\pm$ %.3f', (t2['salt2.X1'], t2['salt2.X1.err']))\n",
    "    latex_command(f, 'saltcompca', '%.3f $\\\\pm$ %.3f', (t1['salt2.Color'], t1['salt2.Color.err']))\n",
    "    latex_command(f, 'saltcompcb', '%.3f $\\\\pm$ %.3f', (t2['salt2.Color'], t2['salt2.Color.err']))\n",
    "    latex_command(f, 'saltcompcoorda', '%.2f', a.embedding[salt_diff_idx[0], 0])\n",
    "    latex_command(f, 'saltcompcoordb', '%.2f', a.embedding[salt_diff_idx[1], 0])\n",
    "    latex_command(f, 'saltcompmagbdiff', '%.3f $\\\\pm$ %.3f', (salt_comparision_mb_diff, salt_comparison_mb_diff_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bunch of functions to make things easier.\n",
    "def latex_host_step(file, name, var, mags, mask):\n",
    "    step, step_err = analyze_host_variable(var, mags, mask, plot=False)\n",
    "    latex_command(file, name, '%.3f $\\\\pm$ %.3f', (np.abs(step), step_err))\n",
    "\n",
    "a.fit_gp(kind='salt_raw', verbose=False)\n",
    "salt_isomap_mags = a.corr_mags.copy()\n",
    "\n",
    "a.fit_gp(verbose=False)\n",
    "rbtl_isomap_mags = a.corr_mags.copy()\n",
    "\n",
    "with open('latex/commands.tex', 'w') as f:\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numdatasetsne', '%d', len(a.dataset.targets))\n",
    "    latex_command(f, 'numdatasetspectra', '%d', np.sum([len(i.spectra) for i in a.dataset.targets]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'nummanifoldsne', '%d', len(a.targets))\n",
    "    latex_command(f, 'nummanifoldspectra', '%d', len(a.spectra))\n",
    "    latex_command(f, 'numinterpsne', '%d', np.sum(a.interp_mask))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numsnftrain', '%d', np.sum([i.subset == 'training' for i in a.targets[a.interp_mask]]))\n",
    "    latex_command(f, 'numsnfvalid', '%d', np.sum([i.subset == 'validation' for i in a.targets[a.interp_mask]]))\n",
    "    latex_command(f, 'numsnfother', '%d', np.sum([i.subset not in ['training', 'validation'] for i in a.targets[a.interp_mask]]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numsnredshift', '%d', np.sum(a.interp_mask & (a.redshift_errs >= 0.004)))\n",
    "    latex_command(f, 'numlowredshift', '%d', np.sum(a.interp_mask & (a.redshifts <= 0.02)))\n",
    "    latex_command(f, 'numhighav', '%d', np.sum(a.interp_mask & (a.colors - np.nanmedian(a.colors) >= 0.5)))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'nummagsne', '%d', np.sum(a.interp_mask & a.redshift_color_mask))\n",
    "    latex_command(f, 'nummagsnetrain', '%d', np.sum(a.good_mag_mask))\n",
    "    latex_command(f, 'nummagsnevalidation', '%d', np.sum(a.interp_mask & a.redshift_color_mask & ~a.good_mag_mask))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'saltparammb', '%.2f', a.salt_MB)\n",
    "    latex_command(f, 'saltparamalpha', '%.3f', a.salt_alpha)\n",
    "    latex_command(f, 'saltparambeta', '%.2f', a.salt_beta)\n",
    "    latex_command(f, 'saltparamsigmaint', '%.3f', a.salt_intrinsic_dispersion)\n",
    "    # latex_command(f, 'saltparamrms', '%.3f', np.std(a.salt_hr[a.good_salt_mask]))\n",
    "    latex_std(f, 'saltparamrms', a.salt_hr[a.good_salt_mask])\n",
    "    latex_nmad(f, 'saltparamnmad', a.salt_hr[a.good_salt_mask])\n",
    "    latex_command(f, 'saltparamwrms', '%.3f', a.salt_wrms)\n",
    "    latex_command(f, 'saltparammindisp', '%.2f', np.min(a.salt_hr_uncertainties[a.good_salt_mask]))\n",
    "    latex_command(f, 'saltparammaxdisp', '%.2f', np.max(a.salt_hr_uncertainties[a.good_salt_mask]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'rawrbtlmagstd', a.mags[a.good_mag_mask])\n",
    "    latex_nmad(f, 'rawrbtlmagnmad', a.mags[a.good_mag_mask])\n",
    "    # latex_print(f, \"\")\n",
    "    # latex_command(f, 'twinrbtlmagstd', '%.3f', a.twins_rms)\n",
    "    # latex_command(f, 'twinrbtlmagnmad', '%.3f', a.twins_nmad)\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'saltcomprawrbtlmagstd', a.mags[a.good_mag_mask & a.good_salt_mask])\n",
    "    latex_std(f, 'saltcompsaltmagstd', a.salt_hr[a.good_mag_mask & a.good_salt_mask])\n",
    "\n",
    "    a.fit_gp(verbose=False, kind='salt_raw')\n",
    "    gp_uncertainties = np.sqrt(np.diag(a.gp_hyperparameter_covariance))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'saltgpcolor', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[0], gp_uncertainties[0]))\n",
    "    latex_command(f, 'saltgpintdisp', '%.3f $\\\\pm$ %.3f', (a.gp_hyperparameters[1], gp_uncertainties[1]))\n",
    "    latex_command(f, 'saltgpkernelamp', '%.3f $\\\\pm$ %.3f', (np.abs(a.gp_hyperparameters[2]), gp_uncertainties[2]))\n",
    "    latex_command(f, 'saltgpkernellengthscale', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[3], gp_uncertainties[3]))\n",
    "    latex_std(f, 'saltgprms', a.corr_mags[a.good_salt_mask & a.interp_mask])\n",
    "    latex_std(f, 'saltgpcompsaltrms', a.salt_hr[a.good_salt_mask & a.interp_mask])\n",
    "\n",
    "    a.fit_gp(verbose=False)\n",
    "    gp_uncertainties = np.sqrt(np.diag(a.gp_hyperparameter_covariance))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'rbtlgpcolor', '%.2f $\\\\pm$ %.2f', (a.fiducial_rv * (1 + a.gp_hyperparameters[0]), a.fiducial_rv * gp_uncertainties[0]))\n",
    "    latex_command(f, 'rbtlgpintdisp', '%.3f $\\\\pm$ %.3f', (a.gp_hyperparameters[1], gp_uncertainties[1]))\n",
    "    latex_command(f, 'rbtlgpkernelamp', '%.3f $\\\\pm$ %.3f', (np.abs(a.gp_hyperparameters[2]), gp_uncertainties[2]))\n",
    "    latex_command(f, 'rbtlgpkernellengthscale', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[3], gp_uncertainties[3]))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'rbtlgprms', a.corr_mags[a.good_mag_mask])\n",
    "    latex_command(f, 'rbtlgpnmad', '%.3f', math.nmad(a.corr_mags[a.good_mag_mask]))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    x1 = a.salt_hr[(a.embedding[:, 0] < 3) & a.good_salt_mask & a.interp_mask]\n",
    "    x2 = a.salt_hr[(a.embedding[:, 0] > 3) & a.good_salt_mask & a.interp_mask]\n",
    "    m1 = np.mean(x1)\n",
    "    m2 = np.mean(x2)\n",
    "    err1 = np.std(x1) / np.sqrt(len(x1))\n",
    "    err2 = np.std(x2) / np.sqrt(len(x2))\n",
    "    latex_command(f, 'saltisomapdiff', '%.3f $\\\\pm$ %.3f', (np.abs(m1-m2), np.sqrt(err1**2 + err2**2)))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'pecvelcontribution', '%.3f', np.sqrt(np.mean(a.get_peculiar_velocity_uncertainty()[a.good_mag_mask & a.good_salt_mask]**2)))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_host_step(f, 'lssfrsaltxifull', 'lssfr', a.salt_hr, a.good_salt_mask)\n",
    "    latex_host_step(f, 'gmasssaltxifull', 'gmass', a.salt_hr, a.good_salt_mask)\n",
    "    latex_host_step(f, 'lssfrsaltxicut', 'lssfr', a.salt_hr, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmasssaltxicut', 'gmass', a.salt_hr, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'lssfrsaltisomapcut', 'lssfr', salt_isomap_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmasssaltisomapcut', 'gmass', salt_isomap_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'lssfrrbtlisomapcut', 'lssfr', a.corr_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmassrbtlisomapcut', 'gmass', a.corr_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_command(f, 'hostcutsnsnetrain', '%d', np.sum(a.good_mag_mask & a.good_salt_mask & a.host_mask))\n",
    "    latex_command(f, 'hostcutsnsnefull', '%d', np.sum(a.redshift_color_mask & a.interp_mask & a.good_salt_mask & a.host_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_91t = [ \n",
    "    'SNF20070528-003', # Scalzo++ 2014\n",
    "    'SNF20070803-005', # Scalzo++ 2014\n",
    "    'SNF20070825-001', # Scalzo++ 2010\n",
    "    'SNF20070912-000', # Scalzo++ 2014\n",
    "    'SNF20080522-000', # Scalzo++ 2014\n",
    "    'SNF20080723-012', # Scalzo++ 2014\n",
    "    'SNF20080805-007', # Lin++ 2020\n",
    "    'LSQ12cyz', # Lin++ 2020\n",
    "    'LSQ12fhe', # Lin++ 2020\n",
    "    'PTF11bju', # Lin++ 2020\n",
    "    'PTF11mkx', # Lin++ 2020\n",
    "]\n",
    "\n",
    "outliers_91bg = [\n",
    "    'LSQ12cfx', # Lin++ 2020\n",
    "    'PTF10ops', # Maguire++ 2011\n",
    "    'PTF11bkf', # Lin++ 2020\n",
    "    'PTF11kjn', # Lin++ 2020\n",
    "    'PTF11okh', # Lin++ 2020\n",
    "    'PTF11pra', # Lin++ 2020\n",
    "    'PTF12dwm', # Lin++ 2020\n",
    "    'SN2005bl', # Lin++ 2020\n",
    "    'SN2005dh', # Lin++ 2020 \n",
    "    'SN2005dm', # Lin++ 2020\n",
    "    'SN2007ba', # Lin++ 2020\n",
    "    'SN2009hs', # Lin++ 2020\n",
    "    'SNNGC6430', # Lin++ 2020\n",
    "]\n",
    "\n",
    "outliers_02cx = [\n",
    "    'SN2005cc', # Lin++ 2020\n",
    "]\n",
    "\n",
    "mask_91t = np.array([i.name in outliers_91t for i in a.targets])\n",
    "mask_91bg = np.array([i.name in outliers_91bg for i in a.targets])\n",
    "mask_02cx = np.array([i.name in outliers_02cx for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09715c03ece242d5a5b5a512dd501f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "use_x = a.embedding[:, 0]\n",
    "\n",
    "mask = a.salt_mask & a.redshift_color_mask & a.uncertainty_mask\n",
    "plt.errorbar(use_x[mask], a.salt_hr[mask], a.salt_hr_uncertainties[mask], label='Individual supernovae', fmt='.', alpha=0.2, c='k')\n",
    "math.plot_binned_mean(use_x[mask], a.salt_hr[mask], c='C3', lw=2, label='Binned mean')\n",
    "\n",
    "# mask = mask & mask_91t\n",
    "# plt.scatter(use_x[mask], a.salt_hr[mask], label='91T-like SNe IA', c='C2', marker='s', zorder=10)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('SALT2 Hubble residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/home/kyle/supernova/meetings/2020_01_04_aas_hawaii/talk/salt_bias.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556449836c3248d7920913565b8bc327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_plot(label, mask=None, **kwargs):\n",
    "    if mask is None:\n",
    "        mask = a.uncertainty_mask\n",
    "    else:\n",
    "        mask = mask & a.uncertainty_mask\n",
    "\n",
    "    plt.scatter(a.embedding[mask, 0], a.embedding[mask, 1], label=label, s=50, **kwargs)\n",
    "    \n",
    "plt.figure()\n",
    "do_plot('All SNe Ia', c='k', alpha=0.1)\n",
    "do_plot('91T-like', mask_91t)\n",
    "do_plot('91bg-like', mask_91bg)\n",
    "do_plot('02cx-like', mask_02cx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
