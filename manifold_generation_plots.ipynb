{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manifold_twins import ManifoldTwinsAnalysis\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from idrtools import math\n",
    "from utils import frac_to_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "    IDR:          BLACKSTON\n",
      "    Phase range: [-5.0, 5.0] days\n",
      "    Bin velocity: 1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [00:17<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating the spectra at maximum light...\n",
      "    Loaded cached stan model\n",
      "    Using saved stan result\n",
      "Reading between the lines...\n",
      "    Loaded cached stan model\n",
      "    Using saved stan result\n",
      "Building masks...\n",
      "    Masking 30/203 targets whose uncertainty power is \n",
      "    more than 0.100 of the intrinsic power.\n",
      "Generating the manifold learning embedding...\n",
      "Calculating spectral indicators...\n",
      "Fitting RBTL GP to magnitude residuals...\n",
      "GP magnitude residuals fit:\n",
      "    Fit result:           b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "    intrinsic_dispersion      0.072 ± 0.012\n",
      "    gp_kernel_amplitude       0.110 ± 0.042\n",
      "    gp_length_scale           3.471 ± 2.467\n",
      "    offset                    -0.029 ± 0.071\n",
      "    covariate_slope_0         -0.007 ± 0.070\n",
      "    Fit NMAD                  0.071 mag\n",
      "    Fit std                   0.098 mag\n",
      "Calculating SALT2 magnitude residuals...\n",
      "SALT2 magnitude residuals fit: \n",
      "    ref_mag: -10.448\n",
      "    alpha:   0.142\n",
      "    beta:    2.677\n",
      "    σ_int:   0.138\n",
      "    RMS:     0.156\n",
      "    NMAD:    0.109\n",
      "    WRMS:    0.156\n",
      "Loading host galaxy data...\n",
      "Loading peculiar SNe Ia data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "a = ManifoldTwinsAnalysis()\n",
    "# a.settings['differential_evolution_use_salt_x1'] = True\n",
    "a.run_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the spectra at maximum light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of maximum light models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33f1d730f604fc58ed934f35d6e6341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=101, description='idx', max=202), Checkbox(value=False, description='sav…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_same_night(idx, save=False)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_same_night(idx, save=False):\n",
    "    night_flux = a.flux[a.target_map == idx]\n",
    "    phases = a.salt_phases[a.target_map == idx]\n",
    "    model = a.differential_evolution_result['maximum_flux'][idx]\n",
    "    model_err = a.differential_evolution_result['maximum_fluxerr'][idx]\n",
    "    \n",
    "    # Plot the original spectrum and the model.\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    for flux, phase in zip(night_flux, phases):\n",
    "        a.plot_flux(ax1, flux, label='Data (%.2f days)' % phase)\n",
    "    a.plot_flux(ax1, model, model_err, c='k', ls='--', label='Model (0 days)')\n",
    "    ax1.legend()\n",
    "    ax1.set_title(a.targets[idx])\n",
    "    fig1.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        a.savefig('time_evolution_model_%s.pdf' % a.targets[idx], fig1)\n",
    "    \n",
    "    # Plot the difference of each spectrum relative to maximum light.\n",
    "    phase_slope = a.differential_evolution_result['phase_slope']\n",
    "    phase_quadratic = a.differential_evolution_result['phase_quadratic']\n",
    "    gray_offsets = a.differential_evolution_result['gray_offsets'][a.target_map == idx]\n",
    "    model_diffs = a.differential_evolution_result['model_diffs'][a.target_map == idx]\n",
    "    \n",
    "    fig2, ax2 = plt.subplots()\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        ax2.plot(a.wave, -2.5*np.log10(flux / model), label='Data (%.2f days)' % phase, c='C%d' % i)\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        ax2.plot(a.wave, model_diff, label='Model (%.2f days)' % phase, c='C%d' % i, ls='--')\n",
    "    ax2.legend(ncol=2, loc=1)\n",
    "    ax2.set_title(a.targets[idx])\n",
    "    ax2.set_xlabel(a.settings['spectrum_plot_xlabel'])\n",
    "    ax2.set_ylabel('Difference from maximum light (mag)')\n",
    "    \n",
    "    if save:\n",
    "        a.savefig('time_evolution_difference_%s.pdf' % a.targets[idx], fig2)\n",
    "\n",
    "    # Plot the interpolation residuals\n",
    "    fig3, ax3 = plt.subplots()\n",
    "    for i, (flux, phase, gray_offset, model_diff) in enumerate(zip(night_flux, phases, gray_offsets, model_diffs)):\n",
    "        ax3.plot(a.wave, -2.5*np.log10(flux / model) - model_diff, label='Residuals (%.2f days)' % phase, c='C%d' % i)\n",
    "    ax3.legend()\n",
    "    ax3.set_title(a.targets[idx])\n",
    "    ax3.set_xlabel(a.settings['spectrum_plot_xlabel'])\n",
    "    ax3.set_ylabel('Interpolation residuals (mag)')\n",
    "    \n",
    "    if save:\n",
    "        a.savefig('time_evolution_residuals_%s.pdf' % a.targets[idx], fig3)\n",
    "\n",
    "    return fig1, fig2, fig3\n",
    "    \n",
    "from ipywidgets import interact\n",
    "interact(plot_same_night, idx=(0, len(a.targets)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd15245a62641838501d18c7ddef1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8587a0da8c81447892d625e1ce6b83f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738206fb23eb400fbba30516e5773ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07388bf9d9324ef199d3762d00eba355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b211844a2540a4bc10379e997eb94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8a19e3e360461c9ed4d40ddda7ad51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_targets = ['PTF13ayw', 'SN2004gc']\n",
    "for plot_target in plot_targets:\n",
    "    target_names = np.array([i.name for i in a.targets])\n",
    "    plot_idx = np.where(target_names == plot_target)[0][0]\n",
    "\n",
    "    plot_same_night(plot_idx, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential time evolution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6d3b0df1d9448fb3554c4b5b09606d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = a.settings['colormap']\n",
    "\n",
    "phase_slope = a.differential_evolution_result['phase_slope']\n",
    "phase_quadratic = a.differential_evolution_result['phase_quadratic']\n",
    "phase_slope_x1 = a.differential_evolution_result['phase_slope_x1']\n",
    "phase_quadratic_x1 = a.differential_evolution_result['phase_quadratic_x1']\n",
    "\n",
    "def evaluate_phase_difference(phase, x1=0):\n",
    "    phase_difference = (\n",
    "        phase_slope * phase\n",
    "        + phase_quadratic * phase * phase\n",
    "        + phase_slope_x1 * x1 * phase\n",
    "        + phase_quadratic_x1 * x1 * phase * phase\n",
    "    )\n",
    "    \n",
    "    return phase_difference\n",
    "\n",
    "# Look at change in phase for the same x1\n",
    "max_phase = a.settings['phase_range']\n",
    "min_phase = -a.settings['phase_range']\n",
    "num_phases = 10\n",
    "phases = np.linspace(min_phase, max_phase, num_phases)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=a.settings['spectrum_plot_figsize'])\n",
    "\n",
    "norm = plt.Normalize(vmin=min_phase, vmax=max_phase)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array(phases)\n",
    "\n",
    "for phase in phases:\n",
    "    ax.plot(a.wave, evaluate_phase_difference(phase), c=cmap(norm(phase)), zorder=np.abs(phase))\n",
    "\n",
    "fig.colorbar(sm, label='Phase (days)')\n",
    "\n",
    "ax.set_xlabel(a.settings['spectrum_plot_xlabel'])\n",
    "ax.set_ylabel('Brightness relative to $t_{max,B}$ (mag)')\n",
    "ax.invert_yaxis()\n",
    "a.savefig('time_evolution_phase_difference.pdf', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALT2 x1 difference plots. This only makes sense if we are including x1 in the\n",
    "# differential evolution model, so these are blank with the default settings.\n",
    "# I only make them if x1 was actually used.\n",
    "\n",
    "def plot_x1_difference(phase):\n",
    "    # Look at change in phase for the same x1\n",
    "    min_x1 = -2\n",
    "    max_x1 = 2\n",
    "    num_x1s = 10\n",
    "    x1s = np.linspace(min_x1, max_x1, num_x1s)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=a.settings['spectrum_plot_figsize'])\n",
    "    norm = plt.Normalize(vmin=min_x1, vmax=max_x1)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array(x1s)\n",
    "\n",
    "    for x1 in x1s:\n",
    "        diff = evaluate_phase_difference(phase, x1) - evaluate_phase_difference(phase, 0)\n",
    "        ax.plot(a.wave, diff, c=cmap(norm(x1)))\n",
    "\n",
    "    fig.colorbar(sm, label='SALT2 $x_1$')\n",
    "\n",
    "    ax.set_xlabel(a.settings['spectrum_plot_xlabel'])\n",
    "    ax.set_ylabel('Difference relative to $x_1=0$ (mag)')\n",
    "    ax.set_title('Difference in interpolation at %+d days' % phase)\n",
    "    ax.set_ylim(0.4, -0.4)\n",
    "    a.savefig('time_evolution_x1_difference_phase_%d.pdf' % phase, fig)\n",
    "\n",
    "if a.settings['differential_evolution_use_salt_x1']:\n",
    "    for phase in [-5, -3, -1, 1, 3, 5]:\n",
    "        plot_x1_difference(phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gray dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray dispersion scale: 0.0292 mag\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a24aa3aa5e42d5910f32c25bd675bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if the gray dispersion is phase dependent. This should not be the\n",
    "# case if the model is working properly.\n",
    "gray_scale = a.differential_evolution_result['gray_dispersion_scale']\n",
    "print(f\"Gray dispersion scale: {gray_scale:.4f} mag\")\n",
    "\n",
    "plt.figure()\n",
    "gray_offsets = a.differential_evolution_result['gray_offsets']\n",
    "plt.scatter(a.salt_phases, gray_offsets, s=3, label='Individual spectra')\n",
    "math.plot_binned_mean(a.salt_phases, gray_offsets, c='C2', lw=2, label='Binned mean')\n",
    "math.plot_binned_rms(a.salt_phases, gray_offsets, c='C3', lw=2, label='Binned RMS')\n",
    "plt.xlabel('SALT2 Phase (days)')\n",
    "plt.ylabel('Gray offset (mag)')\n",
    "plt.legend()\n",
    "a.savefig('gray_offset_vs_phase.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential evolution uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da190a3afb9841398c7aeff0c7543336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1b1b29ac31400e82b3218b89751404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefs = a.differential_evolution_result['phase_dispersion_coefficients']\n",
    "num_phase_coefficients = len(coefs)\n",
    "\n",
    "phase_range = a.settings['phase_range']\n",
    "\n",
    "def evaluate_phase_dispersion(phase):\n",
    "    phase_scale = np.abs((num_phase_coefficients / 2) * (phase / phase_range))\n",
    "    full_bins = int(np.floor(phase_scale))\n",
    "    remainder = phase_scale - full_bins\n",
    "\n",
    "    phase_coefficients = np.zeros(num_phase_coefficients)\n",
    "\n",
    "    for j in range(full_bins + 1):\n",
    "        if j == full_bins:\n",
    "            weight = remainder\n",
    "        else:\n",
    "            weight = 1\n",
    "            \n",
    "        if weight == 0:\n",
    "            break\n",
    "            \n",
    "        if phase > 0:\n",
    "            phase_bin = num_phase_coefficients // 2 + j\n",
    "        else:\n",
    "            phase_bin = num_phase_coefficients // 2 - 1 - j\n",
    "            \n",
    "        phase_coefficients[phase_bin] = weight\n",
    "        \n",
    "    fractional_dispersion = phase_coefficients.dot(coefs)\n",
    "    \n",
    "    # Convert to magnitudes\n",
    "    mag_dispersion = frac_to_mag(fractional_dispersion)\n",
    "\n",
    "    return mag_dispersion\n",
    "\n",
    "phases = np.linspace(-phase_range, phase_range, 1 + num_phase_coefficients)\n",
    "\n",
    "eval_coefs = np.array([evaluate_phase_dispersion(phase) for phase in phases])\n",
    "\n",
    "# Uncertainties for different wavelengths\n",
    "plt.figure()\n",
    "num_wave = 10\n",
    "for i in range(num_wave):\n",
    "    min_wave = a.wave[0]\n",
    "    max_wave = a.wave[-1]\n",
    "    wave_range = max_wave - min_wave\n",
    "    target_wave = min_wave + wave_range * i / (num_wave - 1)\n",
    "    idx = np.argmin(np.abs(a.wave - target_wave))\n",
    "    use_wave = a.wave[idx]\n",
    "    color = plt.cm.rainbow((use_wave - min_wave) / wave_range)\n",
    "    plt.plot(phases, eval_coefs[:, idx], label='%d $\\AA$' % use_wave, c=color)\n",
    "    \n",
    "plt.xlim(-5.2, 5.2)\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Model uncertainty (mag)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "a.savefig('time_evolution_uncertainty_phase.pdf')\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(phases)):\n",
    "    plt.plot(a.wave, eval_coefs[i], label='%.2f days' % phases[i])\n",
    "plt.legend()\n",
    "plt.xlabel(a.settings['spectrum_plot_xlabel'])\n",
    "plt.ylabel('Model uncertainty (mag)')\n",
    "plt.tight_layout()\n",
    "a.savefig('time_evolution_uncertainty_wavelength.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183199c81ebf4c35bb371f44144c411a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1006e33093649989245fc52967f42ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d28efd01da446c8c3db604ec03eefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14cb9c73bae4b7dae18d63f54b48027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_flux = a.differential_evolution_result['maximum_flux']\n",
    "max_fluxerr = a.differential_evolution_result['maximum_fluxerr']\n",
    "\n",
    "max_magerr = frac_to_mag(max_fluxerr / max_flux)\n",
    "\n",
    "rbtl_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "\n",
    "def plot_uncertainties(show_rbtl=False):\n",
    "    plt.figure(figsize=a.settings['spectrum_plot_figsize'])\n",
    "    offset = 29\n",
    "    \n",
    "    # Make sure that we include the worst offender.\n",
    "    max_loc = np.argmax(np.sum(max_magerr**2, axis=1))\n",
    "    start = max_loc % offset\n",
    "    \n",
    "    for idx in range(start, len(a.targets), offset):\n",
    "        plt.plot(a.wave, max_magerr[idx], label=a.targets[idx].name)\n",
    "    plt.legend(ncol=2)\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    \n",
    "    if show_rbtl:\n",
    "        plt.plot(a.wave, rbtl_dispersion, label='SN intrinsic dispersion', c='k', lw=2, ls='--')\n",
    "        plt.ylabel('Dispersion (mag)')\n",
    "        filename = 'maximum_uncertainty_rbtl.pdf'\n",
    "    else:\n",
    "        plt.ylabel('Uncertainty on $f_{max}$ (mag)')\n",
    "        filename = 'maximum_uncertainty_norbtl.pdf'\n",
    "        \n",
    "    plt.legend(ncol=2)\n",
    "    plt.tight_layout()\n",
    "    a.savefig(filename)\n",
    "\n",
    "plot_uncertainties(False)\n",
    "plot_uncertainties(True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=a.settings['spectrum_plot_figsize'])\n",
    "for idx in range(len(a.targets)):\n",
    "    if idx == 0:\n",
    "        label = 'Individual uncertainties of $f_{max}$'\n",
    "    else:\n",
    "        label = ''\n",
    "    plt.plot(a.wave, max_magerr[idx], label=label, alpha=0.02, c='C0')\n",
    "plt.plot(a.wave, rbtl_dispersion, label='Supernova intrinsic dispersion', lw=2, ls='--', c='k')\n",
    "plt.plot(a.wave, np.median(max_magerr, axis=0), label='Median uncertainty on $f_{max}$', lw=2, ls='--', c='C0')\n",
    "plt.plot(a.wave, np.max(max_magerr, axis=0), label='Maximum uncertainty on $f_{max}$', c='C1')\n",
    "plt.legend()\n",
    "plt.ylabel('Dispersion (mag)')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.tight_layout()\n",
    "a.savefig('maximum_uncertainty_median.pdf')\n",
    "\n",
    "plt.figure(figsize=a.settings['spectrum_plot_figsize'])\n",
    "plt.plot(a.wave, rbtl_dispersion, label='SN intrinsic dispersion', lw=2, ls='--', c='k')\n",
    "plt.plot(a.wave, np.min(max_magerr, axis=0), label='Minimum $\\sigma_{f,max}$')\n",
    "for percentile in (25, 50, 75):\n",
    "    plt.plot(a.wave, np.percentile(max_magerr, percentile, axis=0), label='%dth percentile $\\sigma_{f,max}$' % percentile)\n",
    "plt.plot(a.wave, np.max(max_magerr, axis=0), label='Maximum $\\sigma_{f,max}$')\n",
    "plt.legend(ncol=2)\n",
    "plt.ylabel('Dispersion (mag)')\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.tight_layout()\n",
    "a.savefig('maximum_uncertainty_percentile.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution to the total interpolation uncertainty from various sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3f9f92d38b4168bdf74aac69738763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c871533b46846c181730e8f09beb37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a71ed046a94c4ebd87648b93f0ccd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation of 0.0-1.5 days:\n",
      "                 Raw: std=0.052, NMAD=0.039\n",
      "               Phase: std=0.045, NMAD=0.034\n",
      "          Phase + x1: std=0.045, NMAD=0.034\n",
      "        Phase + gray: std=0.029, NMAD=0.014\n",
      "   Phase + x1 + gray: std=0.029, NMAD=0.014\n",
      "\n",
      "Interpolation of 1.5-2.5 days:\n",
      "                 Raw: std=0.115, NMAD=0.087\n",
      "               Phase: std=0.080, NMAD=0.066\n",
      "          Phase + x1: std=0.080, NMAD=0.066\n",
      "        Phase + gray: std=0.060, NMAD=0.042\n",
      "   Phase + x1 + gray: std=0.060, NMAD=0.042\n",
      "\n",
      "Interpolation of 2.5-5.5 days:\n",
      "                 Raw: std=0.178, NMAD=0.126\n",
      "               Phase: std=0.094, NMAD=0.075\n",
      "          Phase + x1: std=0.094, NMAD=0.075\n",
      "        Phase + gray: std=0.081, NMAD=0.055\n",
      "   Phase + x1 + gray: std=0.081, NMAD=0.055\n",
      "\n",
      "Interpolation of 5.5-10.5 days:\n",
      "                 Raw: std=0.272, NMAD=0.209\n",
      "               Phase: std=0.127, NMAD=0.098\n",
      "          Phase + x1: std=0.127, NMAD=0.098\n",
      "        Phase + gray: std=0.108, NMAD=0.076\n",
      "   Phase + x1 + gray: std=0.108, NMAD=0.076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "diffs = []\n",
    "phases_1 = []\n",
    "phases_2 = []\n",
    "x1s = []\n",
    "gray_differences = []\n",
    "\n",
    "gray_offsets = a.differential_evolution_result['gray_offsets']\n",
    "\n",
    "center_specs = a.spectra[a.center_mask]\n",
    "center_gray_offsets = gray_offsets[a.center_mask]\n",
    "for target_idx in range(len(a.targets)):\n",
    "    near_max_spec = center_specs[target_idx]\n",
    "    \n",
    "    target_mask = (a.target_map == target_idx) & (~a.center_mask)\n",
    "    target_specs = a.spectra[target_mask]\n",
    "    target_gray_offsets = gray_offsets[target_mask]\n",
    "    \n",
    "    for spec_idx, target_spec in enumerate(target_specs):\n",
    "        phase_diff = target_spec.phase - near_max_spec.phase\n",
    "        # if np.abs(phase_diff) < 1:\n",
    "            # continue\n",
    "\n",
    "        targets.append(a.targets[target_idx])\n",
    "        diff = -2.5*np.log10(target_spec.flux / near_max_spec.flux)\n",
    "        diffs.append(diff)\n",
    "        phases_1.append(near_max_spec.phase)\n",
    "        phases_2.append(target_spec.phase)\n",
    "        x1s.append(a.salt_x1[target_idx])\n",
    "        \n",
    "        gray_differences.append(target_gray_offsets[spec_idx] - center_gray_offsets[target_idx])\n",
    "\n",
    "targets = np.array(targets)\n",
    "diffs = np.array(diffs)\n",
    "phases_1 = np.array(phases_1)\n",
    "phases_2 = np.array(phases_2)\n",
    "x1s = np.array(x1s)\n",
    "gray_differences = np.array(gray_differences)\n",
    "\n",
    "phase_diffs = phases_2 - phases_1\n",
    "\n",
    "def plot_diffs(diffs, model_subtracted=False):\n",
    "    sel_mask = np.zeros(len(diffs), dtype=bool)\n",
    "    sel_mask[4::50] = True\n",
    "    sel_mask[np.abs(phase_diffs) < 1] = False\n",
    "    \n",
    "    plt.figure(figsize=a.settings['spectrum_plot_figsize'])\n",
    "    \n",
    "    for use_idx in np.where(sel_mask)[0]:\n",
    "        target = targets[use_idx]\n",
    "        phase_1 = phases_1[use_idx]\n",
    "        phase_2 = phases_2[use_idx]\n",
    "        \n",
    "        if phase_1 > phase_2:\n",
    "            phase_1, phase_2 = phase_2, phase_1\n",
    "        \n",
    "        label = '%s, %.1f to %.1f days' % (target, phase_1, phase_2)\n",
    "        \n",
    "        plt.plot(a.wave, diffs[use_idx] / phase_diffs[use_idx], alpha=0.5, label=label)\n",
    "        \n",
    "    plt.legend(ncol=2)\n",
    "\n",
    "    plt.ylim(-0.25, 0.25)\n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    if model_subtracted:\n",
    "        plt.ylabel('$\\Delta m / \\Delta t$ (data) - $\\Delta m / \\Delta t$ (model) (mag/day)')\n",
    "    else:\n",
    "        plt.ylabel('$\\Delta m / \\Delta t$ (data) (mag/day)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_diffs(diffs)\n",
    "a.savefig('raw_phase_difference.pdf')\n",
    "\n",
    "residuals_no_x1 = []\n",
    "residuals_x1 = []\n",
    "for diff, phase_1, phase_2, x1 in zip(diffs, phases_1, phases_2, x1s):\n",
    "    model_no_x1 = evaluate_phase_difference(phase_2, 0) - evaluate_phase_difference(phase_1, 0)\n",
    "    model_x1 = evaluate_phase_difference(phase_2, x1) - evaluate_phase_difference(phase_1, x1)\n",
    "    residuals_no_x1.append(diff - model_no_x1)\n",
    "    residuals_x1.append(diff - model_x1)\n",
    "    \n",
    "residuals_no_x1 = np.array(residuals_no_x1)\n",
    "residuals_x1 = np.array(residuals_x1)\n",
    "\n",
    "residuals_gray_no_x1 = residuals_no_x1 - gray_differences[:, None]\n",
    "residuals_gray_x1 = residuals_x1 - gray_differences[:, None]\n",
    "\n",
    "plot_diffs(residuals_gray_no_x1, True)\n",
    "a.savefig('corr_phase_difference_no_x1.pdf')\n",
    "\n",
    "plot_diffs(residuals_gray_x1, True)\n",
    "a.savefig('corr_phase_difference_x1.pdf')\n",
    "\n",
    "def print_interpolation_residuals(min_days, max_days):\n",
    "    cut = (np.abs(phase_diffs) < max_days) & (np.abs(phase_diffs) > min_days)\n",
    "\n",
    "    def do_print(label, vals, cut):\n",
    "        cut_vals = vals[cut]\n",
    "        print('%20s: std=%.3f, NMAD=%.3f' % (label, math.rms(cut_vals), math.nmad(cut_vals)))\n",
    "\n",
    "    print(\"Interpolation of %.1f-%.1f days:\" % (min_days, max_days))\n",
    "    do_print('Raw', diffs, cut)    \n",
    "    do_print('Phase', residuals_no_x1, cut)    \n",
    "    do_print('Phase + x1', residuals_x1, cut)    \n",
    "    do_print('Phase + gray', residuals_gray_no_x1, cut)    \n",
    "    do_print('Phase + x1 + gray', residuals_gray_x1, cut)    \n",
    "    print(\"\")\n",
    "    \n",
    "print_interpolation_residuals(0., 1.5)\n",
    "print_interpolation_residuals(1.5, 2.5)\n",
    "print_interpolation_residuals(2.5, 5.5)\n",
    "print_interpolation_residuals(5.5, 10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of the interpolation uncertainty is common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b7c65c8c78453ab31b32872ae9a8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31411134c122438aa5957ad3d53215fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median fraction of variance explained: 0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/kyle/packages/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "phases = np.linspace(-5, 5, 101.)\n",
    "\n",
    "common_dispersion = []\n",
    "residual_dispersion = []\n",
    "\n",
    "for phase in phases:\n",
    "    common_dispersion.append(np.sqrt(np.mean(evaluate_phase_difference(phase)**2)))\n",
    "    residual_dispersion.append(np.sqrt(np.mean(evaluate_phase_dispersion(phase)**2)))\n",
    "    \n",
    "common_dispersion = np.array(common_dispersion)\n",
    "residual_dispersion = np.array(residual_dispersion)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(phases, common_dispersion, label='Common variation (explained)')\n",
    "plt.plot(phases, residual_dispersion, label='Residual variation (unexplained)')\n",
    "plt.legend()\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Overall dispersion (mag)')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(phases, residual_dispersion**2 / (residual_dispersion**2 + common_dispersion**2), label='Fraction of dispersion remaining')\n",
    "plt.legend()\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Overall dispersion (mag)')\n",
    "\n",
    "print(\"Median fraction of variance explained: %.3f\" % (1 - np.nanmedian(residual_dispersion**2 / (residual_dispersion**2 + common_dispersion**2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading between the lines plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show spectra before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3a222ba1094f4b971080f5c916516a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6aed1af2f1b4955a34f76efcdd7a0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741b0c310ccb40ac86a7e0a965000061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90340643eb8b442494f36d5bbf79f1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "a.plot_flux(ax, a.maximum_flux[a.uncertainty_mask], lw=1, label='Individual spectra')\n",
    "ax.legend()\n",
    "a.savefig('spectra_at_maximum.pdf', fig)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "a.plot_flux(ax, a.scale_flux[a.uncertainty_mask], lw=1., label='Individual spectra')\n",
    "a.plot_flux(ax, a.mean_flux, c='k', label='Mean spectrum')\n",
    "ax.legend()\n",
    "a.savefig('scale_spectra.pdf', fig)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "a.plot_flux(ax, a.mean_flux, a.mean_flux * a.rbtl_result['fractional_dispersion'], label='Mean spectrum', uncertainty_label='Supernova intrinsic dispersion')\n",
    "ax.legend()\n",
    "a.savefig('scale_spectra_model.pdf', fig)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "intrinsic_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "ax.plot(a.wave, intrinsic_dispersion, c='k', lw=2, label='Supernova intrinsic dispersion')\n",
    "ax.legend()\n",
    "ax.set_xlabel(a.settings['spectrum_plot_xlabel'])\n",
    "ax.set_ylabel(a.settings['spectrum_plot_ylabel'])\n",
    "ax.set_ylim(0, None)\n",
    "a.savefig('rbtl_intrinsic_dispersion.pdf', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08098fafe1543388e3e2d304b22b5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combined version\n",
    "\n",
    "# figsize = (a.settings['spectrum_plot_figsize'][0], a.settings['spectrum_plot_figsize'][1] * 3 - 1.5)\n",
    "figsize = (6, 9)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=figsize, sharex=True)\n",
    "\n",
    "a.plot_flux(ax1, a.maximum_flux, lw=1, label='Individual spectra', alpha=0.3)\n",
    "ax1.set_title('Original spectra')\n",
    "ax1.set_xlabel(None)\n",
    "\n",
    "a.plot_flux(ax2, a.scale_flux[a.uncertainty_mask], lw=1., label='Individual spectra', alpha=0.3)\n",
    "a.plot_flux(ax2, a.mean_flux, c='k', lw=2, ls='--', label='Mean spectrum')\n",
    "ax2.set_title('Dereddened spectra')\n",
    "ax2.set_xlabel(None)\n",
    "\n",
    "intrinsic_dispersion = frac_to_mag(a.rbtl_result['fractional_dispersion'])\n",
    "ax3.plot(a.wave, intrinsic_dispersion, c='k', lw=2)\n",
    "ax3.set_xlabel(a.settings['spectrum_plot_xlabel'])\n",
    "ax3.set_ylabel('Intrinsic dispersion (mag)')\n",
    "ax3.set_title('Recovered intrinsic dispersion')\n",
    "ax3.set_ylim(0, None)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/rbtl_spectra_combined.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests of dust variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57f0396f3bc412cb9c77b807987c22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean offset:  -0.1395\n",
      "Sigma offset: 0.0161\n"
     ]
    }
   ],
   "source": [
    "import extinction\n",
    "plt.figure()\n",
    "ref_extinction = extinction.fitzpatrick99(a.wave, 0.5 * 2.8, 2.8)\n",
    "new_extinction = extinction.fitzpatrick99(a.wave, 0.5 * 3.1, 3.1)\n",
    "plt.plot(a.wave, ref_extinction - new_extinction)\n",
    "\n",
    "print(\"Mean offset:  %.4f\" % np.mean(ref_extinction - new_extinction))\n",
    "print(\"Sigma offset: %.4f\" % np.std(ref_extinction - new_extinction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3be13fc9d44aea91ee0639aa739fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean offset:  -0.1398\n",
      "Sigma offset: 0.0121\n"
     ]
    }
   ],
   "source": [
    "import extinction\n",
    "plt.figure()\n",
    "ref_extinction = extinction.ccm89(a.wave, 0.5 * 2.8, 2.8)\n",
    "new_extinction = extinction.ccm89(a.wave, 0.5 * 3.1, 3.1)\n",
    "plt.plot(a.wave, ref_extinction - new_extinction)\n",
    "\n",
    "print(\"Mean offset:  %.4f\" % np.mean(ref_extinction - new_extinction))\n",
    "print(\"Sigma offset: %.4f\" % np.std(ref_extinction - new_extinction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold learning plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9000917296473482078ac4159439e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cb8a694723447e91b4dc86836c1071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44246ac91852445297dc8973de1c9f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.scatter(a.embedding[:, 2], a.uncertainty_mask, label='Component 3')\n",
    "a.savefig('embedding_components_12.pdf')\n",
    "a.scatter(a.embedding[:, 1], a.uncertainty_mask, axis_1=0, axis_2=2, label='Component 2')\n",
    "a.savefig('embedding_components_13.pdf')\n",
    "a.scatter(a.embedding[:, 0], a.uncertainty_mask, axis_1=1, axis_2=2, label='Component 1')\n",
    "a.savefig('embedding_components_23.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e44dd7afdb46edbf5c09ff9788b948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: the total variance isn't defined for Isomap. The variances of the transfomed components\n",
    "# do map onto the variance of real components though. We provide a very rough estimate of the\n",
    "# measurement variance for comparison purposes... not sure how much it can be trusted...\n",
    "\n",
    "num_show = 10\n",
    "\n",
    "# Do an initial embedding with as many components as possible to get the full variance.\n",
    "embedding = a.generate_embedding(num_components=None)\n",
    "variances = np.var(embedding[a.uncertainty_mask], axis=0)\n",
    "\n",
    "ref_var = np.sum(variances[:10])\n",
    "\n",
    "plot_ref = variances[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(num_show), variances[:num_show] / plot_ref, label='Contributed variance of each component')\n",
    "plt.ylim(0, None)\n",
    "plt.xlabel('Component number')\n",
    "plt.ylabel('Relative variance explained')\n",
    "plt.xticks(np.arange(num_show), np.arange(num_show) + 1)\n",
    "\n",
    "a.savefig('isomap_component_variance.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twin reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e839abad9734d5aa1283e27a562b49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To Best 10% of twinness</th>\n",
       "      <th>To 10-20%</th>\n",
       "      <th>To 20-50%</th>\n",
       "      <th>To Worst 50% of twinness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>From Best 10% of twinness</th>\n",
       "      <td>0.735887</td>\n",
       "      <td>0.234543</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 10-20%</th>\n",
       "      <td>0.197581</td>\n",
       "      <td>0.438844</td>\n",
       "      <td>0.363575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 20-50%</th>\n",
       "      <td>0.020614</td>\n",
       "      <td>0.104862</td>\n",
       "      <td>0.711405</td>\n",
       "      <td>0.163119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From Worst 50% of twinness</th>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.902124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            To Best 10% of twinness  To 10-20%  To 20-50%  \\\n",
       "From Best 10% of twinness                  0.735887   0.234543   0.029570   \n",
       "From 10-20%                                0.197581   0.438844   0.363575   \n",
       "From 20-50%                                0.020614   0.104862   0.711405   \n",
       "From Worst 50% of twinness                 0.000941   0.002420   0.094515   \n",
       "\n",
       "                            To Worst 50% of twinness  \n",
       "From Best 10% of twinness                   0.000000  \n",
       "From 10-20%                                 0.000000  \n",
       "From 20-50%                                 0.163119  \n",
       "From Worst 50% of twinness                  0.902124  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5820debdbb7d46e485854bab43dc3737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To Best 10% of twinness</th>\n",
       "      <th>To 10-20%</th>\n",
       "      <th>To 20-50%</th>\n",
       "      <th>To Worst 50% of twinness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>From Best 10% of twinness</th>\n",
       "      <td>0.735887</td>\n",
       "      <td>0.234543</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 10-20%</th>\n",
       "      <td>0.197581</td>\n",
       "      <td>0.438844</td>\n",
       "      <td>0.363575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 20-50%</th>\n",
       "      <td>0.020614</td>\n",
       "      <td>0.104862</td>\n",
       "      <td>0.711405</td>\n",
       "      <td>0.163119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From Worst 50% of twinness</th>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.902124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            To Best 10% of twinness  To 10-20%  To 20-50%  \\\n",
       "From Best 10% of twinness                  0.735887   0.234543   0.029570   \n",
       "From 10-20%                                0.197581   0.438844   0.363575   \n",
       "From 20-50%                                0.020614   0.104862   0.711405   \n",
       "From Worst 50% of twinness                 0.000941   0.002420   0.094515   \n",
       "\n",
       "                            To Worst 50% of twinness  \n",
       "From Best 10% of twinness                   0.000000  \n",
       "From 10-20%                                 0.000000  \n",
       "From 20-50%                                 0.163119  \n",
       "From Worst 50% of twinness                  0.902124  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7436d2a1319946a5926e3438a396cfb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To Best 10% of twinness</th>\n",
       "      <th>To 10-20%</th>\n",
       "      <th>To 20-50%</th>\n",
       "      <th>To Worst 50% of twinness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>From Best 10% of twinness</th>\n",
       "      <td>0.735887</td>\n",
       "      <td>0.234543</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 10-20%</th>\n",
       "      <td>0.197581</td>\n",
       "      <td>0.438844</td>\n",
       "      <td>0.363575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 20-50%</th>\n",
       "      <td>0.020614</td>\n",
       "      <td>0.104862</td>\n",
       "      <td>0.711405</td>\n",
       "      <td>0.163119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From Worst 50% of twinness</th>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.902124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            To Best 10% of twinness  To 10-20%  To 20-50%  \\\n",
       "From Best 10% of twinness                  0.735887   0.234543   0.029570   \n",
       "From 10-20%                                0.197581   0.438844   0.363575   \n",
       "From 20-50%                                0.020614   0.104862   0.711405   \n",
       "From Worst 50% of twinness                 0.000941   0.002420   0.094515   \n",
       "\n",
       "                            To Worst 50% of twinness  \n",
       "From Best 10% of twinness                   0.000000  \n",
       "From 10-20%                                 0.000000  \n",
       "From 20-50%                                 0.163119  \n",
       "From Worst 50% of twinness                  0.902124  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb2aa62165d44caa7260cebbea41e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To Best 10% of twinness</th>\n",
       "      <th>To 10-20%</th>\n",
       "      <th>To 20-50%</th>\n",
       "      <th>To Worst 50% of twinness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>From Best 10% of twinness</th>\n",
       "      <td>0.735887</td>\n",
       "      <td>0.234543</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 10-20%</th>\n",
       "      <td>0.197581</td>\n",
       "      <td>0.438844</td>\n",
       "      <td>0.363575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 20-50%</th>\n",
       "      <td>0.020614</td>\n",
       "      <td>0.104862</td>\n",
       "      <td>0.711405</td>\n",
       "      <td>0.163119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From Worst 50% of twinness</th>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.902124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            To Best 10% of twinness  To 10-20%  To 20-50%  \\\n",
       "From Best 10% of twinness                  0.735887   0.234543   0.029570   \n",
       "From 10-20%                                0.197581   0.438844   0.363575   \n",
       "From 20-50%                                0.020614   0.104862   0.711405   \n",
       "From Worst 50% of twinness                 0.000941   0.002420   0.094515   \n",
       "\n",
       "                            To Worst 50% of twinness  \n",
       "From Best 10% of twinness                   0.000000  \n",
       "From 10-20%                                 0.000000  \n",
       "From 20-50%                                 0.163119  \n",
       "From Worst 50% of twinness                  0.902124  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60470279f4e941be89b6ffec16615480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>To Best 10% of twinness</th>\n",
       "      <th>To 10-20%</th>\n",
       "      <th>To 20-50%</th>\n",
       "      <th>To Worst 50% of twinness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>From Best 10% of twinness</th>\n",
       "      <td>0.735887</td>\n",
       "      <td>0.234543</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 10-20%</th>\n",
       "      <td>0.197581</td>\n",
       "      <td>0.438844</td>\n",
       "      <td>0.363575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From 20-50%</th>\n",
       "      <td>0.020614</td>\n",
       "      <td>0.104862</td>\n",
       "      <td>0.711405</td>\n",
       "      <td>0.163119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>From Worst 50% of twinness</th>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>0.902124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            To Best 10% of twinness  To 10-20%  To 20-50%  \\\n",
       "From Best 10% of twinness                  0.735887   0.234543   0.029570   \n",
       "From 10-20%                                0.197581   0.438844   0.363575   \n",
       "From 20-50%                                0.020614   0.104862   0.711405   \n",
       "From Worst 50% of twinness                 0.000941   0.002420   0.094515   \n",
       "\n",
       "                            To Worst 50% of twinness  \n",
       "From Best 10% of twinness                   0.000000  \n",
       "From 10-20%                                 0.000000  \n",
       "From 20-50%                                 0.163119  \n",
       "From Worst 50% of twinness                  0.902124  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42abdd47808548aca62317437b8c6fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot where twins and non-twins end up for different number of components.\n",
    "# We also make a summary plot.\n",
    "confused_fraction = []\n",
    "\n",
    "plot_components = np.arange(1, 6)\n",
    "for num_components in plot_components:\n",
    "    embedding = a.generate_embedding(num_components=num_components)\n",
    "    leakage_matrix = a.plot_twin_distances()\n",
    "    if num_components == 1:\n",
    "        title = '1 Component + Color'\n",
    "    else:\n",
    "        title = '%d Components + Color' % num_components\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Recovered twinness percentile in the embedded space')\n",
    "    plt.tight_layout()\n",
    "    a.savefig('twins_recovery_%d_components.pdf' % num_components)\n",
    "\n",
    "    confused_fraction.append(leakage_matrix[3, 0] + leakage_matrix[3, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(len(confused_fraction)) + 1, confused_fraction)\n",
    "plt.xticks(plot_components, plot_components)\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlabel('Number of components (in addition to color)')\n",
    "plt.ylabel('Fraction of non-twins confused as twins')\n",
    "plt.tight_layout()\n",
    "a.savefig('twins_confusion.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS  20%: 0.1056963799599485\n",
      "NMAD 20%: 0.09630002268221892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6afa41a48343faadc8044b38435bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot_twin_pairings(a.uncertainty_mask & a.redshift_color_mask & a.train_mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot steps through component values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def plot_steps(ax, component, num_steps=20):\n",
    "    mask = a.uncertainty_mask\n",
    "\n",
    "    use_embedding = a.embedding[mask, component]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "\n",
    "    bin_edges = np.percentile(use_embedding, np.linspace(0, 100, num_steps + 1))\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2.\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=a.settings['colormap'], norm=plt.Normalize(vmin=bin_centers[0], vmax=bin_centers[-1]))\n",
    "    sm._A = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "\n",
    "        # Make the extreme values of components get plotted on top if everything overlaps.\n",
    "        zorder = np.abs(mean_val)\n",
    "\n",
    "        a.plot_flux(ax, step_flux, c=sm.to_rgba(mean_val), zorder=zorder)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='2.5%', pad=0.1)\n",
    "    fig.colorbar(sm, cax=cax, orientation='vertical', label='Component Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8583cce69d24e148d828d533fade4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# All plots combined\n",
    "fig, axes = plt.subplots(3, 1, figsize=(a.settings['spectrum_plot_figsize'][0], a.settings['spectrum_plot_figsize'][1] * 3 - 1.5), sharex=True)\n",
    "\n",
    "for component, ax in enumerate(axes):\n",
    "    plot_steps(ax, component)\n",
    "\n",
    "    if component != 2:\n",
    "        ax.set_xlabel(None)\n",
    "\n",
    "    ax.set_title('Component %d' % (component + 1))\n",
    "\n",
    "a.savefig('component_steps_combined.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4340bc73035d4aee83353fb906bba82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version for talks\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 7), sharex=True)\n",
    "\n",
    "for component, ax in enumerate(axes):\n",
    "    plot_steps(ax, component)\n",
    "\n",
    "    if component != 2:\n",
    "        ax.set_xlabel(None)\n",
    "\n",
    "    ax.set_ylabel('Flux')\n",
    "\n",
    "a.savefig('component_steps_combined.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fc41dbaa7c47c6a8efaee52ae84688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433e559b65a74001b65a3c3aa42b49b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa69bbda5f44f77a4fa9ce921e82377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Single plots\n",
    "for component in range(a.settings['isomap_num_components']):\n",
    "    fig, ax = plt.subplots(figsize=a.settings['spectrum_plot_figsize'])\n",
    "    ax.set_title(f'Component {component+1}')\n",
    "    plot_steps(ax, component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Comparison to original twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hannah_list = np.genfromtxt('./data/fakhouri_atmax_list.txt', dtype='str')\n",
    "twins_mask = np.array([i.name in hannah_list for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ManifoldTwinsAnalysis' object has no attribute 'good_mag_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-1eb403dafdde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_twin_pairings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./figures/twin_dispersion.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/supernova/snfactory/manifold_twins/analysis/manifold_twins.py\u001b[0m in \u001b[0;36mplot_twin_pairings\u001b[0;34m(self, mask, show_nmad)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgood_mag_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0muse_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfractional_differences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ManifoldTwinsAnalysis' object has no attribute 'good_mag_mask'"
     ]
    }
   ],
   "source": [
    "a.plot_twin_pairings()\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/twin_dispersion.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twins that are poor brightness matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "mask = a.good_mag_mask\n",
    "\n",
    "raw_spec_dists = pdist(a.iso_diffs[mask])\n",
    "spec_dists = squareform(raw_spec_dists)\n",
    "mag_diffs = squareform(pdist(a.mags[mask][:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mask = spec_dists < np.percentile(raw_spec_dists, 20)\n",
    "plt.figure()\n",
    "plt.hist(mag_diffs[dist_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1, idx2 = np.where(dist_mask & (mag_diffs > 0.35))\n",
    "idx_mask = idx1 < idx2\n",
    "idx1 = idx1[idx_mask]\n",
    "idx2 = idx2[idx_mask]\n",
    "\n",
    "def print_pairs(vals):\n",
    "    for val_name, val in vals.items():\n",
    "        print(\"%13s_1\" % val_name, \"%13s_2\" % val_name, end='')\n",
    "    print('')\n",
    "        \n",
    "    for i, j in zip(idx1, idx2):\n",
    "        for val_name, val in vals.items():\n",
    "            try:\n",
    "                print('%15.3f' % val[mask][i], '%15.3f' % val[mask][j], end='')\n",
    "            except TypeError:\n",
    "                print('%15s' % val[mask][i], '%15s' % val[mask][j], end='')\n",
    "        print('')\n",
    "\n",
    "print_pairs({\n",
    "    'target': a.targets,\n",
    "    'redshift': a.redshifts,\n",
    "    'color': a.colors,\n",
    "    'mag': a.mags,\n",
    "    'salt_mag': a.salt_hr,\n",
    "    'embedding[0]': a.embedding[:, 0],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision to Branch classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_blondin_plot()\n",
    "plt.savefig('./figures/branch_classification.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot(axis_1=0, axis_2=2)\n",
    "plt.gca().get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot(axis_1=1, axis_2=2)\n",
    "plt.gca().get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.do_component_blondin_plot()\n",
    "plt.gca().get_legend().remove()\n",
    "plt.savefig('./figures/branch_labels_isomap.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation of Core Normal SNe Ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = a.get_indicators() \n",
    "\n",
    "s1 = indicators[\"EWSiII6355\"]\n",
    "s2 = indicators[\"EWSiII5972\"]\n",
    "\n",
    "component = 0\n",
    "\n",
    "core_normal_cut = (s2 < 30) & (s1 > 70) & (s1 < 100) & ~np.isnan(a.embedding[:, component])\n",
    "\n",
    "cut_flux = a.scale_flux[core_normal_cut]\n",
    "cut_coord = a.embedding[core_normal_cut][:, component]\n",
    "\n",
    "sort_flux = cut_flux[np.argsort(cut_coord)]\n",
    "sort_coord = cut_coord[np.argsort(cut_coord)]\n",
    "\n",
    "num_bins = 5\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=np.percentile(cut_coord, 100 / num_bins / 2), vmax=np.percentile(cut_coord, 100 * (1 - 1. / num_bins / 2))))\n",
    "sm._A = []\n",
    "\n",
    "def plot_spec(bin_idx):\n",
    "    min_idx = int(len(sort_coord) / num_bins * bin_idx)\n",
    "    max_idx = int(len(sort_coord) / num_bins * (bin_idx + 1))\n",
    "    bin_flux = sort_flux[min_idx:max_idx]\n",
    "    \n",
    "    f = np.median(bin_flux, axis=0)\n",
    "    \n",
    "    mean_val = np.mean(sort_coord[min_idx:max_idx])\n",
    "    \n",
    "    plt.plot(a.wave, f * spectrum_plot_scale, c=sm.to_rgba(mean_val), zorder=np.abs(mean_val))\n",
    "    \n",
    "plt.figure(figsize=spectrum_plot_figsize)\n",
    "for i in range(num_bins):\n",
    "    plot_spec(i)\n",
    "plt.colorbar(sm, label='Value of Component %d' % (component + 1))\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/core_normal_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering other indicators of intrinsic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an array to hold everything\n",
    "all_indicators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral features\n",
    "indicators = a.spectral_indicators\n",
    "\n",
    "name_map = {\n",
    "    'EWCaIIHK': 'pEW Ca II HK',\n",
    "    'EWSiII4000': 'pEW Si II 4000',#$\\AA$',\n",
    "    'EWSiII5972': 'pEW Si II 5972',#$\\AA$',\n",
    "    'EWSiII6355': 'pEW Si II 6355',#$\\AA$',\n",
    "    'vCaIIHK': 'Velocity Ca II HK',\n",
    "    'vSiII6355': 'Velocity Si II 6355',#$\\AA$',\n",
    "    'lamCaIIHK': 'Lambda Ca II HK',\n",
    "    'lamSiII6355': 'Lambda Si II 6355',#$\\AA$',\n",
    "}\n",
    "\n",
    "for key in indicators.keys():\n",
    "    values = indicators[key]\n",
    "\n",
    "    if key[:3] == 'lam':\n",
    "        continue\n",
    "        \n",
    "    if key[:1] == 'v':\n",
    "        # Use km/s and make everything positive.\n",
    "        values = values / -1000\n",
    "\n",
    "    all_indicators.append((name_map[key], values, a.uncertainty_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SALT2 X1\n",
    "all_indicators.append(('SALT2 $x_1$', a.salt_x1, a.salt_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Sugar parameters\n",
    "pickle_data =  open('./data/sugar_parameters.pkl').read().replace('\\r\\n', '\\n').encode('latin1')\n",
    "sugar_data = pickle.loads(pickle_data, encoding='latin1')\n",
    "\n",
    "sugar_rows = []\n",
    "for target in a.targets:\n",
    "    try:\n",
    "        row = sugar_data[target.name.encode('latin1')]\n",
    "        sugar_rows.append([row['q1'], row['q2'], row['q3']])\n",
    "    except KeyError:\n",
    "        sugar_rows.append([np.nan] * 3)\n",
    "\n",
    "sugar_embedding = np.array(sugar_rows, dtype=float)\n",
    "sugar_mask = ~np.isnan(sugar_embedding[:, 0])\n",
    "\n",
    "for component in range(3):\n",
    "    all_indicators.append(('SUGAR Component %d\\n(Leget et al. 2019)' % (component + 1), sugar_embedding[:, component], sugar_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nordin colors\n",
    "nordin_bands = {\n",
    "    'uNi': (3300., 3510.),\n",
    "    'uTi': (3510., 3660.),\n",
    "    'uSi': (3660., 3760.),\n",
    "    'uCa': (3750., 3860.),\n",
    "}\n",
    "\n",
    "for label, (wave_min, wave_max) in nordin_bands.items():\n",
    "    cut = (a.wave > wave_min) & (a.wave < wave_max)\n",
    "    \n",
    "    values = -2.5*np.log10(np.sum(a.scale_flux[:, cut], axis=1) / np.sum(a.mean_flux[cut]))\n",
    "    \n",
    "    all_indicators.append(('U-band variation—%s\\n(Nordin et al. 2018)' % label, values, a.uncertainty_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNEMO parameters\n",
    "import pandas as pd\n",
    "snemo_data = pd.read_csv('./data/snemo_salt_coefficients_snf.csv').set_index('SN')\n",
    "\n",
    "nan_row = snemo_data.iloc[0].copy()\n",
    "nan_row[:] = np.nan\n",
    "\n",
    "snemo_rows = []\n",
    "for target in a.targets:\n",
    "    try:\n",
    "        row = snemo_data.loc[target.name]\n",
    "        snemo_rows.append(row)\n",
    "    except KeyError:\n",
    "        snemo_rows.append(nan_row)\n",
    "\n",
    "snemo_embedding = pd.DataFrame(snemo_rows)\n",
    "snemo_mask = ~np.isnan(snemo_embedding['salt_c'])\n",
    "snemo_labels = snemo_data.columns\n",
    "\n",
    "# SNEMO 2\n",
    "all_indicators.append(('SNEMO2 Component 1\\n(Saunders et al. 2018)', snemo_embedding['snemo2_c1'], snemo_mask))\n",
    "\n",
    "# SNEMO 7\n",
    "for component in range(6):\n",
    "    all_indicators.append(('SNEMO7 Component %d' % (component + 1), snemo_embedding[f'snemo7_c{component+1}'], snemo_mask))\n",
    "    \n",
    "# SNEMO 15\n",
    "# for component in range(14):\n",
    "    # all_indicators.append(('SNEMO15 Component %d' % (component + 1), snemo_embedding[f'snemo15_c{component+1}'], snemo_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def find_rotation(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def to_min(x):\n",
    "        diff = values - a.embedding.dot(x[1:]) - x[0]\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0, 0, 0, 0])\n",
    "\n",
    "    rotation = res.x[1:] / np.sqrt(np.sum(res.x[1:]**2))\n",
    "    best_guess = a.embedding.dot(res.x[1:]) + res.x[0]\n",
    "    \n",
    "    return rotation, best_guess\n",
    "\n",
    "def find_rotation_quadratic(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def evaluate(x):\n",
    "        e = a.embedding.T\n",
    "        \n",
    "        model = (\n",
    "            x[0]\n",
    "            + e[0] * x[1]\n",
    "            + e[1] * x[2]\n",
    "            + e[2] * x[3]\n",
    "            + e[0] * e[0] * x[4]\n",
    "            + e[1] * e[1] * x[5]\n",
    "            + e[2] * e[2] * x[6]\n",
    "            + e[0] * e[1] * x[7]\n",
    "            + e[0] * e[2] * x[8]\n",
    "            + e[1] * e[2] * x[9]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def to_min(x):\n",
    "        model = evaluate(x)\n",
    "        diff = values - model\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0] * 10)\n",
    "\n",
    "    best_guess = evaluate(res.x)\n",
    "    \n",
    "    return res.x, best_guess\n",
    "\n",
    "names = []\n",
    "data = []\n",
    "\n",
    "for name, values, mask in all_indicators[::-1]:\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    \n",
    "    params_quadratic, best_guess_quadratic = find_rotation_quadratic(values, mask)\n",
    "    corrcoef_quadratic = np.corrcoef(best_guess_quadratic[mask], values[mask])[0, 1]\n",
    "    \n",
    "    names.append(name)\n",
    "    data.append(np.hstack([rotation, corrcoef, corrcoef_quadratic]))\n",
    "\n",
    "    # print(f'{name} & {rotation[0]:.2f} & {rotation[1]:.2f} & {rotation[2]:.2f} & {corrcoef:.2f}')\n",
    "    \n",
    "data = np.array(data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5.0, 8))\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-1, vmax=1))\n",
    "sm._A = []\n",
    "\n",
    "def do_plot(ax, ax_data, xlabels, ylabels=None):\n",
    "    im = ax.imshow(ax_data, interpolation='nearest', cmap=cmap, vmin=-1, vmax=1)\n",
    "    ax.set(\n",
    "        xticks=np.arange(ax_data.shape[1]),\n",
    "        yticks=np.arange(ax_data.shape[0]),\n",
    "        xticklabels=xlabels,\n",
    "    )\n",
    "\n",
    "    if ylabels is not None:\n",
    "        ax.set_yticklabels(ylabels)\n",
    "    else:\n",
    "        ax.tick_params(axis='y', which='both', left=False, right=False)\n",
    "\n",
    "    ax.set_xlim(-0.5, ax_data.shape[1] - 0.5)\n",
    "    ax.set_ylim(-0.5, ax_data.shape[0] - 0.5)\n",
    "\n",
    "    # Ticks on top\n",
    "    ax.get_xaxis().set_ticks_position('top')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=70, ha=\"left\", va='center',\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.65\n",
    "    for i in range(ax_data.shape[0]):\n",
    "        for j in range(ax_data.shape[1]):\n",
    "            ax.text(j, i, format(ax_data[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if np.abs(ax_data[i, j]) > thresh else \"black\")\n",
    "            \n",
    "do_plot(axes[0], data[:, :3], ['Component 1 Rotation', 'Component 2 Rotation', 'Component 3 Rotation'], names)\n",
    "do_plot(axes[1], data[:, 3:], ['Linear Transformation\\nPearson Correlation', 'Quadratic Transformation\\nPearson Correlation'])\n",
    "\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes('right', size='30%', pad=0.23)\n",
    "fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/indicators_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "        \n",
    "    min_val = np.min([values[mask], best_guess[mask]])\n",
    "    max_val = np.max([values[mask], best_guess[mask]])\n",
    "    val_range = max_val - min_val\n",
    "    \n",
    "    plt.figure(figsize=(4, 3.8))\n",
    "    plt.scatter(best_guess[mask], values[mask])\n",
    "    \n",
    "    plt.text(min_val + 0.*val_range, max_val - 0.02*val_range, \"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    print(\"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    \n",
    "    plt.plot([min_val - val_range, min_val + val_range], [min_val - val_range, min_val + val_range], c='k', ls='--')\n",
    "\n",
    "    plt.xlabel('Transformation of the Isomap latent space')\n",
    "    \n",
    "    plt.ylabel(name)\n",
    "    # plt.ylabel(\"Original measurement\")\n",
    "    # plt.title(name)\n",
    "    \n",
    "    plt.xlim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.ylim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1), quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "        \n",
    "    min_val = np.min([values[mask], best_guess[mask]])\n",
    "    max_val = np.max([values[mask], best_guess[mask]])\n",
    "    val_range = max_val - min_val\n",
    "    \n",
    "    plt.figure(figsize=(2.5, 2.7))\n",
    "    plt.scatter(best_guess[mask], values[mask], s=10)\n",
    "    \n",
    "    plt.text(min_val + 0.*val_range, max_val - 0.04*val_range, \"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    print(\"$\\\\rho = %.2f$\" % np.corrcoef([values[mask], best_guess[mask]])[0, 1])\n",
    "    \n",
    "    plt.plot([min_val - val_range, min_val + val_range], [min_val - val_range, min_val + val_range], c='k', ls='--')\n",
    "\n",
    "    # plt.xlabel('Transformation of the Isomap latent space')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # plt.ylabel(name)\n",
    "    # plt.ylabel(\"Original measurement\")\n",
    "    plt.title(name.split('\\n')[0])\n",
    "    \n",
    "    plt.xlim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.ylim(min_val-0.05*val_range, max_val+0.05*val_range)\n",
    "    plt.tight_layout()\n",
    "\n",
    "interact(plot_component, idx=(0, len(data) - 1), quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    plot_component(i, quadratic=True)\n",
    "    plt.savefig('./figures/rotation_%d.png' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('SALT2 $x_1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.text(-0.3, 0.6, 'hi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component(6, quadratic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.uncertainty_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(best_guess[mask], values[mask])\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Transformation of the Isomap latent space')\n",
    "    plt.ylabel(name)\n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for AAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.salt_x1, mask=a.salt_mask, label='SALT2 $x_1$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Figure out what happened with SNBOSS38. Somehow the SALT2 fit is way off, but it doesn't fail the SALT2 fit cuts. Reject in manually for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[a.salt_mask, 1], a.salt_x1[a.salt_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (a.embedding[:, 0] > 2) & (a.embedding[:, 1] > 1) & (a.embedding[:, 1] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.where(mask)[0]:\n",
    "    print(a.targets[i], a.embedding[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.salt_mask[(a.salt_x1 > 1) & (a.embedding[:, 1] > 1)] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.salt_hr[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tt[2].fit_salt(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out what correlation coefficient we would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrcoef_linear = []\n",
    "all_corrcoef_quadratic = []\n",
    "\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    mask = a.interp_mask\n",
    "    values = np.random.normal(size=len(values))\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    all_corrcoef_linear.append(corrcoef)\n",
    "    \n",
    "    rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    all_corrcoef_quadratic.append(corrcoef)\n",
    "\n",
    "with open('./latex/correlation_simulation.tex', 'w') as f:\n",
    "    latex_command(f, 'correlationmeanlinear', '%.2f', np.mean(all_corrcoef_linear))\n",
    "    latex_command(f, 'correlationstdlinear', '%.2f', np.std(all_corrcoef_linear))\n",
    "    latex_command(f, 'correlationmeanquadratic', '%.2f', np.mean(all_corrcoef_quadratic))\n",
    "    latex_command(f, 'correlationstdquadratic', '%.2f', np.std(all_corrcoef_quadratic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot rotated spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_steps(idx, quadratic=False):\n",
    "    num_steps = 10\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & a.interp_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    use_embedding = best_guess[mask]\n",
    "    use_flux = a.scale_flux[mask]\n",
    "    \n",
    "    min_embedding = np.percentile(use_embedding, 5)\n",
    "    max_embedding = np.percentile(use_embedding, 95)\n",
    "    \n",
    "    bin_edges = np.linspace(min_embedding, max_embedding, num_steps+1)\n",
    "    \n",
    "    bin_edges[0] = -1e20\n",
    "    bin_edges[-1] = 1e20\n",
    "    \n",
    "    plt.figure(figsize=spectrum_plot_figsize)\n",
    "    \n",
    "    cmap = plot_cmap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=min_embedding, vmax=max_embedding))\n",
    "    sm._A = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        step_mask = (use_embedding >= bin_edges[step]) & (use_embedding < bin_edges[step+1])\n",
    "        step_embedding = use_embedding[step_mask]\n",
    "\n",
    "        mean_val = np.mean(step_embedding)\n",
    "        step_flux = np.median(use_flux[step_mask], axis=0)\n",
    "        \n",
    "        plt.plot(a.wave, step_flux * spectrum_plot_scale, c=sm.to_rgba(mean_val))\n",
    "        \n",
    "    plt.colorbar(sm, label='Rotated Isomap vSi II 6355$\\AA$\\nEstimate ($10^3$ km/s)')\n",
    "    \n",
    "    plt.xlabel('Wavelength ($\\AA$)')\n",
    "    plt.ylabel(spectrum_plot_ylabel)\n",
    "    plt.ylim(0, None)\n",
    "    plt.title(name)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "interact(plot_steps, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear combinations of SUGAR components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indicators.append(('Isomap Component 1', a.embedding[:, 0], a.interp_mask))\n",
    "all_indicators.append(('Isomap Component 2', a.embedding[:, 1], a.interp_mask))\n",
    "all_indicators.append(('Isomap Component 3', a.embedding[:, 2], a.interp_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def find_rotation(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def to_min(x):\n",
    "        diff = values - sugar_embedding.dot(x[1:]) - x[0]\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0, 0, 0, 0])\n",
    "\n",
    "    rotation = res.x[1:] / np.sqrt(np.sum(res.x[1:]**2))\n",
    "    best_guess = sugar_embedding.dot(res.x[1:]) + res.x[0]\n",
    "    \n",
    "    return rotation, best_guess\n",
    "\n",
    "def find_rotation_quadratic(values, mask):\n",
    "    # Find the best predictor of an indicator\n",
    "    def evaluate(x):\n",
    "        e = sugar_embedding.T\n",
    "        \n",
    "        model = (\n",
    "            x[0]\n",
    "            + e[0] * x[1]\n",
    "            + e[1] * x[2]\n",
    "            + e[2] * x[3]\n",
    "            + e[0] * e[0] * x[4]\n",
    "            + e[1] * e[1] * x[5]\n",
    "            + e[2] * e[2] * x[6]\n",
    "            + e[0] * e[1] * x[7]\n",
    "            + e[0] * e[2] * x[8]\n",
    "            + e[1] * e[2] * x[9]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def to_min(x):\n",
    "        model = evaluate(x)\n",
    "        diff = values - model\n",
    "        return np.sum(diff[mask]**2)\n",
    "\n",
    "    res = minimize(to_min, [0] * 10)\n",
    "\n",
    "    best_guess = evaluate(res.x)\n",
    "    \n",
    "    return res.x, best_guess\n",
    "\n",
    "names = []\n",
    "data = []\n",
    "\n",
    "for name, values, mask in all_indicators[::-1]:\n",
    "    mask = mask & sugar_mask\n",
    "    \n",
    "    rotation, best_guess = find_rotation(values, mask)\n",
    "    corrcoef = np.corrcoef(best_guess[mask], values[mask])[0, 1]\n",
    "    \n",
    "    params_quadratic, best_guess_quadratic = find_rotation_quadratic(values, mask)\n",
    "    corrcoef_quadratic = np.corrcoef(best_guess_quadratic[mask], values[mask])[0, 1]\n",
    "    \n",
    "    names.append(name)\n",
    "    data.append(np.hstack([rotation, corrcoef, corrcoef_quadratic]))\n",
    "\n",
    "    # print(f'{name} & {rotation[0]:.2f} & {rotation[1]:.2f} & {rotation[2]:.2f} & {corrcoef:.2f}')\n",
    "    \n",
    "data = np.array(data)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(5.0, 8))\n",
    "plt.subplots_adjust(wspace=0., hspace=0.)\n",
    "\n",
    "cmap = plot_cmap\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-1, vmax=1))\n",
    "sm._A = []\n",
    "\n",
    "def do_plot(ax, ax_data, xlabels, ylabels=None):\n",
    "    im = ax.imshow(ax_data, interpolation='nearest', cmap=cmap, vmin=-1, vmax=1)\n",
    "    ax.set(\n",
    "        xticks=np.arange(ax_data.shape[1]),\n",
    "        yticks=np.arange(ax_data.shape[0]),\n",
    "        xticklabels=xlabels,\n",
    "    )\n",
    "\n",
    "    if ylabels is not None:\n",
    "        ax.set_yticklabels(ylabels)\n",
    "    else:\n",
    "        ax.tick_params(axis='y', which='both', left=False, right=False)\n",
    "\n",
    "    ax.set_xlim(-0.5, ax_data.shape[1] - 0.5)\n",
    "    ax.set_ylim(-0.5, ax_data.shape[0] - 0.5)\n",
    "\n",
    "    # Ticks on top\n",
    "    ax.get_xaxis().set_ticks_position('top')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=70, ha=\"left\", va='center',\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = 0.65\n",
    "    for i in range(ax_data.shape[0]):\n",
    "        for j in range(ax_data.shape[1]):\n",
    "            ax.text(j, i, format(ax_data[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if np.abs(ax_data[i, j]) > thresh else \"black\")\n",
    "            \n",
    "do_plot(axes[0], data[:, :3], ['Component 1 Rotation', 'Component 2 Rotation', 'Component 3 Rotation'], names)\n",
    "do_plot(axes[1], data[:, 3:5], ['Linear Rotation\\nPearson Correlation', 'Quadratic Rotation\\nPearson Correlation'])\n",
    "\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes('right', size='30%', pad=0.23)\n",
    "fig.colorbar(sm, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/indicators_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_component(idx, quadratic=False):\n",
    "    name, values, mask = all_indicators[idx]\n",
    "\n",
    "    mask = mask & sugar_mask\n",
    "    if quadratic:\n",
    "        rotation, best_guess = find_rotation_quadratic(values, mask)\n",
    "    else:\n",
    "        rotation, best_guess = find_rotation(values, mask)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(best_guess[mask], values[mask], c=a.colors[mask], vmin=-0.2, vmax=0.2)\n",
    "    plt.title(name)\n",
    "    \n",
    "interact(plot_component, idx=(0, len(data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.rbtl_colors, vmin=-0.3, vmax=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(-0.54*sugar_embedding[:, 0] + 0.84 * sugar_embedding[:, 2], a.salt_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[:, 1], a.colors, c=a.embedding[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "m = (a.redshifts > 0.02) & (a.redshift_errs < 0.004) & (a.uncertainty_mask)\n",
    "plt.scatter(a.rbtl_colors[m] - np.median(a.rbtl_colors[m]), a.corr_mags[m])\n",
    "\n",
    "np.std(a.corr_mags[m & (a.rbtl_colors - np.median(a.rbtl_colors) > 0.5) & a.train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, np.sqrt(np.mean(utils.frac_to_mag((a.maximum_fluxerr / a.maximum_flux)[a.uncertainty_mask])**2, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, 1/a.rbtl_result['fractional_dispersion']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.embedding[a.uncertainty_mask, 0], a.embedding[a.uncertainty_mask, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.spectra[(a.trans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(0.548, -0.830)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((a.rbtl_colors - np.median(a.rbtl_colors)) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.targets[dists < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(a.wave, a.scale_flux[dists < 0.1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.sum((a.embedding - a.embedding[m & (a.corr_mags > 0.5)])**2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 91T/91bg labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_labels = {\n",
    "    # Scalzo++ 2014\n",
    "    \"SNF20070528-003\": \"91T-like\",\n",
    "    \"SNF20070803-005\": \"91T-like\",\n",
    "    \"SNF20070825-001\": \"91T-like\",\n",
    "    \"SNF20070912-000\": \"91T-like\",\n",
    "    \"SNF20080522-000\": \"91T-like\",\n",
    "    \"SNF20080723-012\": \"91T-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"SNF20080805-007\": \"91T-like\",\n",
    "    \"LSQ12cyz\": \"91T-like\",\n",
    "    \"LSQ12fhe\": \"91T-like\",\n",
    "    \"PTF11bju\": \"91T-like\",\n",
    "    \"PTF11mkx\": \"91T-like\",\n",
    "    \"LSQ12cfx\": \"91bg-like\",\n",
    "    \n",
    "    # Discussion between Kyle and Greg:\n",
    "    \"SNNGC2691\": \"91T-like\",\n",
    "    \n",
    "    # Maguire++ 2011\n",
    "    \"PTF10ops\": \"91bg-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"PTF11bkf\": \"91bg-like\",\n",
    "    \"PTF11kjn\": \"91bg-like\",\n",
    "    \"PTF11okh\": \"91bg-like\",\n",
    "    \"PTF11pra\": \"91bg-like\",\n",
    "    \"PTF12dwm\": \"91bg-like\",\n",
    "    \"SN2005bl\": \"91bg-like\",\n",
    "    \"SN2005dh\": \"91bg-like\",\n",
    "    \"SN2005dm\": \"91bg-like\",\n",
    "    \"SN2007ba\": \"91bg-like\",\n",
    "    \"SN2009hs\": \"91bg-like\",\n",
    "    \"SNNGC6430\": \"91bg-like\",\n",
    "    \"SN2005cc\": \"02cx-like\",\n",
    "    \n",
    "    # Foley++ 2013\n",
    "    \"SN2011ay\": \"02cx-like\",\n",
    "    \"LSQ12fhs\": \"02cx-like\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.targets[a.embedding[:, 0] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "colors = []\n",
    "labels = []\n",
    "for idx, sn in enumerate(a.targets):\n",
    "    if not a.uncertainty_mask[idx]:\n",
    "        continue\n",
    "\n",
    "    label = outlier_labels.get(sn.name, 'Other')\n",
    "    if label == 'Other':\n",
    "        c = 'silver'\n",
    "    elif label == '91bg-like':\n",
    "        c = 'C0'\n",
    "    elif label == '91T-like':\n",
    "        c = 'C2'\n",
    "    elif label == '02cx-like':\n",
    "        c = 'C3'\n",
    "        \n",
    "    if c in colors:\n",
    "        plot_label = ''\n",
    "    else:\n",
    "        plot_label = label\n",
    "\n",
    "    colors.append(c)\n",
    "    \n",
    "    plt.scatter(a.embedding[idx, 0], a.embedding[idx, 1], label=plot_label, facecolors=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.targets[np.array([i.name == 'SNF20070825-001' for i in a.targets])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.plot_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_91t = np.array([outlier_labels.get(i.name, 'aa') == '91T-like' for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask_91t & a.uncertainty_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask_91t & a.redshift_color_mask & a.uncertainty_mask & a.train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.corr_mags, mask=a.good_mag_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.where((a.embedding[:, 0] > 4) & (a.embedding[:, 1] > -1.5))[0]:\n",
    "    target = a.targets[idx]\n",
    "    print(a.embedding[idx], target, outlier_labels.get(target.name, 'Other'), a.corr_mags[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALT2 comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SALT2 Hubble residuals\n",
    "a.calculate_salt_hubble_residuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(a.salt_colors, a.rbtl_colors, s=5)\n",
    "plt.xlabel('SALT2 Color ($c$)')\n",
    "plt.ylabel('RBTL Color ($A_V$)')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/salt2_color_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.scatter(a.rbtl_colors, a.uncertainty_mask, label='SALT $x_1$', vmin=-0.3, vmax=1.0)\n",
    "plt.savefig('./figures/salt2_x1_components_full.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALT2 outliers (Type Iax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iax_mask = (a.embedding[:, 0] > 4.) & (a.embedding[:, 1] < -3)\n",
    "a.targets[iax_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier spectra\n",
    "mask = (a.embedding[:, 0] > 4) & (a.embedding[:, 1] < -2)\n",
    "print(a.targets[mask])\n",
    "print(a.rbtl_colors[mask])\n",
    "print(a.redshifts[mask])\n",
    "print(a.rbtl_mags[mask])\n",
    "\n",
    "# Ref spectrum\n",
    "ref_target = 'SNF20070803-005'\n",
    "for idx2, target in enumerate(a.targets):\n",
    "    if target.name == ref_target:\n",
    "        break\n",
    "        \n",
    "# idx2 = np.where((a.embedding[:, 0] > 4.8) & (a.embedding[:, 1] < 2))[0][0]\n",
    "\n",
    "plt.figure()\n",
    "for i in np.where(mask)[0]:\n",
    "    plt.plot(a.wave, a.scale_flux[i] * spectrum_plot_scale, label=a.targets[i].name)\n",
    "    \n",
    "plt.plot(a.wave, a.scale_flux[idx2] * spectrum_plot_scale, c='k', ls='--', label=a.targets[idx2].name)\n",
    "print(a.embedding[idx2])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/type_iax_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.targets[(a.embedding[:, 1] > 4.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier spectra\n",
    "mask = (a.embedding[:, 0] < -4)\n",
    "print(a.targets[mask])\n",
    "print(a.colors[mask])\n",
    "print(a.redshifts[mask])\n",
    "print(a.mags[mask])\n",
    "\n",
    "# Ref spectrum\n",
    "# ref_target = 'SNF20070803-005'\n",
    "# for idx2, target in enumerate(a.targets):\n",
    "    # if target.name == ref_target:\n",
    "        # break\n",
    "        \n",
    "# idx2 = np.where((a.embedding[:, 0] > 4.8) & (a.embedding[:, 1] < 2))[0][0]\n",
    "\n",
    "plt.figure()\n",
    "for i in np.where(mask)[0]:\n",
    "    plt.plot(a.wave, a.scale_flux[i] * spectrum_plot_scale, label=a.targets[i].name)\n",
    "    \n",
    "# plt.plot(a.wave, a.scale_flux[idx2] * spectrum_plot_scale, c='k', ls='--', label=a.targets[idx2].name)\n",
    "print(a.embedding[idx2])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('./figures/type_iax_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same SALT2 parameters but not at the same location in the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_diff(x):\n",
    "    return (x - x[:, None])\n",
    "\n",
    "count = np.array([len(i.spectra) for i in a.targets])\n",
    "first_phase = np.array([i.spectra[0].phase for i in a.targets])\n",
    "mask = (count > 8) & (a.redshifts > 0.03) & (first_phase < -2)\n",
    "\n",
    "salt_x1_diff = outer_diff(a.salt_x1)\n",
    "salt_c_diff = outer_diff(a.salt_color)\n",
    "salt_diff = outer_diff(a.salt_x1)**2 + 100 * outer_diff(a.salt_color)**2\n",
    "manif_diff = outer_diff(a.embedding[:, 0])**2 + outer_diff(a.embedding[:, 1])**2 + outer_diff(a.embedding[:, 2])**2\n",
    "\n",
    "phase_diff = outer_diff(a.salt_phases[a.center_mask])\n",
    "\n",
    "np.fill_diagonal(salt_diff, np.nan)\n",
    "np.fill_diagonal(manif_diff, np.nan)\n",
    "\n",
    "salt_diff[~mask] = np.nan\n",
    "salt_diff[:, ~mask] = np.nan\n",
    "manif_diff[~mask] = np.nan\n",
    "manif_diff[:, ~mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = (salt_x1_diff > 0) & (salt_x1_diff < 0.2) & (np.abs(salt_c_diff) < 0.02) & (manif_diff > 30) & (np.abs(phase_diff) < 1.0)\n",
    "print(\"Num objects:  %s\" % np.sum(cut))\n",
    "salt_diff_idx = [i[2] for i in np.where(cut)]\n",
    "\n",
    "t1 = a.targets[salt_diff_idx[0]]\n",
    "t2 = a.targets[salt_diff_idx[1]]\n",
    "\n",
    "print(\"target 1:     %s\" % t1)\n",
    "print(\"target 2:     %s\" % t2)\n",
    "print(\"redshifts:    %.4f, %.4f\" % (a.redshifts[salt_diff_idx[0]], a.redshifts[salt_diff_idx[1]]))\n",
    "print(\"x_1 values:   %+.3f, %+.3f\" % (a.salt_x1[salt_diff_idx[0]], a.salt_x1[salt_diff_idx[1]]))\n",
    "print(\"c values:     %+.3f, %+.3f\" % (a.salt_color[salt_diff_idx[0]], a.salt_color[salt_diff_idx[1]]))\n",
    "print(\"mags:         %.3f, %.3f\" % (a.mags[salt_diff_idx[0]], a.mags[salt_diff_idx[1]]))\n",
    "print(\"salt HRs:     %.3f, %.3f\" % (a.salt_hr[salt_diff_idx[0]], a.salt_hr[salt_diff_idx[1]]))\n",
    "print(\"corr mags:    %.3f, %.3f\" % (a.corr_mags[salt_diff_idx[0]], a.corr_mags[salt_diff_idx[1]]))\n",
    "print(\"embedding 1:  %s\" % a.embedding[salt_diff_idx[0]])\n",
    "print(\"embedding 2:  %s\" % a.embedding[salt_diff_idx[1]])\n",
    "\n",
    "salt_comparision_mb_diff = np.abs(\n",
    "    a.salt_hr[salt_diff_idx[0]]\n",
    "    - a.salt_hr[salt_diff_idx[1]]\n",
    ")\n",
    "dm_1 = frac_to_mag(t1.salt_fit['x0_err'] / t1.salt_fit['x0'])\n",
    "dm_2 = frac_to_mag(t2.salt_fit['x0_err'] / t2.salt_fit['x0'])\n",
    "\n",
    "salt_comparison_mb_diff_err = np.sqrt(dm_1**2 + dm_2**2)\n",
    "print(\"mag_diff:     %.3f +/- %.3f\" % (salt_comparision_mb_diff, salt_comparison_mb_diff_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['U', 'B', 'V', 'R', 'I']\n",
    "\n",
    "band_colors = {\n",
    "    'U': 'C4',\n",
    "    'B': 'C0',\n",
    "    'V': 'C2',\n",
    "    'R': 'C3',\n",
    "    'I': 'C1',\n",
    "}\n",
    "\n",
    "gap = 1.\n",
    "\n",
    "def plot_lightcurve(target, marker='o', ls='--', mfc='none', label_bands=True):\n",
    "    photometry = target.get_photometry(bands, clip_filter=True)\n",
    "    \n",
    "    # Cut late phases\n",
    "    photometry = photometry[photometry['time'] < 30]\n",
    "        \n",
    "    ref_mag = target.salt_fit['fitted_model'].source_peakmag('snfb', 'ab')\n",
    "    \n",
    "    for offset, band in enumerate(bands):\n",
    "        band_photometry = photometry[photometry['band'] == 'snf%s' % band.lower()]\n",
    "        \n",
    "        if band == 'B':\n",
    "            label = target.name\n",
    "        else:\n",
    "            label = ''\n",
    "            \n",
    "        color = band_colors[band]\n",
    "        \n",
    "        phases = band_photometry['time']\n",
    "        mags = -2.5*np.log10(band_photometry['flux']) - ref_mag - (offset - 1) * gap\n",
    "        magerrs = band_photometry['magerr']\n",
    "    \n",
    "        plt.errorbar(phases, mags, magerrs, fmt='none', c=color)\n",
    "        plt.plot(phases, mags, label=label, marker=marker, c=color, mfc=mfc, ls=ls)\n",
    "        \n",
    "        if label_bands:\n",
    "            plt.text(phases[-1] + 2, mags[-1] + 0.2, '%s%+d' % (band, offset - 1), c=color)\n",
    "            plt.xlim(None, phases[-1] + 9)\n",
    "            \n",
    "def plot_salt_lightcurve(target, phase_min=-6, phase_max=50):\n",
    "    model = target.salt_fit['fitted_model']\n",
    "    phases = np.linspace(phase_min, phase_max, 200)\n",
    "    \n",
    "    # Compute the reference magnitude for B-band at max.\n",
    "    ref_mag = model.source_peakmag('snfb', 'ab')\n",
    "\n",
    "    # Plot each light curve\n",
    "    for offset, band in enumerate(bands):\n",
    "        mags = model.bandmag('snf%s' % band.lower(), 'ab', phases) - ref_mag - (offset - 1) * gap\n",
    "        plt.plot(phases, mags, c='k')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plot_lightcurve(t1, marker='^', ls='', mfc=None, label_bands=False)\n",
    "plot_lightcurve(t2, marker='o', ls='', mfc='none', label_bands=True)\n",
    "# plot_salt_lightcurve(t1)\n",
    "plt.legend()\n",
    "plt.xlabel('Phase (days)')\n",
    "plt.ylabel('Normalized magnitude + offset')\n",
    "plt.ylim(4.8, -2.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/same_salt_comparison.pdf')\n",
    "\n",
    "# plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "def plot_spec(idx):\n",
    "    spec = a.spectra[a.center_mask][idx]\n",
    "\n",
    "    ref_mag = spec.target.salt_fit['fitted_model'].source_peakmag('snfb', 'ab')\n",
    "    \n",
    "    label = '%s, %.2f days' % (spec.target.name, spec.phase)\n",
    "    \n",
    "    scale = 10**(+0.4*ref_mag)\n",
    "    \n",
    "    plt.plot(a.wave, spec.flux * scale * spectrum_plot_scale, label=label)\n",
    "\n",
    "plot_spec(salt_diff_idx[0])\n",
    "plot_spec(salt_diff_idx[1])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Restframe wavelength ($\\AA$)')\n",
    "plt.ylabel(spectrum_plot_ylabel)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/same_salt_spectra.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump details to latex\n",
    "with open('latex/salt_comparison.tex', 'w') as f:\n",
    "    latex_print(f, \"\")\n",
    "    t1 = a.targets[salt_diff_idx[0]]\n",
    "    t2 = a.targets[salt_diff_idx[1]]\n",
    "    latex_command(f, 'saltcompnamea', '%s', t1.name)\n",
    "    latex_command(f, 'saltcompnameb', '%s', t2.name)\n",
    "    latex_command(f, 'saltcompxonea', '%.3f $\\\\pm$ %.3f', (t1['salt2.X1'], t1['salt2.X1.err']))\n",
    "    latex_command(f, 'saltcompxoneb', '%.3f $\\\\pm$ %.3f', (t2['salt2.X1'], t2['salt2.X1.err']))\n",
    "    latex_command(f, 'saltcompca', '%.3f $\\\\pm$ %.3f', (t1['salt2.Color'], t1['salt2.Color.err']))\n",
    "    latex_command(f, 'saltcompcb', '%.3f $\\\\pm$ %.3f', (t2['salt2.Color'], t2['salt2.Color.err']))\n",
    "    latex_command(f, 'saltcompcoorda', '%.2f', a.embedding[salt_diff_idx[0], 0])\n",
    "    latex_command(f, 'saltcompcoordb', '%.2f', a.embedding[salt_diff_idx[1], 0])\n",
    "    latex_command(f, 'saltcompmagbdiff', '%.3f $\\\\pm$ %.3f', (salt_comparision_mb_diff, salt_comparison_mb_diff_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bunch of functions to make things easier.\n",
    "def latex_host_step(file, name, var, mags, mask):\n",
    "    step, step_err = analyze_host_variable(var, mags, mask, plot=False)\n",
    "    latex_command(file, name, '%.3f $\\\\pm$ %.3f', (np.abs(step), step_err))\n",
    "\n",
    "a.fit_gp(kind='salt_raw', verbose=False)\n",
    "salt_isomap_mags = a.corr_mags.copy()\n",
    "\n",
    "a.fit_gp(verbose=False)\n",
    "rbtl_isomap_mags = a.corr_mags.copy()\n",
    "\n",
    "with open('latex/commands.tex', 'w') as f:\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numdatasetsne', '%d', len(a.dataset.targets))\n",
    "    latex_command(f, 'numdatasetspectra', '%d', np.sum([len(i.spectra) for i in a.dataset.targets]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'nummanifoldsne', '%d', len(a.targets))\n",
    "    latex_command(f, 'nummanifoldspectra', '%d', len(a.spectra))\n",
    "    latex_command(f, 'numinterpsne', '%d', np.sum(a.interp_mask))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numsnftrain', '%d', np.sum([i.subset == 'training' for i in a.targets[a.interp_mask]]))\n",
    "    latex_command(f, 'numsnfvalid', '%d', np.sum([i.subset == 'validation' for i in a.targets[a.interp_mask]]))\n",
    "    latex_command(f, 'numsnfother', '%d', np.sum([i.subset not in ['training', 'validation'] for i in a.targets[a.interp_mask]]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'numsnredshift', '%d', np.sum(a.interp_mask & (a.redshift_errs >= 0.004)))\n",
    "    latex_command(f, 'numlowredshift', '%d', np.sum(a.interp_mask & (a.redshifts <= 0.02)))\n",
    "    latex_command(f, 'numhighav', '%d', np.sum(a.interp_mask & (a.colors - np.nanmedian(a.colors) >= 0.5)))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'nummagsne', '%d', np.sum(a.interp_mask & a.redshift_color_mask))\n",
    "    latex_command(f, 'nummagsnetrain', '%d', np.sum(a.good_mag_mask))\n",
    "    latex_command(f, 'nummagsnevalidation', '%d', np.sum(a.interp_mask & a.redshift_color_mask & ~a.good_mag_mask))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'saltparammb', '%.2f', a.salt_MB)\n",
    "    latex_command(f, 'saltparamalpha', '%.3f', a.salt_alpha)\n",
    "    latex_command(f, 'saltparambeta', '%.2f', a.salt_beta)\n",
    "    latex_command(f, 'saltparamsigmaint', '%.3f', a.salt_intrinsic_dispersion)\n",
    "    # latex_command(f, 'saltparamrms', '%.3f', np.std(a.salt_hr[a.good_salt_mask]))\n",
    "    latex_std(f, 'saltparamrms', a.salt_hr[a.good_salt_mask])\n",
    "    latex_nmad(f, 'saltparamnmad', a.salt_hr[a.good_salt_mask])\n",
    "    latex_command(f, 'saltparamwrms', '%.3f', a.salt_wrms)\n",
    "    latex_command(f, 'saltparammindisp', '%.2f', np.min(a.salt_hr_uncertainties[a.good_salt_mask]))\n",
    "    latex_command(f, 'saltparammaxdisp', '%.2f', np.max(a.salt_hr_uncertainties[a.good_salt_mask]))\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'rawrbtlmagstd', a.mags[a.good_mag_mask])\n",
    "    latex_nmad(f, 'rawrbtlmagnmad', a.mags[a.good_mag_mask])\n",
    "    # latex_print(f, \"\")\n",
    "    # latex_command(f, 'twinrbtlmagstd', '%.3f', a.twins_rms)\n",
    "    # latex_command(f, 'twinrbtlmagnmad', '%.3f', a.twins_nmad)\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'saltcomprawrbtlmagstd', a.mags[a.good_mag_mask & a.good_salt_mask])\n",
    "    latex_std(f, 'saltcompsaltmagstd', a.salt_hr[a.good_mag_mask & a.good_salt_mask])\n",
    "\n",
    "    a.fit_gp(verbose=False, kind='salt_raw')\n",
    "    gp_uncertainties = np.sqrt(np.diag(a.gp_hyperparameter_covariance))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'saltgpcolor', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[0], gp_uncertainties[0]))\n",
    "    latex_command(f, 'saltgpintdisp', '%.3f $\\\\pm$ %.3f', (a.gp_hyperparameters[1], gp_uncertainties[1]))\n",
    "    latex_command(f, 'saltgpkernelamp', '%.3f $\\\\pm$ %.3f', (np.abs(a.gp_hyperparameters[2]), gp_uncertainties[2]))\n",
    "    latex_command(f, 'saltgpkernellengthscale', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[3], gp_uncertainties[3]))\n",
    "    latex_std(f, 'saltgprms', a.corr_mags[a.good_salt_mask & a.interp_mask])\n",
    "    latex_std(f, 'saltgpcompsaltrms', a.salt_hr[a.good_salt_mask & a.interp_mask])\n",
    "\n",
    "    a.fit_gp(verbose=False)\n",
    "    gp_uncertainties = np.sqrt(np.diag(a.gp_hyperparameter_covariance))\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'rbtlgpcolor', '%.2f $\\\\pm$ %.2f', (a.fiducial_rv * (1 + a.gp_hyperparameters[0]), a.fiducial_rv * gp_uncertainties[0]))\n",
    "    latex_command(f, 'rbtlgpintdisp', '%.3f $\\\\pm$ %.3f', (a.gp_hyperparameters[1], gp_uncertainties[1]))\n",
    "    latex_command(f, 'rbtlgpkernelamp', '%.3f $\\\\pm$ %.3f', (np.abs(a.gp_hyperparameters[2]), gp_uncertainties[2]))\n",
    "    latex_command(f, 'rbtlgpkernellengthscale', '%.2f $\\\\pm$ %.2f', (a.gp_hyperparameters[3], gp_uncertainties[3]))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_std(f, 'rbtlgprms', a.corr_mags[a.good_mag_mask])\n",
    "    latex_command(f, 'rbtlgpnmad', '%.3f', math.nmad(a.corr_mags[a.good_mag_mask]))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    x1 = a.salt_hr[(a.embedding[:, 0] < 3) & a.good_salt_mask & a.interp_mask]\n",
    "    x2 = a.salt_hr[(a.embedding[:, 0] > 3) & a.good_salt_mask & a.interp_mask]\n",
    "    m1 = np.mean(x1)\n",
    "    m2 = np.mean(x2)\n",
    "    err1 = np.std(x1) / np.sqrt(len(x1))\n",
    "    err2 = np.std(x2) / np.sqrt(len(x2))\n",
    "    latex_command(f, 'saltisomapdiff', '%.3f $\\\\pm$ %.3f', (np.abs(m1-m2), np.sqrt(err1**2 + err2**2)))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_command(f, 'pecvelcontribution', '%.3f', np.sqrt(np.mean(a.get_peculiar_velocity_uncertainty()[a.good_mag_mask & a.good_salt_mask]**2)))\n",
    "\n",
    "    latex_print(f, \"\")\n",
    "    latex_host_step(f, 'lssfrsaltxifull', 'lssfr', a.salt_hr, a.good_salt_mask)\n",
    "    latex_host_step(f, 'gmasssaltxifull', 'gmass', a.salt_hr, a.good_salt_mask)\n",
    "    latex_host_step(f, 'lssfrsaltxicut', 'lssfr', a.salt_hr, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmasssaltxicut', 'gmass', a.salt_hr, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'lssfrsaltisomapcut', 'lssfr', salt_isomap_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmasssaltisomapcut', 'gmass', salt_isomap_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'lssfrrbtlisomapcut', 'lssfr', a.corr_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_host_step(f, 'gmassrbtlisomapcut', 'gmass', a.corr_mags, a.good_salt_mask & a.good_mag_mask)\n",
    "    latex_command(f, 'hostcutsnsnetrain', '%d', np.sum(a.good_mag_mask & a.good_salt_mask & a.host_mask))\n",
    "    latex_command(f, 'hostcutsnsnefull', '%d', np.sum(a.redshift_color_mask & a.interp_mask & a.good_salt_mask & a.host_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_labels = {\n",
    "    # Scalzo++ 2014\n",
    "    \"SNF20070528-003\": \"91T-like\",\n",
    "    \"SNF20070803-005\": \"91T-like\",\n",
    "    \"SNF20070825-001\": \"91T-like\",\n",
    "    \"SNF20070912-000\": \"91T-like\",\n",
    "    \"SNF20080522-000\": \"91T-like\",\n",
    "    \"SNF20080723-012\": \"91T-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"SNF20080805-007\": \"91T-like\",\n",
    "    \"LSQ12cyz\": \"91T-like\",\n",
    "    \"LSQ12fhe\": \"91T-like\",\n",
    "    \"PTF11bju\": \"91T-like\",\n",
    "    \"PTF11mkx\": \"91T-like\",\n",
    "    \"LSQ12cfx\": \"91bg-like\",\n",
    "    \n",
    "    # Discussion between Kyle and Greg:\n",
    "    \"SNNGC2691\": \"91T-like\",\n",
    "    \n",
    "    # Maguire++ 2011\n",
    "    \"PTF10ops\": \"91bg-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"PTF11bkf\": \"91bg-like\",\n",
    "    \"PTF11kjn\": \"91bg-like\",\n",
    "    \"PTF11okh\": \"91bg-like\",\n",
    "    \"PTF11pra\": \"91bg-like\",\n",
    "    \"PTF12dwm\": \"91bg-like\",\n",
    "    \"SN2005bl\": \"91bg-like\",\n",
    "    \"SN2005dh\": \"91bg-like\",\n",
    "    \"SN2005dm\": \"91bg-like\",\n",
    "    \"SN2007ba\": \"91bg-like\",\n",
    "    \"SN2009hs\": \"91bg-like\",\n",
    "    \"SNNGC6430\": \"91bg-like\",\n",
    "    \"SN2005cc\": \"02cx-like\",\n",
    "    \n",
    "    # Foley++ 2013\n",
    "    \"SN2011ay\": \"02cx-like\",\n",
    "    \"LSQ12fhs\": \"02cx-like\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_91t = [ \n",
    "    'SNF20070528-003', # Scalzo++ 2014\n",
    "    'SNF20070803-005', # Scalzo++ 2014\n",
    "    'SNF20070825-001', # Scalzo++ 2010\n",
    "    'SNF20070912-000', # Scalzo++ 2014\n",
    "    'SNF20080522-000', # Scalzo++ 2014\n",
    "    'SNF20080723-012', # Scalzo++ 2014\n",
    "    'SNF20080805-007', # Lin++ 2020\n",
    "    'LSQ12cyz', # Lin++ 2020\n",
    "    'LSQ12fhe', # Lin++ 2020\n",
    "    'PTF11bju', # Lin++ 2020\n",
    "    'PTF11mkx', # Lin++ 2020\n",
    "]\n",
    "\n",
    "outliers_91bg = [\n",
    "    'LSQ12cfx', # Lin++ 2020\n",
    "    'PTF10ops', # Maguire++ 2011\n",
    "    'PTF11bkf', # Lin++ 2020\n",
    "    'PTF11kjn', # Lin++ 2020\n",
    "    'PTF11okh', # Lin++ 2020\n",
    "    'PTF11pra', # Lin++ 2020\n",
    "    'PTF12dwm', # Lin++ 2020\n",
    "    'SN2005bl', # Lin++ 2020\n",
    "    'SN2005dh', # Lin++ 2020 \n",
    "    'SN2005dm', # Lin++ 2020\n",
    "    'SN2007ba', # Lin++ 2020\n",
    "    'SN2009hs', # Lin++ 2020\n",
    "    'SNNGC6430', # Lin++ 2020\n",
    "]\n",
    "\n",
    "outliers_02cx = [\n",
    "    'SN2005cc', # Lin++ 2020\n",
    "    'LSQ12fhs', # \n",
    "    LSQ12fhs\") Target(name=\"SN2005cc\") Target(name=\"SN2011ay\n",
    "]\n",
    "\n",
    "outlier_labels = {\n",
    "    # Scalzo++ 2014\n",
    "    \"SNF20070528-003\": \"91T-like\",\n",
    "    \"SNF20070803-005\": \"91T-like\",\n",
    "    \"SNF20070825-001\": \"91T-like\",\n",
    "    \"SNF20070912-000\": \"91T-like\",\n",
    "    \"SNF20080522-000\": \"91T-like\",\n",
    "    \"SNF20080723-012\": \"91T-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"SNF20080805-007\": \"91T-like\",\n",
    "    \"LSQ12cyz\": \"91T-like\",\n",
    "    \"LSQ12fhe\": \"91T-like\",\n",
    "    \"PTF11bju\": \"91T-like\",\n",
    "    \"PTF11mkx\": \"91T-like\",\n",
    "    \"LSQ12cfx\": \"91bg-like\",\n",
    "    \n",
    "    # Discussion between Kyle and Greg:\n",
    "    \"SNNGC2691\": \"91T-like\",\n",
    "    \n",
    "    # Maguire++ 2011\n",
    "    \"PTF10ops\": \"91bg-like\",\n",
    "    \n",
    "    # Lin++ 2020\n",
    "    \"PTF11bkf\": \"91bg-like\",\n",
    "    \"PTF11kjn\": \"91bg-like\",\n",
    "    \"PTF11okh\": \"91bg-like\",\n",
    "    \"PTF11pra\": \"91bg-like\",\n",
    "    \"PTF12dwm\": \"91bg-like\",\n",
    "    \"SN2005bl\": \"91bg-like\",\n",
    "    \"SN2005dh\": \"91bg-like\",\n",
    "    \"SN2005dm\": \"91bg-like\",\n",
    "    \"SN2007ba\": \"91bg-like\",\n",
    "    \"SN2009hs\": \"91bg-like\",\n",
    "    \"SNNGC6430\": \"91bg-like\",\n",
    "    \"SN2005cc\": \"02cx-like\",\n",
    "    \n",
    "    # Foley++ 2013\n",
    "    \"SN2011ay\": \"02cx-like\",\n",
    "    \"LSQ12fhs\": \"02cx-like\",\n",
    "}\n",
    "\n",
    "mask_91t = np.array([i.name in outliers_91t for i in a.targets])\n",
    "mask_91bg = np.array([i.name in outliers_91bg for i in a.targets])\n",
    "mask_02cx = np.array([i.name in outliers_02cx for i in a.targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "use_x = a.embedding[:, 0]\n",
    "\n",
    "mask = a.salt_mask & a.redshift_color_mask & a.uncertainty_mask\n",
    "plt.errorbar(use_x[mask], a.salt_hr[mask], a.salt_hr_uncertainties[mask], label='Individual supernovae', fmt='.', alpha=0.2, c='k')\n",
    "math.plot_binned_mean(use_x[mask], a.salt_hr[mask], c='C3', lw=2, label='Binned mean')\n",
    "\n",
    "# mask = mask & mask_91t\n",
    "# plt.scatter(use_x[mask], a.salt_hr[mask], label='91T-like SNe IA', c='C2', marker='s', zorder=10)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('SALT2 Hubble residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('/home/kyle/supernova/meetings/2020_01_04_aas_hawaii/talk/salt_bias.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot(label, mask=None, **kwargs):\n",
    "    if mask is None:\n",
    "        mask = a.uncertainty_mask\n",
    "    else:\n",
    "        mask = mask & a.uncertainty_mask\n",
    "\n",
    "    plt.scatter(a.embedding[mask, 0], a.embedding[mask, 1], label=label, s=50, **kwargs)\n",
    "    \n",
    "plt.figure()\n",
    "do_plot('All SNe Ia', c='k', alpha=0.1)\n",
    "do_plot('91T-like', mask_91t)\n",
    "do_plot('91bg-like', mask_91bg)\n",
    "do_plot('02cx-like', mask_02cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./spectra_list.txt', 'w') as outfile:\n",
    "    for line in all_obs:\n",
    "        print(line, file=outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
